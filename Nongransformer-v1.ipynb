{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1vz8OdJRw7bYk_E8iyT-BHCxevylLgrzb","authorship_tag":"ABX9TyOpph9utkgnkOdWJkLFJSAQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["%cd drive/MyDrive/data/aT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEudILbtkzu2","executionInfo":{"status":"ok","timestamp":1662102426475,"user_tz":-540,"elapsed":3,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"1af872ab-318c-4969-fa8f-0cfd163e5d9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data/aT\n"]}]},{"cell_type":"markdown","source":["# Import"],"metadata":{"id":"mHmUZYfeendt"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.optim.lr_scheduler as lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# torch.random.manual_seed(seed=2020320120)"],"metadata":{"id":"fRvio_MJbPTM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset\n","데이터셋을 만들 때 고려해야 할 조건\n","* train, val, test를 어떻게 구분할 것인가? -> 먼저, split 인자를 통해 (train, val), test를 구분한다.\n","* 특히 train, val을 어떻게 구분할 것인가? -> phase 인자를 통해 train, val을 구분한다.\n","* 품목에 따라 데이터셋을 만들 것인가? -> use_all_items 인자와 item_idx 인자를 통해 모든 품목을 사용할 것인지, 하나의 품목만 사용할 것인지, 하나의 품목만 사용할 것이라면 사용할 품목의 인덱스는 무엇인지 설정한다."],"metadata":{"id":"-EF4kax3em-q"}},{"cell_type":"code","source":["def time_window(df, t, t_sep, use_scale=False):\n","    seq_len = t\n","    seqence_length = seq_len + t_sep\n","\n","    scaler = MinMaxScaler()\n","\n","    result = []\n","    for index in range(len(df) - seqence_length):\n","        data = np.array(df[index: index + seqence_length].values, dtype=np.float32)\n","        if use_scale:\n","            scaler.fit(data)\n","            data = scaler.transform(data)\n","        result.append(data)\n","    return np.array(result)"],"metadata":{"id":"SkLoVNn36BU4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NongDataset(Dataset):\n","    def __init__(self, split, use_all_pummok=True, idx_pummok=0):\n","        super().__init__()\n","\n","        # 'train' or 'test'\n","        self.split = split\n","\n","        # initialize data\n","        if self.split == 'train':\n","            self.init_train(use_all_pummok, idx_pummok)\n","        elif self.split == 'test':\n","            self.init_test(use_all_pummok, idx_pummok)\n","        else:\n","            raise ValueError()\n","    \n","    def init_train(self, use_all_pummok, idx_pummok):\n","        # in case of train, self.phase is needed\n","        self.phase = 'train'\n","\n","        # train_0.csv, train_1.csv, train_2.csv etc.\n","        self.file_list = [os.path.join(self.split, x) for x in os.listdir(self.split)]\n","\n","        # columns doesn't used in train phase\n","        tr_del_list = ['단가(원)', '거래량', '거래대금(원)', '경매건수', '도매시장코드', '도매법인코드', '산지코드 ']\n","        \n","        # Data\n","        self.data = {\n","            'train': {\n","                'inputs': [],\n","                'labels': []\n","            },\n","            'val': {\n","                'inputs': [],\n","                'labels': []\n","            },\n","        }\n","\n","        # transform all data\n","        for file_path in self.file_list:\n","            data = pd.read_csv(file_path)\n","\n","            for j in data.columns:\n","                data[j] = data[j].replace({' ': np.nan})\n","            \n","            data.drop(tr_del_list, axis=1, inplace=True)\n","            data.set_index('datadate', drop=True, inplace=True)\n","\n","            data = data.fillna(0)\n","\n","            x, y = data[[i for i in data.columns if i != '해당일자_전체평균가격(원)']], data['해당일자_전체평균가격(원)']\n","\n","            y = y[14:]\n","\n","            data_x = time_window(x, 13, 1, use_scale=True)\n","            data_y = time_window(y, 27, 1)\n","\n","            xdata = data_x[:len(data_y)]\n","            ydata = data_y\n","\n","            x_train, x_val, y_train, y_val = train_test_split(xdata, ydata, test_size=0.2, shuffle=False, random_state=119)\n","\n","            self.data['train']['inputs'].append(x_train)\n","            self.data['train']['labels'].append(y_train)\n","            self.data['val']['inputs'].append(x_val)\n","            self.data['val']['labels'].append(y_val)\n","        \n","        self.data['train']['inputs'] = torch.tensor(np.concatenate(self.data['train']['inputs'], axis=0, dtype=np.float32))\n","        self.data['train']['labels'] = torch.tensor(np.concatenate(self.data['train']['labels'], axis=0, dtype=np.float32))\n","        self.data['val']['inputs'] = torch.tensor(np.concatenate(self.data['val']['inputs'], axis=0, dtype=np.float32))\n","        self.data['val']['labels'] = torch.tensor(np.concatenate(self.data['val']['labels'], axis=0, dtype=np.float32))\n","        \n","    def init_test(self, use_all_pummok, idx_pummok): # 수정해주세용\n","        self.path_list = [os.path.join(self.split, x) for x in os.listdir(self.split)]\n","        self.file_list = []\n","\n","        # test 에서 사용하지 않는 열\n","        ts_del_list = ['단가(원)', '거래량', '거래대금(원)', '경매건수', '도매시장코드', '도매법인코드', '산지코드 ', '해당일자_전체평균가격(원)']\n","\n","        for path in self.path_list:\n","            file_list = [os.path.join(path, x) for x in os.listdir(path)]\n","            self.file_list.append(file_list)\n","\n","\n","        self.data = {\n","            'inputs': [],\n","            'labels': [],\n","        }\n","\n","        for file_paths in self.file_list:\n","            for file_path in file_paths:\n","                data = pd.read_csv(file_path)\n","\n","                for j in data.columns:\n","                    data[j] = data[j].replace({' ': np.nan})\n","\n","                data.drop(ts_del_list, axis=0, inplace=True)\n","                data.set_index('datadate', drop=True, inplace=True)\n","\n","                data = data.fillna(0)\n","\n","                x, y = data[[i for i in data.columns if i != '해당일자_전체평균가격(원)']], data['해당일자_전체평균가격(원)']\n","\n","                y = y[14:]\n","\n","                data_x = time_window(x, 13, 1)\n","                data_y = time_window(y, 27, 1)\n","\n","                xdata = data_x[:len(data_y)]\n","                ydata = data_y\n","\n","                self.data['inputs'].append(xdata)\n","                self.data['labels'].append(ydata)\n","\n","        self.data['inputs'] = np.concatenate(self.data['inputs'], axis=0)\n","        self.data['labels'] = np.concatenate(self.data['labels'], axis=0)\n","\n","        print(self.data['inputs'].shape)\n","        print(self.data['labels'].shape)\n","\n","    def __getitem__(self, idx):\n","        if self.split == 'train':\n","            return self.train_item(idx)\n","        elif self.split == 'test':\n","            return self.test_item(idx)\n","        else:\n","            raise ValueError()\n","\n","    def train(self):\n","        self.phase = 'train'\n","    \n","    def eval(self):\n","        self.phase = 'val'\n","    \n","    def train_item(self, idx):\n","        return self.data[self.phase]['inputs'][idx], self.data[self.phase]['labels'][idx]\n","\n","    def test_item(self, idx): # 수정하기\n","        pass\n","    \n","    def __len__(self):\n","        return self.data[self.phase]['inputs'].shape[0]"],"metadata":{"id":"0yz1shb9kKPP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model"],"metadata":{"id":"jyvTwL8cetUr"}},{"cell_type":"code","source":["class Nongransformer(nn.Module):\n","    def __init__(self, d_model, n_heads, dropout, n_transformer_blocks):\n","        super().__init__()\n","\n","        self.dim_magnification = nn.Sequential(\n","            nn.Linear(49, d_model // 2),\n","            nn.ReLU(),\n","            nn.Linear(d_model // 2, d_model),\n","            nn.ReLU(),\n","            nn.Linear(d_model, d_model)\n","        )\n","\n","        self.encoder = nn.TransformerEncoder(\n","            encoder_layer=nn.TransformerEncoderLayer(\n","                d_model=d_model,\n","                nhead=n_heads,\n","                dropout=dropout,\n","            ),\n","            num_layers=n_transformer_blocks,\n","        )\n","\n","        self.predictor = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(512 * 14, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 28),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, inputs):\n","        dim_magnification = self.dim_magnification(inputs)\n","        encodings = self.encoder(dim_magnification)\n","        return self.predictor(encodings)"],"metadata":{"id":"GtHzZ4Vqd_NF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train\n"],"metadata":{"id":"BT3tMrr4lj0b"}},{"cell_type":"code","source":["def grad_check_fn(named_params):\n","    params = named_params[1]\n","    with torch.no_grad():\n","        sum = params * params\n","    return sum.sum()"],"metadata":{"id":"a8iUSl3M45LN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t = torch.tensor([[1, 2, 3],\n","                  [1, 2, 3],\n","                  [1, 2 ,3]] ,dtype=torch.float32)\n","\n","print(grad_check_fn(('name', t)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IlGwu775Jih","executionInfo":{"status":"ok","timestamp":1662103254664,"user_tz":-540,"elapsed":7,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"e8db7c7a-e438-4ece-d46e-4b49cebb04cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(42.)\n"]}]},{"cell_type":"code","source":["net = Nongransformer(\n","        d_model=512,\n","        n_heads=8,\n","        dropout=0.5,\n","        n_transformer_blocks=6\n","    )\n","\n","n = grad_check_fn(next(net.named_parameters()))\n","\n","print(f'n: {n}')\n","\n","if n > 0:\n","    print('n > 0')\n","\n","if n < 0:\n","    print('n < 0')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQo_UMsqB6FK","executionInfo":{"status":"ok","timestamp":1662103399212,"user_tz":-540,"elapsed":485,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"5b4e31c5-d4f7-4cc8-f5b6-8427e3b2ab4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["n: 85.93367004394531\n","n > 0\n"]}]},{"cell_type":"code","source":["def train_one_epoch(net, dataloader, optimizer, criterion, scheduler, device):\n","    dataloader.dataset.train()\n","    net.train()\n","\n","    total_size = len(dataloader.dataset)\n","\n","    total_loss = 0.0\n","\n","    is_grad_update = None\n","\n","    for inputs, labels in tqdm(dataloader):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        with torch.set_grad_enabled(True):\n","            outputs = net(inputs)\n","\n","            loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        grad_check = grad_check_fn(next(net.named_parameters())).item()\n","        if is_grad_update == None and grad_check > 0:\n","            is_grad_update = grad_check\n","\n","        optimizer.step()\n","\n","        scheduler.step()\n","\n","        total_loss += loss.item() * inputs.shape[0]\n","    \n","    print(f'Train Total Loss: {total_loss / total_size}')\n","    \n","    if is_grad_update:\n","        print('gradient flow good')\n","    else:\n","        print('gradient flow bad')\n","    \n","    return net.state_dict()"],"metadata":{"id":"fXfQ4sLVMw2Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval_one_epoch(net, dataloader, criterion, device):\n","    dataloader.dataset.eval()\n","    net.eval()\n","\n","    total_size = len(dataloader.dataset)\n","\n","    total_loss = 0.0\n","\n","    for inputs, labels in tqdm(dataloader):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        with torch.set_grad_enabled(False):\n","            outputs = net(inputs)\n","\n","            loss = criterion(outputs, labels)\n","\n","        total_loss += loss.item() * inputs.shape[0]\n","    \n","    print(f'Eval Total Loss: {total_loss / total_size}')\n","    \n","    return total_loss / total_size"],"metadata":{"id":"r0kfjL06MrmB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = NongDataset('train')"],"metadata":{"id":"Xgdm9C3o0GOZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(epochs, train_dataset):\n","    # Dataset\n","    # train_dataset = NongDataset('train')\n","    print('Make Dataset ' + '=' * 30)\n","\n","    # DataLoader\n","    train_dataloader = DataLoader(\n","        dataset=train_dataset,\n","        batch_size=128,\n","        shuffle=True\n","    )\n","    print('Make DataLoader ' + '=' * 30)\n","\n","    for inputs, labels in train_dataloader:\n","        print(f'type(inputs): {type(inputs)}')\n","        print(f'type(labels): {type(labels)}')\n","        print(f'inputs.shape: {inputs.shape}')\n","        print(f'labels.shape: {labels.shape}')\n","\n","        break\n","\n","    # Net\n","    nongransformer = Nongransformer(\n","        d_model=512,\n","        n_heads=8,\n","        dropout=0.5,\n","        n_transformer_blocks=6\n","    )\n","    print('Make Nongransformer ' + '=' * 30)\n","\n","    for name, param in nongransformer.named_parameters():\n","        nn.init.normal_(param)\n","    print('Complete Param Init ' + '=' * 30)\n","    \n","    # Criterion\n","    criterion = nn.L1Loss()\n","\n","    # Optimizer\n","    optimizer = optim.Adam(nongransformer.parameters(), lr=1e-3, betas=(0.9, 0.999))\n","\n","    # Learning Rate Scheduler\n","    scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n","\n","    # Device\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    nongransformer = nongransformer.to(device)\n","\n","    best_loss = None\n","    best_state = None\n","    update_count = 0\n","    no_update_count = 0\n","    late_update = False\n","\n","    for epoch in range(epochs):\n","        print(f'{epoch} Epoch ' + '=' * 50)\n","\n","        if late_update:\n","            nongransformer.load_state_dict(best_state)\n","            update_count = update_count + 1\n","            print(f'Update Count: {update_count} / {update_count + no_update_count}')\n","        else:\n","            no_update_count = no_update_count + 1\n","            print(f'No Update Count: {no_update_count} / {update_count + no_update_count}')\n","\n","        state = train_one_epoch(\n","            net=nongransformer,\n","            dataloader=train_dataloader,\n","            optimizer=optimizer,\n","            criterion=criterion,\n","            scheduler=scheduler,\n","            device=device\n","        )\n","\n","        eval_loss = eval_one_epoch(\n","            net=nongransformer,\n","            dataloader=train_dataloader,\n","            criterion=criterion,\n","            device=device\n","        )\n","\n","        late_update = False\n","\n","        if best_loss == None:\n","            best_loss = eval_loss\n","            best_state = state\n","            late_update = True\n","            print(f'Best Loss: {best_loss}')\n","        elif best_loss > eval_loss:\n","            best_loss = eval_loss\n","            best_state = state\n","            late_update = True\n","            print(f'Best Loss: {best_loss}')\n","        else:\n","            print('No Update')\n","\n","train(epochs=1000, train_dataset=train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CwOLZYQLMHMr","executionInfo":{"status":"error","timestamp":1662107662471,"user_tz":-540,"elapsed":2133199,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"5ccd61c7-68d1-4aaa-ba25-6121dafbb921"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Make Dataset ==============================\n","Make DataLoader ==============================\n","type(inputs): <class 'torch.Tensor'>\n","type(labels): <class 'torch.Tensor'>\n","inputs.shape: torch.Size([128, 14, 49])\n","labels.shape: torch.Size([128, 28])\n","Make Nongransformer ==============================\n","Complete Param Init ==============================\n","0 Epoch ==================================================\n","No Update Count: 1 / 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1669.59088077066\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 35.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1909.5960526540791\n","Best Loss: 20066035.321289062\n","1 Epoch ==================================================\n","Update Count: 1 / 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:27<00:00, 12.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.273030896419\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.968449261872\n","Best Loss: 20059440.46484375\n","2 Epoch ==================================================\n","Update Count: 2 / 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.4440627261476\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.960580257304\n","Best Loss: 20059357.77734375\n","3 Epoch ==================================================\n","Update Count: 3 / 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.7045234702884\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 36.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.965338443775\n","No Update\n","4 Epoch ==================================================\n","No Update Count: 2 / 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.8610243313935\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9666128634135\n","No Update\n","5 Epoch ==================================================\n","No Update Count: 3 / 6\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.7562333179778\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9648303673391\n","No Update\n","6 Epoch ==================================================\n","No Update Count: 4 / 7\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.227375224636\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9579087436357\n","Best Loss: 20059329.705078125\n","7 Epoch ==================================================\n","Update Count: 4 / 8\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.4640535325773\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9647579476277\n","No Update\n","8 Epoch ==================================================\n","No Update Count: 5 / 9\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.1561831091312\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9737236566039\n","No Update\n","9 Epoch ==================================================\n","No Update Count: 6 / 10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.8105546215743\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.96211484888\n","No Update\n","10 Epoch ==================================================\n","No Update Count: 7 / 11\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.9231005283832\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9656837907726\n","No Update\n","11 Epoch ==================================================\n","No Update Count: 8 / 12\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.5992277319565\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.954626692535\n","Best Loss: 20059295.217285156\n","12 Epoch ==================================================\n","Update Count: 5 / 13\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.2952331797312\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.953160083017\n","Best Loss: 20059279.806152344\n","13 Epoch ==================================================\n","Update Count: 6 / 14\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.9878603305174\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9496654892403\n","Best Loss: 20059243.084960938\n","14 Epoch ==================================================\n","Update Count: 7 / 15\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.1247264718083\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9656632521055\n","No Update\n","15 Epoch ==================================================\n","No Update Count: 9 / 16\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.7689527887435\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9583551111355\n","No Update\n","16 Epoch ==================================================\n","No Update Count: 10 / 17\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.2001299273445\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9533065952726\n","No Update\n","17 Epoch ==================================================\n","No Update Count: 11 / 18\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.104080104635\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9557519047987\n","No Update\n","18 Epoch ==================================================\n","No Update Count: 12 / 19\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.7826181409246\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9697241926538\n","No Update\n","19 Epoch ==================================================\n","No Update Count: 13 / 20\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.6418936068933\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9624988104301\n","No Update\n","20 Epoch ==================================================\n","No Update Count: 14 / 21\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1629.166593682214\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9565405989038\n","No Update\n","21 Epoch ==================================================\n","No Update Count: 15 / 22\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.1460546537812\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9656699434358\n","No Update\n","22 Epoch ==================================================\n","No Update Count: 16 / 23\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.1573472985995\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9487338608828\n","Best Loss: 20059233.295410156\n","23 Epoch ==================================================\n","Update Count: 8 / 24\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.3679289125519\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9553822087933\n","No Update\n","24 Epoch ==================================================\n","No Update Count: 17 / 25\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.7772801903036\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9574101465848\n","No Update\n","25 Epoch ==================================================\n","No Update Count: 18 / 26\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.3771568846087\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9594336234893\n","No Update\n","26 Epoch ==================================================\n","No Update Count: 19 / 27\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.8657147032943\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.97052166913\n","No Update\n","27 Epoch ==================================================\n","No Update Count: 20 / 28\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1629.1506198247653\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.96632792426\n","No Update\n","28 Epoch ==================================================\n","No Update Count: 21 / 29\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.5623247442961\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9555093440713\n","No Update\n","29 Epoch ==================================================\n","No Update Count: 22 / 30\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.4569674810152\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9644307462172\n","No Update\n","30 Epoch ==================================================\n","No Update Count: 23 / 31\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.9291488936321\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9633417321922\n","No Update\n","31 Epoch ==================================================\n","No Update Count: 24 / 32\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.4237390088756\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9659935900772\n","No Update\n","32 Epoch ==================================================\n","No Update Count: 25 / 33\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.1998217270564\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9720213170917\n","No Update\n","33 Epoch ==================================================\n","No Update Count: 26 / 34\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.9013241525915\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.959931384124\n","No Update\n","34 Epoch ==================================================\n","No Update Count: 27 / 35\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.3324716739903\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9689196995741\n","No Update\n","35 Epoch ==================================================\n","No Update Count: 28 / 36\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.5584734092229\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9624680953648\n","No Update\n","36 Epoch ==================================================\n","No Update Count: 29 / 37\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.730794582828\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9641256401374\n","No Update\n","37 Epoch ==================================================\n","No Update Count: 30 / 38\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.0638640045736\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.955655275482\n","No Update\n","38 Epoch ==================================================\n","No Update Count: 31 / 39\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.545567323049\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9614223426497\n","No Update\n","39 Epoch ==================================================\n","No Update Count: 32 / 40\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.843410711678\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9516360860475\n","No Update\n","40 Epoch ==================================================\n","No Update Count: 33 / 41\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.9882308027975\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 36.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9550471775967\n","No Update\n","41 Epoch ==================================================\n","No Update Count: 34 / 42\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.7419301596776\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9604901566813\n","No Update\n","42 Epoch ==================================================\n","No Update Count: 35 / 43\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1629.07421572404\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9673517675149\n","No Update\n","43 Epoch ==================================================\n","No Update Count: 36 / 44\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.018188430054\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9574004813296\n","No Update\n","44 Epoch ==================================================\n","No Update Count: 37 / 45\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1629.108857456175\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9671763756633\n","No Update\n","45 Epoch ==================================================\n","No Update Count: 38 / 46\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.9693525846408\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.97734631501\n","No Update\n","46 Epoch ==================================================\n","No Update Count: 39 / 47\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.2865224346601\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9623034142885\n","No Update\n","47 Epoch ==================================================\n","No Update Count: 40 / 48\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.061357986372\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9589975717906\n","No Update\n","48 Epoch ==================================================\n","No Update Count: 41 / 49\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.8000314862632\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.96216940181\n","No Update\n","49 Epoch ==================================================\n","No Update Count: 42 / 50\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.2156140123639\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9612646317091\n","No Update\n","50 Epoch ==================================================\n","No Update Count: 43 / 51\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.8078438438308\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9617630893574\n","No Update\n","51 Epoch ==================================================\n","No Update Count: 44 / 52\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.1561930416055\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.964431303828\n","No Update\n","52 Epoch ==================================================\n","No Update Count: 45 / 53\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.892513611879\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9677010410223\n","No Update\n","53 Epoch ==================================================\n","No Update Count: 46 / 54\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.3532563516676\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9647254435608\n","No Update\n","54 Epoch ==================================================\n","No Update Count: 47 / 55\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.645381681413\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9655736161585\n","No Update\n","55 Epoch ==================================================\n","No Update Count: 48 / 56\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.3692061874692\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9608769062856\n","No Update\n","56 Epoch ==================================================\n","No Update Count: 49 / 57\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.8823161408027\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9696193153432\n","No Update\n","57 Epoch ==================================================\n","No Update Count: 50 / 58\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.9501991988677\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9660951217227\n","No Update\n","58 Epoch ==================================================\n","No Update Count: 51 / 59\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.5539080434846\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9628725026469\n","No Update\n","59 Epoch ==================================================\n","No Update Count: 52 / 60\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.327307458826\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9579346725411\n","No Update\n","60 Epoch ==================================================\n","No Update Count: 53 / 61\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.2543830523678\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9535682077048\n","No Update\n","61 Epoch ==================================================\n","No Update Count: 54 / 62\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.5979000941331\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9557509754472\n","No Update\n","62 Epoch ==================================================\n","No Update Count: 55 / 63\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.0543734687071\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9579887143277\n","No Update\n","63 Epoch ==================================================\n","No Update Count: 56 / 64\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.1911451628357\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.96654957458\n","No Update\n","64 Epoch ==================================================\n","No Update Count: 57 / 65\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.5925772907535\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.959500350923\n","No Update\n","65 Epoch ==================================================\n","No Update Count: 58 / 66\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.592751816855\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9557897294026\n","No Update\n","66 Epoch ==================================================\n","No Update Count: 59 / 67\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.8965634859806\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9647189381008\n","No Update\n","67 Epoch ==================================================\n","No Update Count: 60 / 68\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.5868189584046\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9584262529888\n","No Update\n","68 Epoch ==================================================\n","No Update Count: 61 / 69\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.608074979513\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9650815710352\n","No Update\n","69 Epoch ==================================================\n","No Update Count: 62 / 70\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1627.1842492060996\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9687222123916\n","No Update\n","70 Epoch ==================================================\n","No Update Count: 63 / 71\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.4153129540393\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9699575992695\n","No Update\n","71 Epoch ==================================================\n","No Update Count: 64 / 72\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.0706237349684\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9578469417645\n","No Update\n","72 Epoch ==================================================\n","No Update Count: 65 / 73\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:26<00:00, 12.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Total Loss: 1628.7582969733655\n","gradient flow good\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:02<00:00, 37.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Total Loss: 1908.9638943245623\n","No Update\n","73 Epoch ==================================================\n","No Update Count: 66 / 74\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 209/329 [00:17<00:09, 12.26it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-42245a9aeeaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No Update'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-28-42245a9aeeaf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, train_dataset)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         )\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-346d5a1861f5>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(net, dataloader, optimizer, criterion, scheduler, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mgrad_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_check_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_grad_update\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgrad_check\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mis_grad_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"zdRYbAF7NacD"},"execution_count":null,"outputs":[]}]}