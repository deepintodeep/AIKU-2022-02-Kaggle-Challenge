{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fNvP68r8H1on5RaJ0Aq6WcS9vvEkxpvL","timestamp":1662518322575},{"file_id":"1Xrh4MFYbJUFQnZ0JWyvKFcj4Wh60mPK4","timestamp":1662387501770}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"948cc76e26194475a07a3204db8947da":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_df537a395ed4411ea86b4421ba6036c5","IPY_MODEL_332edc2cd15d4a8ebe173d8afdea6455"],"layout":"IPY_MODEL_c6066f9d5c9349eb9347f7e5f374ca5a"}},"df537a395ed4411ea86b4421ba6036c5":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4729ff5cdcd41c694c013f04a9c6425","placeholder":"​","style":"IPY_MODEL_172fc46fd46a435680516d1e28ef36d8","value":"0.095 MB of 0.095 MB uploaded (0.000 MB deduped)\r"}},"332edc2cd15d4a8ebe173d8afdea6455":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f4cd4d256a14b858af714f724bdad73","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8079b616318d421f9f6ebfc9a655c826","value":1}},"c6066f9d5c9349eb9347f7e5f374ca5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4729ff5cdcd41c694c013f04a9c6425":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"172fc46fd46a435680516d1e28ef36d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f4cd4d256a14b858af714f724bdad73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8079b616318d421f9f6ebfc9a655c826":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","source":["# Install wandb\n","!pip install wandb"],"metadata":{"id":"gV7Eul5O5K-P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3h43fJU2tMC","executionInfo":{"status":"ok","timestamp":1662435664195,"user_tz":-540,"elapsed":2458,"user":{"displayName":"intodeep deep","userId":"12836540751567644477"}},"outputId":"97c583c3-5f00-4a98-bfbe-3ec72def2b42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Access data\n","%cd drive/MyDrive/scaled_data/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLejx7u_uvjP","executionInfo":{"status":"ok","timestamp":1662435664195,"user_tz":-540,"elapsed":8,"user":{"displayName":"intodeep deep","userId":"12836540751567644477"}},"outputId":"0afa39c2-c727-4d03-ddac-81e40298a5f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/scaled_data\n"]}]},{"cell_type":"code","source":["# Login wandb\n","!wandb login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFwtYiBE5cgU","executionInfo":{"status":"ok","timestamp":1662435666993,"user_tz":-540,"elapsed":2802,"user":{"displayName":"intodeep deep","userId":"12836540751567644477"}},"outputId":"3c5495ec-ff58-431a-e7a3-72d1becbc84b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdeep-overflow\u001b[0m (\u001b[33mdeepintodeep\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}]},{"cell_type":"code","source":["# Import\n","import torch\n","import torch.nn as nn # Neural Network\n","import torch.optim as optim # Optimizer\n","import torch.optim.lr_scheduler as lr_scheduler # Scheduler\n","from torch.utils.data import Dataset, DataLoader # Data\n","\n","import wandb\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import warnings\n","from glob import glob\n","from sklearn.model_selection import train_test_split\n","import random\n","import os\n","\n","# 경고 끄기\n","warnings.filterwarnings(action='ignore')\n","\n","# Fix seed\n","torch.random.manual_seed(2020320120)\n","random.seed(2020320120)\n","np.random.seed(2020320120)"],"metadata":{"id":"DxBU2KYFrjgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train data file path list\n","data_list = glob('.//train/*.csv')\n","\n","# column list that include column which isn't used in train\n","tr_del_list = ['단가(원)', '거래량', '거래대금(원)', '경매건수', '도매시장코드', '도매법인코드', '산지코드 ']\n","# column list that include column which isn't used in test\n","ts_del_list = ['단가(원)', '거래량', '거래대금(원)', '경매건수', '도매시장코드', '도매법인코드', '산지코드 ', '해당일자_전체평균가격(원)']\n","\n","check_col = ['일자구분_중순', '일자구분_초순', '일자구분_하순','월구분_10월', '월구분_11월', '월구분_12월', '월구분_1월', '월구분_2월', '월구분_3월', \n","             '월구분_4월','월구분_5월', '월구분_6월', '월구분_7월', '월구분_8월', '월구분_9월']"],"metadata":{"id":"O1og1-aHuxHb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for data sample according to time window\n","def time_window(df, t, t_sep):\n","    seq_len = t\n","    seqence_length = seq_len + t_sep\n","\n","    result = []\n","    for index in range(len(df) - seqence_length):\n","        tmp = df[index: index + seqence_length].values\n","        tmp = np.vstack(tmp).astype(np.float)\n","        tmp = torch.from_numpy(tmp)\n","        result.append(tmp)\n","\n","    return np.array(result)\n","\n","# function for creating dataset; return tuple(ndarray, ndarray)\n","def make_dataset(i):\n","    df_number = i.split(\"_\")[-1].split(\".\")[0]\n","    df = pd.read_csv(i)\n","\n","    for j in df.columns:\n","        df[j] = df[j].replace({' ': np.nan})\n","\n","    # 사용할 열 선택 및 index 설정\n","    df.drop(tr_del_list, axis=1, inplace=True)\n","    df.set_index('datadate', drop=True, inplace=True)\n","\n","    # nan 처리\n","    df = df.fillna(0)\n","\n","    # 변수와 타겟 분리\n","    x, y = df[[i for i in df.columns if i != '해당일자_전체평균가격(원)']], df['해당일자_전체평균가격(원)']\n","\n","    # 2주 입력을 통한 이후 4주 예측을 위해 y의 첫 14일을 제외\n","    y = y[14:]\n","\n","    # time series window 생성\n","    data_x = time_window(x, 13, 1)\n","    data_y = time_window(y, 27, 1)\n","\n","    # y의 길이와 같은 길이로 설정\n","    xdata = data_x[:len(data_y)]\n","    ydata = data_y\n","\n","    return xdata, ydata"],"metadata":{"id":"Lrej9_OyvVms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Flag:\n","    def __init__(self, flags):\n","        for key, value in flags.items():\n","            if isinstance(value, dict):\n","                self.__dict__[key] = Flag(value)\n","            else:\n","                self.__dict__[key] = value"],"metadata":{"id":"VhKJjPQgxcnb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_Tensor(array):\n","    return torch.from_numpy(array)\n","\n","\n","def astype_data(data):\n","    df = data.astype(np.float32)\n","    return make_Tensor(df)\n","\n","\n","class testDataset(Dataset):\n","    def __init__(self, data):\n","        zero_csv = [0 for i in range(14)]\n","        df = pd.read_csv(data)\n","\n","        if len(df) == 0:\n","            print('no data in Dataset!!')\n","            print(df)\n","            df['zero_non'] = zero_csv\n","            print(df)\n","            df = df.fillna(0)\n","            print(df)\n","            df.drop('zero_non', axis=1, inplace=True)\n","            df.drop('Unnamed: 0', axis=1, inplace=True)\n","            print(df)\n","\n","        file_number = data.split('test_')[1].split('.')[0]\n","\n","        # 사용할 열 선택, index 설정\n","        df.drop(ts_del_list, axis=1, inplace=True)\n","        df.set_index('datadate', drop=True, inplace=True)\n","\n","        # train input 과 형상 맞추기\n","        add_col = [i for i in check_col if i not in df.columns]\n","\n","        for a in add_col:\n","            df[a] = 0\n","\n","        # ' ' -> nan 으로 변경\n","        for a in df.columns:\n","            df[a] = df[a].replace({' ': np.nan})\n","\n","        # nan 처리\n","        df = df.fillna(0)\n","\n","        # x_test  생성\n","        self.df_test = astype_data(df.values.reshape(1, df.values.shape[0], df.values.shape[1]))\n","\n","    def __len__(self):\n","        return len(self.df_test)\n","\n","    def __getitem__(self, idx):\n","        return self.df_test[idx]"],"metadata":{"id":"jxDFo0mRVnqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_test(flags):\n","    name = 'Test_001'\n","\n","    wandb.init(\n","        project=\"Nong_Linear\",\n","        entity='deep-overflow',\n","        config=flags,\n","        name=name\n","    )\n","\n","    flags = Flag(flags)\n","\n","    for item_idx in range(37): # 37로 수정하기\n","        if item_idx < 30:\n","            continue\n","        data_path = f'./train/train_{item_idx}.csv'\n","        train_dataset = windowDataset(data_path)\n","\n","        train_dataloader = DataLoader(\n","            dataset=train_dataset,\n","            batch_size=flags.batch_size,\n","            shuffle=True,\n","        )\n","\n","        net = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(14 * 49, flags.model.hid_dim),\n","            # nn.BatchNorm1d(flags.model.hid_dim),\n","            nn.LeakyReLU(),\n","            nn.Dropout(flags.dropout),\n","        )\n","\n","        for _ in range(flags.model.nlayers - 2):\n","            net.append(nn.Linear(flags.model.hid_dim, flags.model.hid_dim))\n","            # net.append(nn.BatchNorm1d(flags.model.hid_dim))\n","            net.append(nn.LeakyReLU())\n","            net.append(nn.Dropout(flags.dropout))\n","        \n","        net.append(nn.Linear(flags.model.hid_dim, 28))\n","        net.append(nn.ReLU())\n","\n","        for name, param in net.named_parameters():\n","            if name.split('.')[-1] == 'bias':\n","                continue\n","            nn.init.xavier_uniform_(param)\n","            # nn.init.kaiming_uniform_(param, nonlinearity='leaky_relu')\n","\n","        criterion = nn.L1Loss()\n","\n","        optimizer = optim.Adam(\n","            params=net.parameters(), \n","            lr=flags.lr,\n","            betas=(0.9, 0.999),\n","        )\n","\n","        def lr_schedule_fn(epoch):\n","            if epoch < 15:\n","                return 1.5 # 1e-4 * 1.5\n","            elif epoch >= 15 and epoch < 250:\n","                return 1.0\n","            elif epoch >= 250 and epoch < 350:\n","                return 1.5\n","            else:\n","                return 1.0\n","\n","        scheduler = lr_scheduler.LambdaLR(\n","            optimizer=optimizer,\n","            lr_lambda=lr_schedule_fn\n","        )\n","\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","        net = net.to(device)\n","        \n","        for epoch in range(flags.epochs):\n","            epoch_train_loss = 0.0\n","\n","            for inputs, labels in train_dataloader:\n","                inputs, labels = inputs.float().to(device), labels.to(device)\n","\n","                with torch.set_grad_enabled(True):\n","                    outputs = net(inputs)\n","                    loss = criterion(outputs, labels)\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","            \n","                epoch_train_loss += loss.item()\n","            \n","            scheduler.step()\n","            \n","            wandb.log({\n","                'loss': epoch_train_loss / len(train_dataloader),\n","                'lr': optimizer.param_groups[0]['lr']\n","            })\n","\n","            if (epoch + 1) % 10 == 0:\n","                print(f'[epoch : {epoch + 1} / {flags.epochs}] Train Loss : {epoch_train_loss / len(train_dataloader)}')\n","        \n","        # Test\n","        result_np = np.zeros((1, 28), dtype=np.float32)\n","        for set_num in range(10): # 10으로 수정하기\n","            data_path = f'./test/set_{set_num}/test_{item_idx}.csv'\n","            test_dataset = testDataset(data_path)\n","\n","            inputs = test_dataset[0].reshape(1, 14, 49).to(device)\n","\n","            with torch.no_grad():\n","                outputs = net(inputs)\n","\n","            output_np = outputs.cpu().detach().numpy()\n","\n","            result_np = np.concatenate([result_np, output_np], axis=0)\n","        \n","        result_pd = pd.DataFrame(result_np)\n","        result_pd.to_csv(f'./result_{item_idx}.csv')\n","        print(f'Save Result {item_idx}')\n","\n","flags = {\n","    'epochs': 500,\n","    'lr': 1e-4,\n","    'batch_size': 64,\n","    'data_num': 0,\n","    'model': {\n","        'nlayers': 10,\n","        'hid_dim': 1024,\n","        'weight_init': 'xavier_uniform'\n","    },\n","    'optim': 'Adam',\n","    'criterion': 'L1Loss',\n","    'dropout': 0.5,\n","    'lr_scheduler': {\n","        'method': 'Lambda'\n","    }\n","}\n","\n","train_and_test(flags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":506,"referenced_widgets":["948cc76e26194475a07a3204db8947da","df537a395ed4411ea86b4421ba6036c5","332edc2cd15d4a8ebe173d8afdea6455","c6066f9d5c9349eb9347f7e5f374ca5a","b4729ff5cdcd41c694c013f04a9c6425","172fc46fd46a435680516d1e28ef36d8","9f4cd4d256a14b858af714f724bdad73","8079b616318d421f9f6ebfc9a655c826"]},"id":"316osUg9zV1A","executionInfo":{"status":"error","timestamp":1662439391757,"user_tz":-540,"elapsed":1444,"user":{"displayName":"intodeep deep","userId":"12836540751567644477"}},"outputId":"9563063a-f441-41b5-a518-ed16d43b089a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:3h0zy5lo) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"948cc76e26194475a07a3204db8947da"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:3h0zy5lo). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Problem at: <ipython-input-16-9ebc410e6223> 8 train_and_test\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-9ebc410e6223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m }\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-9ebc410e6223>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(flags)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deep-overflow'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interrupted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0merror_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_disable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                 \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_probe_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_probe_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_label_probe_notebook\u001b[0;34m(self, notebook)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m             \u001b[0mcell0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cells\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mprobe_ipynb\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mcolab_ipynb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_colab_load_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolab_ipynb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcolab_ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mattempt_colab_load_ipynb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;31m# This isn't thread safe, never call in a thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get_ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ipynb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["def train(flags, idx):\n","    name = f'Exp_X_U_batch_128_{flags[\"data_num\"]:03d}_{idx}'\n","    \n","    flags['data_path'] = f'./train/train_{flags[\"data_num\"]}.csv'\n","\n","    wandb.init(\n","        project=\"Nong_Linear\", \n","        entity=\"deep-overflow\", \n","        config=flags,\n","        name=name\n","    )\n","\n","    # Flag # ====================\n","    # 다양한 Regularization 시도해보기\n","    # ===========================\n","    flags = Flag(flags)\n","\n","    # Dataset # ====================\n","    train_dataset = windowDataset(flags.data_path)\n","    test_dataset = testDataset()\n","\n","    # DataLoader # ====================\n","    train_dataloader = DataLoader(\n","        dataset=train_dataset,\n","        batch_size=flags.batch_size,\n","        shuffle=True\n","    )\n","\n","    # Net # ====================\n","    # Dropout\n","    # BatchNorm\n","    # ==========================\n","    net = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(14 * 49, flags.model.hid_dim),\n","        # nn.BatchNorm1d(flags.model.hid_dim),\n","        nn.LeakyReLU(),\n","        nn.Dropout(flags.dropout),\n","    )\n","\n","    for _ in range(flags.model.nlayers - 2):\n","        net.append(nn.Linear(flags.model.hid_dim, flags.model.hid_dim))\n","        # net.append(nn.BatchNorm1d(flags.model.hid_dim))\n","        net.append(nn.LeakyReLU())\n","        net.append(nn.Dropout(flags.dropout))\n","    \n","    net.append(nn.Linear(flags.model.hid_dim, 28))\n","    net.append(nn.ReLU())\n","\n","    # Weight Initialization # ====================\n","    # Xavier\n","    # Kaiming\n","    # ============================================\n","    for name, param in net.named_parameters():\n","        if name.split('.')[-1] == 'bias':\n","            continue\n","        print(f'Init {name}')\n","        nn.init.xavier_uniform_(param)\n","        # nn.init.kaiming_uniform_(param, nonlinearity='leaky_relu')\n","\n","    # Criterion # ====================\n","    # 다양한 로스 시도해보기\n","    # ================================\n","    criterion = nn.L1Loss()\n","\n","    # Optimizer # ====================\n","    # 다양한 옵티마이저 시도해보기\n","    # ================================\n","    optimizer = optim.Adam(\n","        params=net.parameters(), \n","        lr=flags.lr,\n","        betas=(0.9, 0.999),\n","    )\n","\n","    # scheduler = lr_scheduler.ExponentialLR(\n","    #     optimizer=optimizer,\n","    #     gamma=0.9\n","    # )\n","\n","    # scheduler = lr_scheduler.StepLR(\n","    #     optimizer=optimizer,\n","    #     step_size=flags.lr_scheduler.step_size,\n","    #     gamma=flags.lr_scheduler.gamma\n","    # )\n","\n","    def lr_schedule_fn(epoch):\n","        if epoch < 15:\n","            return 1.5 # 1e-4 * 1.5\n","        elif epoch >= 15 and epoch < 250:\n","            return 1.0\n","        elif epoch >= 250 and epoch < 350:\n","            return 1.5\n","        else:\n","            return 1.0\n","\n","\n","    # =====\n","    # a: 0 - 14: 1.5 // 15 - 249: 1 // 250 - 399: 1.5 // 400 - 499: 1 (O)\n","    # b: 0 - 14: 1.5 // 15 - 249: 1 // 250 - 349: 2 // 350 - 499: 1\n","    # c: 0 - 14: 1.5 // 15 - 249: 1 // 250 - 349: 10 // 350 - 499: 1 (X)\n","    # d: 0 - 14: 1.5 // 15 - 249: 1 // 250 - 349: 3 // 350 - 499: 1\n","    \n","    scheduler = lr_scheduler.LambdaLR(\n","        optimizer=optimizer,\n","        lr_lambda=lr_schedule_fn\n","    )\n","\n","    # scheduler = lr_scheduler.CosineAnnealingLR(\n","    #     optimizer=optimizer,\n","    #     T_max=100\n","    # )\n","\n","    # Device\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    net = net.to(device)\n","\n","    # Train\n","    for epoch in range(flags.epochs):\n","            \n","        epoch_train_loss = 0.0\n","\n","        for inputs, labels in train_dataloader:\n","            inputs, labels = inputs.float().to(device), labels.to(device)\n","\n","            with torch.set_grad_enabled(True):\n","                outputs = net(inputs)\n","                loss = criterion(outputs, labels)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","        \n","            epoch_train_loss += loss.item()\n","        \n","        scheduler.step()\n","        \n","        wandb.log({\n","            'loss': epoch_train_loss / len(train_dataloader),\n","            'lr': optimizer.param_groups[0]['lr']\n","        })\n","        if (epoch + 1) % 10 == 0:\n","            print(f'[epoch : {epoch + 1} / {flags.epochs}] Train Loss : {epoch_train_loss / len(train_dataloader)}')\n","\n","for i in range(1):\n","    flags = {\n","        'epochs': 500,\n","        'lr': 1e-4,\n","        'batch_size': 64,\n","        'data_num': 0,\n","        'model': {\n","            'nlayers': 10,\n","            'hid_dim': 1024,\n","            'weight_init': 'xavier_uniform'\n","        },\n","        'optim': 'Adam',\n","        'criterion': 'L1Loss',\n","        'dropout': 0.5,\n","        'lr_scheduler': {\n","            'method': 'Lambda'\n","        }\n","    }\n","\n","    train(flags, i)"],"metadata":{"id":"GjVzyrlPziGt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GXRK7rmtvvK0"},"execution_count":null,"outputs":[]}]}