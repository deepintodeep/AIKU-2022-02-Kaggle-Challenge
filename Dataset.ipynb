{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1eYGy41r4JatbhQLAfxoK8XuyvRbdAiPB","authorship_tag":"ABX9TyPkgiG6XS/M3Eed46IWDUiK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"76a5168ee17c4048a8fb5febc3c61265":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_8455cf5e6c514d9fb04b855f84fb466f","IPY_MODEL_9a6f18999aaf43dd8f8e71b641a8a83f"],"layout":"IPY_MODEL_658922dce49b47138b34d63fa6876b1b"}},"8455cf5e6c514d9fb04b855f84fb466f":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b73f0f0f5f7240bf8a45f63d56c1451f","placeholder":"​","style":"IPY_MODEL_9abd3a8afc004f9f88c3bb9a8e581d78","value":"0.103 MB of 0.103 MB uploaded (0.000 MB deduped)\r"}},"9a6f18999aaf43dd8f8e71b641a8a83f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ee7bd3966bb44c987dadb899a1e912f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6614c43fbc764634808605fdc80e4e0b","value":1}},"658922dce49b47138b34d63fa6876b1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b73f0f0f5f7240bf8a45f63d56c1451f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9abd3a8afc004f9f88c3bb9a8e581d78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ee7bd3966bb44c987dadb899a1e912f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6614c43fbc764634808605fdc80e4e0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8frjxDf-fSzN","executionInfo":{"status":"ok","timestamp":1662533880363,"user_tz":-540,"elapsed":3458,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"5c642ed1-d237-497d-81eb-8f7a2237a840"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.2)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n"]}]},{"cell_type":"code","source":["%cd drive/MyDrive/data/aT/scaled_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"icO12wVmSdwX","executionInfo":{"status":"ok","timestamp":1662533880364,"user_tz":-540,"elapsed":14,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"045a06f8-1617-480f-a7d1-947fc6120bd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data/aT/scaled_data\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XoMCHESyUc7u","executionInfo":{"status":"ok","timestamp":1662533880364,"user_tz":-540,"elapsed":9,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"f4395f3e-94e4-41b0-f867-df8fb086c9ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["answer_example.csv            model_weights_28.bias_3.pth  \u001b[0m\u001b[01;34mset_4\u001b[0m/\n","\u001b[01;34maT_test_raw\u001b[0m/                  model_weights_28.bias_4.pth  \u001b[01;34mset_5\u001b[0m/\n","\u001b[01;34mLinear_weight\u001b[0m/                model_weights_28.bias_5.pth  \u001b[01;34mset_6\u001b[0m/\n","model_weights_28.bias_0.pth   model_weights_28.bias_6.pth  \u001b[01;34mset_7\u001b[0m/\n","model_weights_28.bias_10.pth  model_weights_28.bias_7.pth  \u001b[01;34mset_8\u001b[0m/\n","model_weights_28.bias_11.pth  model_weights_28.bias_8.pth  \u001b[01;34mset_9\u001b[0m/\n","model_weights_28.bias_12.pth  model_weights_28.bias_9.pth  \u001b[01;34mtest\u001b[0m/\n","model_weights_28.bias_13.pth  \u001b[01;34mset_0\u001b[0m/                       \u001b[01;34mtrain\u001b[0m/\n","model_weights_28.bias_14.pth  \u001b[01;34mset_1\u001b[0m/                       \u001b[01;34mwandb\u001b[0m/\n","model_weights_28.bias_1.pth   \u001b[01;34mset_2\u001b[0m/\n","model_weights_28.bias_2.pth   \u001b[01;34mset_3\u001b[0m/\n"]}]},{"cell_type":"code","source":["!wandb login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8SHjTGYefcub","executionInfo":{"status":"ok","timestamp":1662533882800,"user_tz":-540,"elapsed":2440,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"10f20d5d-a4d8-4788-8b91-d4aaffd5940f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdeep-overflow\u001b[0m (\u001b[33mdeepintodeep\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from glob import glob\n","from sklearn.model_selection import train_test_split\n","import random\n","import os\n","import wandb\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn # Neural Network\n","import torch.optim as optim # Optimizer\n","import torch.optim.lr_scheduler as lr_scheduler # Scheduler\n","from torch.utils.data import Dataset, DataLoader # Data"],"metadata":{"id":"sbCNejrsSr3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습에 사용할 데이터 파일 (csv)\n","data_list = glob('.//train/*.csv')\n","\n","tr_del_list = ['단가(원)', '거래량', '거래대금(원)', '경매건수', '도매시장코드', '도매법인코드', '산지코드 '] # train 에서 사용하지 않는 열\n","ts_del_list = ['단가(원)', '거래량', '거래대금(원)', '경매건수', '도매시장코드', '도매법인코드', '산지코드 ', '해당일자_전체평균가격(원)'] # test 에서 사용하지 않는 열\n","check_col = ['일자구분_중순', '일자구분_초순', '일자구분_하순','월구분_10월', '월구분_11월', '월구분_12월', '월구분_1월', '월구분_2월', '월구분_3월', \n","             '월구분_4월','월구분_5월', '월구분_6월', '월구분_7월', '월구분_8월', '월구분_9월'] # 열 개수 맞추기\n","\n","def time_window(df, t, t_sep):\n","    seq_len = t\n","    seqence_length = seq_len + t_sep\n","\n","    result = []\n","    for index in range(len(df) - seqence_length):\n","        tmp = df[index: index + seqence_length].values\n","        tmp = np.vstack(tmp).astype(np.float32)\n","        result.append(tmp)\n","\n","    return np.array(result)"],"metadata":{"id":"lmvgI8i3UZal"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def right_value(a, i):\n","    for j in range(i + 1, len(a)):\n","        if a[j] != 0:\n","            return a[j]\n","    return None\n","\n","def left_value(a ,i):\n","    for j in range(0, i):\n","        if a[i - j - 1] != 0:\n","            return a[i - j - 1]\n","    return None\n","\n","def nearest_value(a, i):\n","    size = len(a)\n","    rvalue = right_value(a, i)\n","    lvalue = left_value(a, i)\n","\n","    if rvalue == None:\n","        if lvalue == None:\n","            return None\n","        else:\n","            return lvalue\n","    else:\n","        if lvalue == None:\n","            return rvalue\n","        else:\n","            return rvalue"],"metadata":{"id":"wjiioAsFyBvB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","class Data:\n","    def __init__(self, data_path='./train/', item_idx=0, split_ratio=0.2):\n","        # 파일 경로 ex) item_idx = 0인 경우, file_path='./train/train_0.csv'이다.\n","        file_path = os.path.join(data_path, f'train_{item_idx}.csv')\n","\n","        # csv 파일 읽기\n","        data_pd = pd.read_csv(file_path)\n","\n","        # 데이터 전처리\n","        for column in data_pd.columns:\n","            data_pd[column] = data_pd[column].replace({' ': np.nan})\n","        \n","        data_pd.drop(tr_del_list, axis=1, inplace=True)\n","        data_pd.set_index('datadate', drop=True, inplace=True)\n","\n","        data_pd = data_pd.fillna(0)\n","\n","        x_pd, y_pd = data_pd[[i for i in data_pd.columns if i != '해당일자_전체평균가격(원)']], data_pd['해당일자_전체평균가격(원)']\n","\n","        y_t = np.array(y_pd)\n","\n","        y_pd = y_pd[14:]\n","\n","        x_np = time_window(x_pd, 13, 1)\n","        y_np = time_window(y_pd, 27, 1)\n","\n","        x_np = x_np[:len(y_np)]\n","        y_np = y_np.reshape(-1, 28)\n","        print(len(x_np))\n","\n","        # 변동률 예측\n","        print(y_np[0])\n","        print(y_t[0])\n","        for i in range(len(y_np)):\n","            for j in range(28):\n","                if y_t[i] == 0:\n","                    value_t = nearest_value(y_t, i)\n","                else:\n","                    value_t = y_t[i]\n","\n","                y_np[i][j] = y_np[i][j] - value_t\n","                y_np[i][j] = y_np[i][j] / value_t\n","\n","        print(y_np[0])\n","        self.data = {\n","            'inputs': x_np,\n","            'labels': y_np,\n","        }\n","\n","        self.split_ratio = split_ratio\n","\n","        if self.split_ratio > 0:\n","            self.train_val_split()\n","    \n","    def train_val_split(self):\n","        x_train, x_val, y_train, y_val = train_test_split(\n","            self.data['inputs'],\n","            self.data['labels'],\n","            test_size=self.split_ratio,\n","            random_state=42\n","        )\n","\n","        self.train_data = (x_train, y_train)\n","        self.val_data = (x_val, y_val)\n","\n","    def get_train(self, use_tensor=False):\n","        if use_tensor:\n","            return torch.tensor(self.train_data[0], dtype=torch.float32), torch.tensor(self.train_data[1], dtype=torch.float32)\n","        else:\n","            return self.train_data\n","    \n","    def get_val(self, use_tensor=False):\n","        if use_tensor:\n","            return torch.tensor(self.val_data[0], dtype=torch.float32), torch.tensor(self.val_data[1], dtype=torch.float32)\n","        else:\n","            return self.val_data\n"],"metadata":{"id":"LLOC1y_2VFt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TestData:\n","    pass"],"metadata":{"id":"MocI4S-whFt5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = Data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7xSyn15pjXO","executionInfo":{"status":"ok","timestamp":1662535542100,"user_tz":-540,"elapsed":391,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"530ff8f8-3966-4622-d8ac-0dd80ac39c2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1419\n","[   0.     2916.061  2313.3643 3045.0603 3214.291  4387.5825 1631.7\n","    0.     2700.754  1101.2709    0.        0.        0.        0.\n","    0.        0.        0.     5475.074  2363.925  3093.0178 2249.058\n","    0.     2783.1553 1031.9697 3062.8455 2593.413  2983.8428 2347.6807]\n","0.0\n","[-0.99999994 -0.8592107  -0.88830936 -0.8529825  -0.844812   -0.78816473\n"," -0.9212205  -0.99999994 -0.8696059  -0.94683    -0.99999994 -0.99999994\n"," -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.73566\n"," -0.88586825 -0.8506671  -0.8914141  -0.99999994 -0.8656275  -0.9501759\n"," -0.85212386 -0.8747884  -0.8559382  -0.8866525 ]\n"]}]},{"cell_type":"code","source":["class TorchDataset(Dataset):\n","    def __init__(self, x_tensor, y_tensor):\n","        super().__init__()\n","        self.x = x_tensor\n","        self.y = y_tensor\n","    \n","    def __getitem__(self, idx):\n","        return self.x[idx], self.y[idx]\n","    \n","    def __len__(self):\n","        return len(self.x)"],"metadata":{"id":"cQduGxt-fGB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Flag:\n","    def __init__(self, flags):\n","        for key, value in flags.items():\n","            if isinstance(value, dict):\n","                self.__dict__[key] = Flag(value)\n","            else:\n","                self.__dict__[key] = value"],"metadata":{"id":"BlE4M4NchChq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_val(flags):\n","    name = flags['name']\n","\n","    wandb.init(\n","        project=\"Nong_Linear\",\n","        entity='deep-overflow',\n","        config=flags,\n","        name=name\n","    )\n","\n","    flags = Flag(flags)\n","\n","    for item_idx in range(37):\n","        data = Data(item_idx=item_idx)\n","\n","        # Data\n","        train_data = data.get_train(use_tensor=True)\n","        val_data = data.get_val(use_tensor=True)\n","        \n","        # Dataset\n","        train_dataset = TorchDataset(train_data[0], train_data[1])\n","        val_dataset = TorchDataset(val_data[0], val_data[1])\n","\n","        # Dataloader\n","        train_dataloader = DataLoader(\n","            dataset=train_dataset,\n","            batch_size=flags.batch_size,\n","            shuffle=True\n","        )\n","        val_dataloader = DataLoader(\n","            dataset=val_dataset,\n","            batch_size=flags.batch_size,\n","            shuffle=False\n","        )\n","\n","        for inputs, labels in train_dataloader:\n","            print(inputs.shape)\n","            print(labels.shape)\n","            break\n","\n","        net = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(14 * 49, flags.model.hid_dim),\n","            nn.BatchNorm1d(flags.model.hid_dim),\n","            nn.ReLU(),\n","            nn.Dropout(flags.dropout),\n","        )\n","\n","        for _ in range(flags.model.nlayers - 2):\n","            net.append(nn.Linear(flags.model.hid_dim, flags.model.hid_dim))\n","            # net.append(nn.BatchNorm1d(flags.model.hid_dim))\n","            net.append(nn.ReLU())\n","            net.append(nn.Dropout(flags.dropout))\n","        \n","        net.append(nn.Linear(flags.model.hid_dim, 28))\n","\n","        for name, param in net.named_parameters():\n","            if name.split('.')[-1] == 'bias':\n","                continue\n","            nn.init.xavier_uniform_(param)\n","\n","        criterion = nn.L1Loss()\n","\n","        optimizer = optim.Adam(\n","            params=net.parameters(), \n","            lr=flags.lr,\n","            betas=(0.9, 0.999),\n","        )\n","\n","        def lr_schedule_fn(epoch):\n","            if epoch < 15:\n","                return 1.5 # 1e-4 * 1.5\n","            elif epoch >= 15 and epoch < 250:\n","                return 1.0\n","            elif epoch >= 250 and epoch < 350:\n","                return 1.5\n","            else:\n","                return 1.0\n","\n","        scheduler = lr_scheduler.LambdaLR(\n","            optimizer=optimizer,\n","            lr_lambda=lr_schedule_fn\n","        )\n","\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","        net = net.to(device)\n","\n","        best_val_loss = 987654321.0\n","\n","        for epoch in range(flags.epochs):\n","            epoch_train_loss = 0.0\n","\n","            for inputs, labels in train_dataloader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                with torch.set_grad_enabled(True):\n","                    outputs = net(inputs)\n","                    loss = criterion(outputs, labels)\n","                \n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                epoch_train_loss += loss.item()\n","            \n","            scheduler.step()\n","\n","            if (epoch + 1) % 10 == 0:\n","                print(f'[epoch : {epoch + 1} / {flags.epochs}] Train Loss : {epoch_train_loss / len(train_dataloader)}')\n","\n","            epoch_val_loss = 0.0\n","\n","            for inputs, labels in val_dataloader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                with torch.no_grad():\n","                    outputs = net(inputs)\n","                    loss = criterion(outputs, labels)\n","                \n","                epoch_val_loss += loss.item()\n","            \n","            wandb.log({\n","                'train_loss': epoch_train_loss / len(train_dataloader),\n","                'train_lr': optimizer.param_groups[0]['lr'],\n","                'val_loss': epoch_val_loss / len(val_dataloader),\n","            })\n","\n","            val_loss = epoch_val_loss / len(val_dataloader)\n","\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                print(f'Save item: {item_idx} / best_val_loss: {best_val_loss}')\n","                torch.save(net.state_dict(), f'./model_weights_{name}_{item_idx}.pth')\n","\n","flags = {\n","    'name': 'Exp_val_y_variance_001',\n","    'epochs': 500,\n","    'lr': 1e-4,\n","    'batch_size': 64,\n","    'data_num': 0,\n","    'model': {\n","        'activation': 'relu',\n","        'nlayers': 10,\n","        'use_BatchNorm': True,\n","        'hid_dim': 1024,\n","        'weight_init': 'xavier_uniform'\n","    },\n","    'optim': 'Adam',\n","    'criterion': 'L1Loss',\n","    'dropout': 0.5,\n","    'lr_scheduler': {\n","        'method': 'Lambda'\n","    }\n","}\n","\n","train_and_val(flags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["76a5168ee17c4048a8fb5febc3c61265","8455cf5e6c514d9fb04b855f84fb466f","9a6f18999aaf43dd8f8e71b641a8a83f","658922dce49b47138b34d63fa6876b1b","b73f0f0f5f7240bf8a45f63d56c1451f","9abd3a8afc004f9f88c3bb9a8e581d78","1ee7bd3966bb44c987dadb899a1e912f","6614c43fbc764634808605fdc80e4e0b"]},"id":"aJhl7IIFZKsu","executionInfo":{"status":"ok","timestamp":1662538588227,"user_tz":-540,"elapsed":3028913,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"377c075e-71e4-4a1c-b8ed-88a8b3392e30"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:1p43op67) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76a5168ee17c4048a8fb5febc3c61265"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>████████▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_lr</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>████████▃▂▂▁▃▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>135.09823</td></tr><tr><td>train_lr</td><td>0.0001</td></tr><tr><td>val_loss</td><td>187.83022</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">Exp_val_y_variance_001</strong>: <a href=\"https://wandb.ai/deep-overflow/Nong_Linear/runs/1p43op67\" target=\"_blank\">https://wandb.ai/deep-overflow/Nong_Linear/runs/1p43op67</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220907_070139-1p43op67/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:1p43op67). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/data/aT/scaled_data/wandb/run-20220907_072559-2tljlcx6</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/deep-overflow/Nong_Linear/runs/2tljlcx6\" target=\"_blank\">Exp_val_y_variance_001</a></strong> to <a href=\"https://wandb.ai/deep-overflow/Nong_Linear\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1419\n","[   0.     2916.061  2313.3643 3045.0603 3214.291  4387.5825 1631.7\n","    0.     2700.754  1101.2709    0.        0.        0.        0.\n","    0.        0.        0.     5475.074  2363.925  3093.0178 2249.058\n","    0.     2783.1553 1031.9697 3062.8455 2593.413  2983.8428 2347.6807]\n","0.0\n","[-0.99999994 -0.8592107  -0.88830936 -0.8529825  -0.844812   -0.78816473\n"," -0.9212205  -0.99999994 -0.8696059  -0.94683    -0.99999994 -0.99999994\n"," -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.73566\n"," -0.88586825 -0.8506671  -0.8914141  -0.99999994 -0.8656275  -0.9501759\n"," -0.85212386 -0.8747884  -0.8559382  -0.8866525 ]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 0 / best_val_loss: 0.4793683111667633\n","Save item: 0 / best_val_loss: 0.47562294602394106\n","Save item: 0 / best_val_loss: 0.4753348231315613\n","Save item: 0 / best_val_loss: 0.4729121387004852\n","Save item: 0 / best_val_loss: 0.4726067900657654\n","Save item: 0 / best_val_loss: 0.4712198436260223\n","Save item: 0 / best_val_loss: 0.47005838751792905\n","[epoch : 10 / 500] Train Loss : 0.4675909959607654\n","Save item: 0 / best_val_loss: 0.4673188030719757\n","Save item: 0 / best_val_loss: 0.4662100374698639\n","Save item: 0 / best_val_loss: 0.45876807570457456\n","Save item: 0 / best_val_loss: 0.4522188365459442\n","Save item: 0 / best_val_loss: 0.45077313780784606\n","Save item: 0 / best_val_loss: 0.44361971616744994\n","Save item: 0 / best_val_loss: 0.44035778045654295\n","Save item: 0 / best_val_loss: 0.43621826171875\n","[epoch : 20 / 500] Train Loss : 0.438855583469073\n","Save item: 0 / best_val_loss: 0.42933606505393984\n","Save item: 0 / best_val_loss: 0.42829737067222595\n","Save item: 0 / best_val_loss: 0.42687988877296446\n","Save item: 0 / best_val_loss: 0.42333164215087893\n","Save item: 0 / best_val_loss: 0.4215892910957336\n","[epoch : 30 / 500] Train Loss : 0.4245860626300176\n","Save item: 0 / best_val_loss: 0.4183006942272186\n","Save item: 0 / best_val_loss: 0.4159685432910919\n","[epoch : 40 / 500] Train Loss : 0.41092103057437473\n","Save item: 0 / best_val_loss: 0.41248713731765746\n","[epoch : 50 / 500] Train Loss : 0.4034106449948417\n","[epoch : 60 / 500] Train Loss : 0.3972548974884881\n","Save item: 0 / best_val_loss: 0.40897743701934813\n","[epoch : 70 / 500] Train Loss : 0.39283061027526855\n","[epoch : 80 / 500] Train Loss : 0.38850848707887864\n","[epoch : 90 / 500] Train Loss : 0.38300219343768227\n","Save item: 0 / best_val_loss: 0.40486255288124084\n","[epoch : 100 / 500] Train Loss : 0.3798040300607681\n","[epoch : 110 / 500] Train Loss : 0.37748634318510693\n","[epoch : 120 / 500] Train Loss : 0.37331008083290523\n","[epoch : 130 / 500] Train Loss : 0.37191061509980095\n","[epoch : 140 / 500] Train Loss : 0.37212125294738346\n","[epoch : 150 / 500] Train Loss : 0.37002680864599014\n","[epoch : 160 / 500] Train Loss : 0.36863502197795445\n","Save item: 0 / best_val_loss: 0.40462514758110046\n","[epoch : 170 / 500] Train Loss : 0.36837317049503326\n","[epoch : 180 / 500] Train Loss : 0.36523810029029846\n","[epoch : 190 / 500] Train Loss : 0.3634966280725267\n","[epoch : 200 / 500] Train Loss : 0.3618306583828396\n","[epoch : 210 / 500] Train Loss : 0.36426276134120095\n","[epoch : 220 / 500] Train Loss : 0.3635343809922536\n","[epoch : 230 / 500] Train Loss : 0.3590820911857817\n","[epoch : 240 / 500] Train Loss : 0.36102616290251416\n","[epoch : 250 / 500] Train Loss : 0.3611188299126095\n","Save item: 0 / best_val_loss: 0.4044030547142029\n","Save item: 0 / best_val_loss: 0.40438978672027587\n","Save item: 0 / best_val_loss: 0.40362854599952697\n","Save item: 0 / best_val_loss: 0.4018054246902466\n","[epoch : 260 / 500] Train Loss : 0.3654315388864941\n","[epoch : 270 / 500] Train Loss : 0.3641656090815862\n","Save item: 0 / best_val_loss: 0.40175879597663877\n","[epoch : 280 / 500] Train Loss : 0.3622800095213784\n","[epoch : 290 / 500] Train Loss : 0.36143841677241856\n","[epoch : 300 / 500] Train Loss : 0.36116736630598706\n","[epoch : 310 / 500] Train Loss : 0.36069759560955894\n","Save item: 0 / best_val_loss: 0.40061567425727845\n","[epoch : 320 / 500] Train Loss : 0.3596857488155365\n","[epoch : 330 / 500] Train Loss : 0.3584774997499254\n","[epoch : 340 / 500] Train Loss : 0.3632788128323025\n","[epoch : 350 / 500] Train Loss : 0.35854046377870774\n","Save item: 0 / best_val_loss: 0.39895530939102175\n","[epoch : 360 / 500] Train Loss : 0.3572664674785402\n","Save item: 0 / best_val_loss: 0.3979846954345703\n","Save item: 0 / best_val_loss: 0.39618468284606934\n","[epoch : 370 / 500] Train Loss : 0.35616577168305713\n","[epoch : 380 / 500] Train Loss : 0.35496023959583706\n","Save item: 0 / best_val_loss: 0.39565996527671815\n","[epoch : 390 / 500] Train Loss : 0.3543338163031472\n","[epoch : 400 / 500] Train Loss : 0.3556657052702374\n","[epoch : 410 / 500] Train Loss : 0.35832758247852325\n","[epoch : 420 / 500] Train Loss : 0.3540618386533525\n","Save item: 0 / best_val_loss: 0.39366295337677004\n","[epoch : 430 / 500] Train Loss : 0.35490979419814217\n","[epoch : 440 / 500] Train Loss : 0.35398533443609875\n","[epoch : 450 / 500] Train Loss : 0.3529132505257924\n","[epoch : 460 / 500] Train Loss : 0.35367253919442493\n","[epoch : 470 / 500] Train Loss : 0.3544598122437795\n","[epoch : 480 / 500] Train Loss : 0.3530813041660521\n","[epoch : 490 / 500] Train Loss : 0.35638365646203357\n","[epoch : 500 / 500] Train Loss : 0.35299460258748794\n","1419\n","[   0.     1232.3533 1176.3842 1192.7048 1191.3949 1114.1569 1167.2227\n","    0.     1200.7931 1168.7917    0.        0.        0.        0.\n","    0.        0.        0.     1216.8458 1258.1359 1254.8438 1318.8473\n","    0.     1325.7219 1285.0006 1266.0402 1235.1729 1306.7786 1343.717 ]\n","0.0\n","[-1.         -0.02246688 -0.06686297 -0.053917   -0.05495607 -0.1162232\n"," -0.0741301  -1.         -0.04750119 -0.07288545 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.03476777\n"," -0.00201549 -0.00462687  0.04614232 -1.          0.05159545  0.0192943\n","  0.0042544  -0.02023032  0.03656911  0.06586962]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 1 / best_val_loss: 0.3156004071235657\n","Save item: 1 / best_val_loss: 0.30896381139755247\n","Save item: 1 / best_val_loss: 0.3074305295944214\n","Save item: 1 / best_val_loss: 0.3069086968898773\n","Save item: 1 / best_val_loss: 0.3064582645893097\n","Save item: 1 / best_val_loss: 0.3060642659664154\n","Save item: 1 / best_val_loss: 0.30606378316879274\n","Save item: 1 / best_val_loss: 0.3052081882953644\n","[epoch : 10 / 500] Train Loss : 0.30850165916813743\n","Save item: 1 / best_val_loss: 0.30460222363471984\n","Save item: 1 / best_val_loss: 0.3043780386447906\n","Save item: 1 / best_val_loss: 0.30372430086135865\n","Save item: 1 / best_val_loss: 0.3000361561775208\n","Save item: 1 / best_val_loss: 0.2910165548324585\n","Save item: 1 / best_val_loss: 0.2821956992149353\n","Save item: 1 / best_val_loss: 0.2770590364933014\n","Save item: 1 / best_val_loss: 0.2748014986515045\n","[epoch : 20 / 500] Train Loss : 0.27452952166398364\n","Save item: 1 / best_val_loss: 0.27395779490470884\n","Save item: 1 / best_val_loss: 0.27152042388916015\n","Save item: 1 / best_val_loss: 0.26743667125701903\n","Save item: 1 / best_val_loss: 0.26536800861358645\n","Save item: 1 / best_val_loss: 0.2628936171531677\n","[epoch : 30 / 500] Train Loss : 0.2596515988310178\n","Save item: 1 / best_val_loss: 0.2619647741317749\n","Save item: 1 / best_val_loss: 0.25999532341957093\n","Save item: 1 / best_val_loss: 0.25770107209682463\n","Save item: 1 / best_val_loss: 0.25688947141170504\n","Save item: 1 / best_val_loss: 0.256067281961441\n","Save item: 1 / best_val_loss: 0.2556060433387756\n","[epoch : 40 / 500] Train Loss : 0.25330614298582077\n","Save item: 1 / best_val_loss: 0.254401883482933\n","Save item: 1 / best_val_loss: 0.251990869641304\n","Save item: 1 / best_val_loss: 0.250925749540329\n","[epoch : 50 / 500] Train Loss : 0.24661563667986128\n","Save item: 1 / best_val_loss: 0.24913467168807985\n","Save item: 1 / best_val_loss: 0.2473254233598709\n","[epoch : 60 / 500] Train Loss : 0.2410113513469696\n","[epoch : 70 / 500] Train Loss : 0.23814203259017733\n","Save item: 1 / best_val_loss: 0.24450457096099854\n","Save item: 1 / best_val_loss: 0.24391282200813294\n","Save item: 1 / best_val_loss: 0.24386164247989656\n","Save item: 1 / best_val_loss: 0.24300522208213807\n","[epoch : 80 / 500] Train Loss : 0.2372665380438169\n","Save item: 1 / best_val_loss: 0.24172476828098297\n","[epoch : 90 / 500] Train Loss : 0.2356459606024954\n","Save item: 1 / best_val_loss: 0.24062632620334626\n","Save item: 1 / best_val_loss: 0.2404804915189743\n","[epoch : 100 / 500] Train Loss : 0.233007008002864\n","Save item: 1 / best_val_loss: 0.2394385367631912\n","Save item: 1 / best_val_loss: 0.23781927824020385\n","[epoch : 110 / 500] Train Loss : 0.2315765900744332\n","[epoch : 120 / 500] Train Loss : 0.23166794495450127\n","[epoch : 130 / 500] Train Loss : 0.2304282925195164\n","Save item: 1 / best_val_loss: 0.23709308803081514\n","[epoch : 140 / 500] Train Loss : 0.22936731080214182\n","Save item: 1 / best_val_loss: 0.23647723495960235\n","Save item: 1 / best_val_loss: 0.23535919785499573\n","[epoch : 150 / 500] Train Loss : 0.22934860487778982\n","[epoch : 160 / 500] Train Loss : 0.2295839637517929\n","Save item: 1 / best_val_loss: 0.2347408264875412\n","[epoch : 170 / 500] Train Loss : 0.22742488814724815\n","[epoch : 180 / 500] Train Loss : 0.22737977157036462\n","[epoch : 190 / 500] Train Loss : 0.22824889752599928\n","[epoch : 200 / 500] Train Loss : 0.22782904240820143\n","Save item: 1 / best_val_loss: 0.23434733152389525\n","[epoch : 210 / 500] Train Loss : 0.22573229918877283\n","[epoch : 220 / 500] Train Loss : 0.22615880022446314\n","Save item: 1 / best_val_loss: 0.23347921371459962\n","[epoch : 230 / 500] Train Loss : 0.22677100863721636\n","[epoch : 240 / 500] Train Loss : 0.22560040901104608\n","[epoch : 250 / 500] Train Loss : 0.22611472755670547\n","[epoch : 260 / 500] Train Loss : 0.22721097121636072\n","[epoch : 270 / 500] Train Loss : 0.22671363171603945\n","[epoch : 280 / 500] Train Loss : 0.22714611970716053\n","[epoch : 290 / 500] Train Loss : 0.22615542014439902\n","[epoch : 300 / 500] Train Loss : 0.2265467726522022\n","Save item: 1 / best_val_loss: 0.2334595263004303\n","[epoch : 310 / 500] Train Loss : 0.22468304302957323\n","[epoch : 320 / 500] Train Loss : 0.22555652177996105\n","[epoch : 330 / 500] Train Loss : 0.22521722316741943\n","[epoch : 340 / 500] Train Loss : 0.22527951333257887\n","Save item: 1 / best_val_loss: 0.23274621665477752\n","[epoch : 350 / 500] Train Loss : 0.22453855474789938\n","Save item: 1 / best_val_loss: 0.23191943168640136\n","[epoch : 360 / 500] Train Loss : 0.22242174959845012\n","[epoch : 370 / 500] Train Loss : 0.22341607097122404\n","Save item: 1 / best_val_loss: 0.2317964106798172\n","[epoch : 380 / 500] Train Loss : 0.2229302061928643\n","Save item: 1 / best_val_loss: 0.23053916692733764\n","[epoch : 390 / 500] Train Loss : 0.22309366282489565\n","[epoch : 400 / 500] Train Loss : 0.22278500099976858\n","[epoch : 410 / 500] Train Loss : 0.2225861276189486\n","[epoch : 420 / 500] Train Loss : 0.22321143332454893\n","[epoch : 430 / 500] Train Loss : 0.22149567140473259\n","Save item: 1 / best_val_loss: 0.22995052933692933\n","[epoch : 440 / 500] Train Loss : 0.2216561602221595\n","[epoch : 450 / 500] Train Loss : 0.22194894817140368\n","[epoch : 460 / 500] Train Loss : 0.2222148593929079\n","[epoch : 470 / 500] Train Loss : 0.22180046223931843\n","[epoch : 480 / 500] Train Loss : 0.22171205447779763\n","[epoch : 490 / 500] Train Loss : 0.2226926080054707\n","[epoch : 500 / 500] Train Loss : 0.22165252019961676\n","1419\n","[   0.     1445.0253 1331.2527 1398.677  1418.0869 1305.1617 1354.8763\n","    0.     1464.3568 1402.2251    0.        0.        0.        0.\n","    0.        0.        0.     1588.4657 1565.3768 1561.0583 1589.7758\n","    0.     1618.9556 1531.042  1588.6707 1530.0771 1567.5485 1447.6915]\n","0.0\n","[-1.         -0.02127745 -0.09833617 -0.05266936 -0.03952293 -0.11600769\n"," -0.08233576 -1.         -0.00818411 -0.05026621 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.07587544\n","  0.06023724  0.05731231  0.07676274 -1.          0.09652637  0.03698208\n","  0.07601426  0.03632859  0.06170809 -0.01947158]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 2 / best_val_loss: 0.28025984168052676\n","Save item: 2 / best_val_loss: 0.2738227844238281\n","Save item: 2 / best_val_loss: 0.27327737808227537\n","Save item: 2 / best_val_loss: 0.272070038318634\n","Save item: 2 / best_val_loss: 0.27178957462310793\n","Save item: 2 / best_val_loss: 0.2712328314781189\n","Save item: 2 / best_val_loss: 0.2705420136451721\n","[epoch : 10 / 500] Train Loss : 0.2697351690795686\n","Save item: 2 / best_val_loss: 0.2699737012386322\n","Save item: 2 / best_val_loss: 0.26956872940063475\n","Save item: 2 / best_val_loss: 0.26908987760543823\n","Save item: 2 / best_val_loss: 0.2676978290081024\n","Save item: 2 / best_val_loss: 0.2662639856338501\n","Save item: 2 / best_val_loss: 0.2638827502727509\n","Save item: 2 / best_val_loss: 0.26259165406227114\n","Save item: 2 / best_val_loss: 0.25824353098869324\n","Save item: 2 / best_val_loss: 0.25783050060272217\n","Save item: 2 / best_val_loss: 0.25601696968078613\n","[epoch : 20 / 500] Train Loss : 0.25667999933163327\n","Save item: 2 / best_val_loss: 0.2519328147172928\n","Save item: 2 / best_val_loss: 0.24967587888240814\n","Save item: 2 / best_val_loss: 0.24933451116085054\n","Save item: 2 / best_val_loss: 0.24832056760787963\n","Save item: 2 / best_val_loss: 0.24720852077007294\n","[epoch : 30 / 500] Train Loss : 0.24944991370042166\n","Save item: 2 / best_val_loss: 0.24476904571056365\n","Save item: 2 / best_val_loss: 0.2433996468782425\n","Save item: 2 / best_val_loss: 0.2405596613883972\n","[epoch : 40 / 500] Train Loss : 0.242970815135373\n","Save item: 2 / best_val_loss: 0.23984207808971406\n","Save item: 2 / best_val_loss: 0.23981556594371795\n","Save item: 2 / best_val_loss: 0.23781878650188445\n","[epoch : 50 / 500] Train Loss : 0.23813143372535706\n","Save item: 2 / best_val_loss: 0.23744135797023774\n","Save item: 2 / best_val_loss: 0.23657151758670808\n","Save item: 2 / best_val_loss: 0.2363283544778824\n","[epoch : 60 / 500] Train Loss : 0.2331276742948426\n","Save item: 2 / best_val_loss: 0.23401200771331787\n","Save item: 2 / best_val_loss: 0.23396748602390288\n","Save item: 2 / best_val_loss: 0.23317984044551848\n","Save item: 2 / best_val_loss: 0.23291527032852172\n","[epoch : 70 / 500] Train Loss : 0.2302280076675945\n","Save item: 2 / best_val_loss: 0.23281319737434386\n","Save item: 2 / best_val_loss: 0.23188005685806273\n","Save item: 2 / best_val_loss: 0.23160272538661958\n","Save item: 2 / best_val_loss: 0.23027853071689605\n","Save item: 2 / best_val_loss: 0.22885054349899292\n","[epoch : 80 / 500] Train Loss : 0.2267693438463741\n","[epoch : 90 / 500] Train Loss : 0.2248164696825875\n","Save item: 2 / best_val_loss: 0.22852082550525665\n","Save item: 2 / best_val_loss: 0.22767916619777678\n","[epoch : 100 / 500] Train Loss : 0.22271162023146948\n","Save item: 2 / best_val_loss: 0.22559196054935454\n","[epoch : 110 / 500] Train Loss : 0.22196990996599197\n","[epoch : 120 / 500] Train Loss : 0.220331233408716\n","[epoch : 130 / 500] Train Loss : 0.21894689400990805\n","Save item: 2 / best_val_loss: 0.22556244134902953\n","[epoch : 140 / 500] Train Loss : 0.21879633184936312\n","Save item: 2 / best_val_loss: 0.2249348819255829\n","[epoch : 150 / 500] Train Loss : 0.21780319346321952\n","Save item: 2 / best_val_loss: 0.2248169869184494\n","Save item: 2 / best_val_loss: 0.22465945184230804\n","[epoch : 160 / 500] Train Loss : 0.21791048596302667\n","[epoch : 170 / 500] Train Loss : 0.21651184310515723\n","Save item: 2 / best_val_loss: 0.2244158834218979\n","[epoch : 180 / 500] Train Loss : 0.21619275046719444\n","Save item: 2 / best_val_loss: 0.22400382161140442\n","Save item: 2 / best_val_loss: 0.22386723160743713\n","Save item: 2 / best_val_loss: 0.22219208776950836\n","[epoch : 190 / 500] Train Loss : 0.2157234193550216\n","[epoch : 200 / 500] Train Loss : 0.216152869992786\n","[epoch : 210 / 500] Train Loss : 0.21483557505740059\n","[epoch : 220 / 500] Train Loss : 0.21578666898939344\n","[epoch : 230 / 500] Train Loss : 0.2141644855340322\n","[epoch : 240 / 500] Train Loss : 0.21486748341057035\n","Save item: 2 / best_val_loss: 0.22159209251403808\n","[epoch : 250 / 500] Train Loss : 0.21409621669186485\n","[epoch : 260 / 500] Train Loss : 0.21503167516655392\n","Save item: 2 / best_val_loss: 0.22099463045597076\n","Save item: 2 / best_val_loss: 0.22099030017852783\n","[epoch : 270 / 500] Train Loss : 0.21453155659967\n","[epoch : 280 / 500] Train Loss : 0.21459982792536417\n","[epoch : 290 / 500] Train Loss : 0.21396086613337198\n","[epoch : 300 / 500] Train Loss : 0.21461930208735996\n","[epoch : 310 / 500] Train Loss : 0.21439312564002144\n","[epoch : 320 / 500] Train Loss : 0.2134974574049314\n","[epoch : 330 / 500] Train Loss : 0.21361996647384432\n","[epoch : 340 / 500] Train Loss : 0.2140260645084911\n","[epoch : 350 / 500] Train Loss : 0.21271061069435543\n","[epoch : 360 / 500] Train Loss : 0.2124063124259313\n","Save item: 2 / best_val_loss: 0.22074513435363768\n","Save item: 2 / best_val_loss: 0.2200248658657074\n","[epoch : 370 / 500] Train Loss : 0.2121287402179506\n","[epoch : 380 / 500] Train Loss : 0.21171836886141035\n","[epoch : 390 / 500] Train Loss : 0.2117403613196479\n","[epoch : 400 / 500] Train Loss : 0.21144851297140121\n","Save item: 2 / best_val_loss: 0.21968962848186493\n","[epoch : 410 / 500] Train Loss : 0.2117216255929735\n","[epoch : 420 / 500] Train Loss : 0.2115159018172158\n","[epoch : 430 / 500] Train Loss : 0.21068993128008312\n","[epoch : 440 / 500] Train Loss : 0.21158363835679161\n","[epoch : 450 / 500] Train Loss : 0.2114105522632599\n","[epoch : 460 / 500] Train Loss : 0.21114827609724468\n","[epoch : 470 / 500] Train Loss : 0.21087336291869482\n","[epoch : 480 / 500] Train Loss : 0.21130362898111343\n","[epoch : 490 / 500] Train Loss : 0.21060747901598612\n","[epoch : 500 / 500] Train Loss : 0.21089825448062685\n","1419\n","[   0.     2616.6643 2532.117  2549.3997 2480.042  2496.8767 2436.5605\n"," 2739.4766 2430.3171 2536.6975    0.        0.        0.        0.\n","    0.        0.        0.     2070.8708 1941.6772 1997.7849 1904.2301\n","    0.     1958.1448 1781.4716 1801.174  1691.1559 1765.2787 1834.91  ]\n","0.0\n","[-1.          0.29967487  0.25768092  0.2662651   0.23181573  0.2401774\n","  0.21021886  0.36067468  0.20711781  0.25995606 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.02858391\n"," -0.03558545 -0.00771725 -0.05418513 -1.         -0.02740617 -0.11515826\n"," -0.10537224 -0.16001728 -0.12320112 -0.08861582]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 3 / best_val_loss: 0.3324018895626068\n","Save item: 3 / best_val_loss: 0.3254913091659546\n","Save item: 3 / best_val_loss: 0.3237248659133911\n","Save item: 3 / best_val_loss: 0.3234141945838928\n","Save item: 3 / best_val_loss: 0.32225643992424013\n","Save item: 3 / best_val_loss: 0.3220649480819702\n","[epoch : 10 / 500] Train Loss : 0.32685329020023346\n","Save item: 3 / best_val_loss: 0.32200143337249754\n","Save item: 3 / best_val_loss: 0.3216561019420624\n","Save item: 3 / best_val_loss: 0.3214587509632111\n","Save item: 3 / best_val_loss: 0.3212228655815125\n","Save item: 3 / best_val_loss: 0.32008519768714905\n","Save item: 3 / best_val_loss: 0.31979863047599794\n","Save item: 3 / best_val_loss: 0.3193269014358521\n","Save item: 3 / best_val_loss: 0.31625367403030397\n","Save item: 3 / best_val_loss: 0.31332972049713137\n","[epoch : 20 / 500] Train Loss : 0.31119123763508266\n","Save item: 3 / best_val_loss: 0.3091385722160339\n","Save item: 3 / best_val_loss: 0.30735993981361387\n","Save item: 3 / best_val_loss: 0.3044873595237732\n","Save item: 3 / best_val_loss: 0.30318406224250793\n","Save item: 3 / best_val_loss: 0.3001242220401764\n","Save item: 3 / best_val_loss: 0.2961237609386444\n","Save item: 3 / best_val_loss: 0.29457093477249147\n","Save item: 3 / best_val_loss: 0.2944286346435547\n","Save item: 3 / best_val_loss: 0.29185418486595155\n","[epoch : 30 / 500] Train Loss : 0.2856655807958709\n","Save item: 3 / best_val_loss: 0.2911102116107941\n","Save item: 3 / best_val_loss: 0.2896856129169464\n","Save item: 3 / best_val_loss: 0.28889173865318296\n","Save item: 3 / best_val_loss: 0.28797360956668855\n","Save item: 3 / best_val_loss: 0.2843642354011536\n","Save item: 3 / best_val_loss: 0.2806472688913345\n","Save item: 3 / best_val_loss: 0.2802229940891266\n","[epoch : 40 / 500] Train Loss : 0.27215104301770526\n","Save item: 3 / best_val_loss: 0.2796868860721588\n","Save item: 3 / best_val_loss: 0.2786412984132767\n","Save item: 3 / best_val_loss: 0.2772354960441589\n","Save item: 3 / best_val_loss: 0.2762839883565903\n","Save item: 3 / best_val_loss: 0.2745242178440094\n","[epoch : 50 / 500] Train Loss : 0.2642555865976546\n","Save item: 3 / best_val_loss: 0.273673415184021\n","Save item: 3 / best_val_loss: 0.27146042585372926\n","Save item: 3 / best_val_loss: 0.2693293929100037\n","[epoch : 60 / 500] Train Loss : 0.2600056603550911\n","Save item: 3 / best_val_loss: 0.26804632544517515\n","Save item: 3 / best_val_loss: 0.26784915030002593\n","Save item: 3 / best_val_loss: 0.2661690145730972\n","[epoch : 70 / 500] Train Loss : 0.25869935833745533\n","Save item: 3 / best_val_loss: 0.2647317111492157\n","[epoch : 80 / 500] Train Loss : 0.25428512112961876\n","Save item: 3 / best_val_loss: 0.26342144012451174\n","Save item: 3 / best_val_loss: 0.2632357895374298\n","[epoch : 90 / 500] Train Loss : 0.2504028512371911\n","Save item: 3 / best_val_loss: 0.26249544620513915\n","Save item: 3 / best_val_loss: 0.2610223740339279\n","[epoch : 100 / 500] Train Loss : 0.2487483893831571\n","Save item: 3 / best_val_loss: 0.2588990718126297\n","[epoch : 110 / 500] Train Loss : 0.24660341193278631\n","Save item: 3 / best_val_loss: 0.25877344608306885\n","[epoch : 120 / 500] Train Loss : 0.24620388696591058\n","Save item: 3 / best_val_loss: 0.25854999721050265\n","Save item: 3 / best_val_loss: 0.2549066662788391\n","[epoch : 130 / 500] Train Loss : 0.24475306106938255\n","Save item: 3 / best_val_loss: 0.2547179192304611\n","[epoch : 140 / 500] Train Loss : 0.24406790650553173\n","[epoch : 150 / 500] Train Loss : 0.24349832203653124\n","[epoch : 160 / 500] Train Loss : 0.2422681376338005\n","[epoch : 170 / 500] Train Loss : 0.24125096201896667\n","Save item: 3 / best_val_loss: 0.2545228213071823\n","[epoch : 180 / 500] Train Loss : 0.24181674669186273\n","Save item: 3 / best_val_loss: 0.25329189002513885\n","[epoch : 190 / 500] Train Loss : 0.2423432303799523\n","[epoch : 200 / 500] Train Loss : 0.2400278788473871\n","[epoch : 210 / 500] Train Loss : 0.24069586644570032\n","[epoch : 220 / 500] Train Loss : 0.24060582369565964\n","[epoch : 230 / 500] Train Loss : 0.2384126385052999\n","[epoch : 240 / 500] Train Loss : 0.23946731206443575\n","[epoch : 250 / 500] Train Loss : 0.23775451299217013\n","Save item: 3 / best_val_loss: 0.25186977386474607\n","[epoch : 260 / 500] Train Loss : 0.23994843744569355\n","[epoch : 270 / 500] Train Loss : 0.23995744602547753\n","[epoch : 280 / 500] Train Loss : 0.23977459304862553\n","Save item: 3 / best_val_loss: 0.2517751485109329\n","[epoch : 290 / 500] Train Loss : 0.23987761471006605\n","Save item: 3 / best_val_loss: 0.2509835630655289\n","[epoch : 300 / 500] Train Loss : 0.24038304719660017\n","[epoch : 310 / 500] Train Loss : 0.2386731637848748\n","Save item: 3 / best_val_loss: 0.25060057640075684\n","[epoch : 320 / 500] Train Loss : 0.23895028150743908\n","Save item: 3 / best_val_loss: 0.249839386343956\n","[epoch : 330 / 500] Train Loss : 0.23744391318824556\n","[epoch : 340 / 500] Train Loss : 0.23824663708607355\n","[epoch : 350 / 500] Train Loss : 0.23727295216586855\n","[epoch : 360 / 500] Train Loss : 0.2361849124232928\n","Save item: 3 / best_val_loss: 0.24935316145420075\n","[epoch : 370 / 500] Train Loss : 0.23607728878657022\n","Save item: 3 / best_val_loss: 0.24826455414295195\n","[epoch : 380 / 500] Train Loss : 0.23430582053131527\n","[epoch : 390 / 500] Train Loss : 0.23708713468578127\n","[epoch : 400 / 500] Train Loss : 0.2349627067645391\n","[epoch : 410 / 500] Train Loss : 0.2355695739388466\n","[epoch : 420 / 500] Train Loss : 0.23542123950190014\n","[epoch : 430 / 500] Train Loss : 0.23417421761486265\n","Save item: 3 / best_val_loss: 0.24810074269771576\n","[epoch : 440 / 500] Train Loss : 0.23402568532360923\n","Save item: 3 / best_val_loss: 0.24723035097122192\n","[epoch : 450 / 500] Train Loss : 0.233747445874744\n","Save item: 3 / best_val_loss: 0.24601617753505706\n","[epoch : 460 / 500] Train Loss : 0.23423423369725546\n","[epoch : 470 / 500] Train Loss : 0.2337924987077713\n","[epoch : 480 / 500] Train Loss : 0.23374125609795252\n","Save item: 3 / best_val_loss: 0.2446945309638977\n","[epoch : 490 / 500] Train Loss : 0.23270770907402039\n","[epoch : 500 / 500] Train Loss : 0.23332669337590536\n","1419\n","[   0.     1957.4884 1928.9612 1945.7856 1927.7086 1915.232  1844.7305\n"," 1685.5227 1804.512  1878.034     0.        0.        0.        0.\n","    0.        0.        0.     1642.3839 1737.4325 1561.933  1898.0244\n","    0.     1996.022  1597.4778 1632.721  1524.4635 1532.9795 1384.1569]\n","0.0\n","[-1.          0.23320748  0.21523549  0.2258348   0.21444638  0.20658621\n","  0.16217057  0.06187052  0.13683313  0.18315166 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.0346933\n","  0.09457341 -0.01599036  0.19574548 -1.          0.25748342  0.00640268\n","  0.02860568 -0.03959594 -0.03423091 -0.1279884 ]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 4 / best_val_loss: 0.3165003776550293\n","Save item: 4 / best_val_loss: 0.3089461624622345\n","Save item: 4 / best_val_loss: 0.30847803950309755\n","Save item: 4 / best_val_loss: 0.3068916261196136\n","Save item: 4 / best_val_loss: 0.3068461060523987\n","Save item: 4 / best_val_loss: 0.3061806082725525\n","[epoch : 10 / 500] Train Loss : 0.31099022593763137\n","Save item: 4 / best_val_loss: 0.30599598288536073\n","Save item: 4 / best_val_loss: 0.30564277768135073\n","Save item: 4 / best_val_loss: 0.3052467703819275\n","Save item: 4 / best_val_loss: 0.3049837052822113\n","Save item: 4 / best_val_loss: 0.3032246232032776\n","Save item: 4 / best_val_loss: 0.30282014012336733\n","Save item: 4 / best_val_loss: 0.30250916481018064\n","Save item: 4 / best_val_loss: 0.2991093695163727\n","[epoch : 20 / 500] Train Loss : 0.3021077927615907\n","Save item: 4 / best_val_loss: 0.29526957869529724\n","Save item: 4 / best_val_loss: 0.2903306305408478\n","Save item: 4 / best_val_loss: 0.28914996385574343\n","Save item: 4 / best_val_loss: 0.2877975642681122\n","Save item: 4 / best_val_loss: 0.2840500473976135\n","Save item: 4 / best_val_loss: 0.28102909326553344\n","Save item: 4 / best_val_loss: 0.2796537220478058\n","Save item: 4 / best_val_loss: 0.2770709335803986\n","Save item: 4 / best_val_loss: 0.275202339887619\n","[epoch : 30 / 500] Train Loss : 0.2791086385647456\n","Save item: 4 / best_val_loss: 0.2745036602020264\n","Save item: 4 / best_val_loss: 0.2714532554149628\n","Save item: 4 / best_val_loss: 0.2674486368894577\n","Save item: 4 / best_val_loss: 0.26689107716083527\n","Save item: 4 / best_val_loss: 0.2653405636548996\n","Save item: 4 / best_val_loss: 0.26073415875434874\n","[epoch : 40 / 500] Train Loss : 0.26723816990852356\n","Save item: 4 / best_val_loss: 0.2607125699520111\n","Save item: 4 / best_val_loss: 0.25984627604484556\n","Save item: 4 / best_val_loss: 0.2565871000289917\n","[epoch : 50 / 500] Train Loss : 0.25881777455409366\n","Save item: 4 / best_val_loss: 0.2544360637664795\n","Save item: 4 / best_val_loss: 0.2525125056505203\n","Save item: 4 / best_val_loss: 0.2500942021608353\n","Save item: 4 / best_val_loss: 0.24829322695732117\n","[epoch : 60 / 500] Train Loss : 0.2538536638021469\n","Save item: 4 / best_val_loss: 0.24632160663604735\n","[epoch : 70 / 500] Train Loss : 0.2500667737589942\n","Save item: 4 / best_val_loss: 0.24401563107967378\n","[epoch : 80 / 500] Train Loss : 0.24772542383935717\n","[epoch : 90 / 500] Train Loss : 0.2457210909989145\n","Save item: 4 / best_val_loss: 0.24360540211200715\n","[epoch : 100 / 500] Train Loss : 0.24237426701519224\n","Save item: 4 / best_val_loss: 0.2429777443408966\n","Save item: 4 / best_val_loss: 0.24196310043334962\n","Save item: 4 / best_val_loss: 0.2409965455532074\n","Save item: 4 / best_val_loss: 0.24069290459156037\n","[epoch : 110 / 500] Train Loss : 0.243120482398404\n","Save item: 4 / best_val_loss: 0.24039054214954375\n","Save item: 4 / best_val_loss: 0.23849247694015502\n","[epoch : 120 / 500] Train Loss : 0.2397744647330708\n","[epoch : 130 / 500] Train Loss : 0.23815805051061842\n","[epoch : 140 / 500] Train Loss : 0.2366285671790441\n","[epoch : 150 / 500] Train Loss : 0.2350177706943618\n","Save item: 4 / best_val_loss: 0.23720748722553253\n","[epoch : 160 / 500] Train Loss : 0.23543640308909947\n","Save item: 4 / best_val_loss: 0.23677870035171508\n","[epoch : 170 / 500] Train Loss : 0.23524977515141168\n","[epoch : 180 / 500] Train Loss : 0.2347307958536678\n","[epoch : 190 / 500] Train Loss : 0.2329692103796535\n","[epoch : 200 / 500] Train Loss : 0.23380193528201845\n","Save item: 4 / best_val_loss: 0.23663557767868043\n","[epoch : 210 / 500] Train Loss : 0.23248249954647487\n","Save item: 4 / best_val_loss: 0.2365283787250519\n","Save item: 4 / best_val_loss: 0.2362266093492508\n","[epoch : 220 / 500] Train Loss : 0.23215068380037943\n","Save item: 4 / best_val_loss: 0.23611744344234467\n","Save item: 4 / best_val_loss: 0.23522622883319855\n","[epoch : 230 / 500] Train Loss : 0.23192631784412596\n","Save item: 4 / best_val_loss: 0.23505100905895232\n","Save item: 4 / best_val_loss: 0.2347950041294098\n","[epoch : 240 / 500] Train Loss : 0.23118131359418234\n","Save item: 4 / best_val_loss: 0.23432578444480895\n","[epoch : 250 / 500] Train Loss : 0.23054548932446373\n","[epoch : 260 / 500] Train Loss : 0.23251303285360336\n","[epoch : 270 / 500] Train Loss : 0.23112301694022286\n","[epoch : 280 / 500] Train Loss : 0.23325743940141466\n","[epoch : 290 / 500] Train Loss : 0.23181416342655817\n","Save item: 4 / best_val_loss: 0.23405384719371797\n","Save item: 4 / best_val_loss: 0.23209066689014435\n","[epoch : 300 / 500] Train Loss : 0.22987924764553705\n","[epoch : 310 / 500] Train Loss : 0.23183712777164248\n","[epoch : 320 / 500] Train Loss : 0.22829852253198624\n","[epoch : 330 / 500] Train Loss : 0.22920481198363835\n","[epoch : 340 / 500] Train Loss : 0.22976843184894985\n","[epoch : 350 / 500] Train Loss : 0.22957487652699152\n","Save item: 4 / best_val_loss: 0.23119415640830993\n","[epoch : 360 / 500] Train Loss : 0.22832097361485162\n","Save item: 4 / best_val_loss: 0.2310401350259781\n","[epoch : 370 / 500] Train Loss : 0.2268019136455324\n","[epoch : 380 / 500] Train Loss : 0.22723675767580667\n","[epoch : 390 / 500] Train Loss : 0.22833604448371464\n","[epoch : 400 / 500] Train Loss : 0.22785257051388422\n","[epoch : 410 / 500] Train Loss : 0.2272828213042683\n","[epoch : 420 / 500] Train Loss : 0.22694850133525002\n","Save item: 4 / best_val_loss: 0.23103469014167785\n","[epoch : 430 / 500] Train Loss : 0.22655415121052\n","Save item: 4 / best_val_loss: 0.23102784752845765\n","[epoch : 440 / 500] Train Loss : 0.22639297942320505\n","Save item: 4 / best_val_loss: 0.23082517981529235\n","Save item: 4 / best_val_loss: 0.23054348230361937\n","[epoch : 450 / 500] Train Loss : 0.22579097582234275\n","[epoch : 460 / 500] Train Loss : 0.22633859349621666\n","Save item: 4 / best_val_loss: 0.23005674183368682\n","Save item: 4 / best_val_loss: 0.22889652252197265\n","[epoch : 470 / 500] Train Loss : 0.22608743442429435\n","[epoch : 480 / 500] Train Loss : 0.22584397428565556\n","[epoch : 490 / 500] Train Loss : 0.2266388444436921\n","[epoch : 500 / 500] Train Loss : 0.22614816659026676\n","1419\n","[   0.     4955.317  4897.632  5187.415  4556.7856 4404.7935 4232.113\n","    0.     4307.6167 4154.237     0.        0.        0.        0.\n","    0.        0.        0.     5132.5093 5310.772  4705.1274 5115.477\n","    0.     4826.758  4924.058  4699.4067 4145.7563 4851.6    4877.5283]\n","0.0\n","[-1.          0.08407027  0.07145055  0.13484617 -0.00311607 -0.03636726\n"," -0.07414445 -1.         -0.05762653 -0.09118132 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.12283447\n","  0.16183284  0.02933653  0.11910835 -1.          0.0559455   0.0772318\n","  0.02808502 -0.09303658  0.06138023  0.06705253]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 5 / best_val_loss: 0.3285939395427704\n","Save item: 5 / best_val_loss: 0.32139936089515686\n","Save item: 5 / best_val_loss: 0.31952444314956663\n","Save item: 5 / best_val_loss: 0.3195227324962616\n","Save item: 5 / best_val_loss: 0.319196492433548\n","Save item: 5 / best_val_loss: 0.31781741976737976\n","Save item: 5 / best_val_loss: 0.3172663331031799\n","[epoch : 10 / 500] Train Loss : 0.3158130794763565\n","Save item: 5 / best_val_loss: 0.31641303896903994\n","Save item: 5 / best_val_loss: 0.3145636856555939\n","Save item: 5 / best_val_loss: 0.3138033449649811\n","Save item: 5 / best_val_loss: 0.31239434480667116\n","Save item: 5 / best_val_loss: 0.30656289458274844\n","Save item: 5 / best_val_loss: 0.30225527882575987\n","Save item: 5 / best_val_loss: 0.30165517926216123\n","Save item: 5 / best_val_loss: 0.2952157616615295\n","Save item: 5 / best_val_loss: 0.29331639409065247\n","[epoch : 20 / 500] Train Loss : 0.29370252788066864\n","Save item: 5 / best_val_loss: 0.2921254634857178\n","Save item: 5 / best_val_loss: 0.29182265400886537\n","Save item: 5 / best_val_loss: 0.2883936822414398\n","Save item: 5 / best_val_loss: 0.2863907337188721\n","Save item: 5 / best_val_loss: 0.28159859776496887\n","Save item: 5 / best_val_loss: 0.2814722716808319\n","Save item: 5 / best_val_loss: 0.27780516147613527\n","Save item: 5 / best_val_loss: 0.2758095622062683\n","Save item: 5 / best_val_loss: 0.2720943093299866\n","[epoch : 30 / 500] Train Loss : 0.2732899553245968\n","Save item: 5 / best_val_loss: 0.2719405353069305\n","Save item: 5 / best_val_loss: 0.26872475147247316\n","[epoch : 40 / 500] Train Loss : 0.26168298059039646\n","Save item: 5 / best_val_loss: 0.2678156793117523\n","Save item: 5 / best_val_loss: 0.2636932611465454\n","Save item: 5 / best_val_loss: 0.26347895860672\n","[epoch : 50 / 500] Train Loss : 0.2561172942320506\n","Save item: 5 / best_val_loss: 0.2610699951648712\n","Save item: 5 / best_val_loss: 0.25955086946487427\n","[epoch : 60 / 500] Train Loss : 0.25103550569878685\n","Save item: 5 / best_val_loss: 0.25710934996604917\n","[epoch : 70 / 500] Train Loss : 0.24749115937285954\n","Save item: 5 / best_val_loss: 0.25666542649269103\n","Save item: 5 / best_val_loss: 0.25570178031921387\n","[epoch : 80 / 500] Train Loss : 0.24467286467552185\n","Save item: 5 / best_val_loss: 0.2545942485332489\n","Save item: 5 / best_val_loss: 0.2531819313764572\n","[epoch : 90 / 500] Train Loss : 0.24323529998461405\n","Save item: 5 / best_val_loss: 0.2513560354709625\n","[epoch : 100 / 500] Train Loss : 0.24202430413828957\n","[epoch : 110 / 500] Train Loss : 0.23969114985730913\n","Save item: 5 / best_val_loss: 0.25062167942523955\n","[epoch : 120 / 500] Train Loss : 0.2388875244392289\n","Save item: 5 / best_val_loss: 0.2503448724746704\n","[epoch : 130 / 500] Train Loss : 0.23687178641557693\n","[epoch : 140 / 500] Train Loss : 0.23559360206127167\n","Save item: 5 / best_val_loss: 0.2499314546585083\n","[epoch : 150 / 500] Train Loss : 0.2353672045800421\n","[epoch : 160 / 500] Train Loss : 0.2339683241314358\n","Save item: 5 / best_val_loss: 0.24840495884418487\n","[epoch : 170 / 500] Train Loss : 0.23234727482000986\n","Save item: 5 / best_val_loss: 0.2475541353225708\n","[epoch : 180 / 500] Train Loss : 0.2328218792875608\n","[epoch : 190 / 500] Train Loss : 0.2326998081472185\n","[epoch : 200 / 500] Train Loss : 0.23251919779512617\n","[epoch : 210 / 500] Train Loss : 0.23116465161244074\n","Save item: 5 / best_val_loss: 0.24702122807502747\n","[epoch : 220 / 500] Train Loss : 0.2322692738638984\n","Save item: 5 / best_val_loss: 0.2449718236923218\n","[epoch : 230 / 500] Train Loss : 0.23055053916242388\n","[epoch : 240 / 500] Train Loss : 0.23047886706060833\n","[epoch : 250 / 500] Train Loss : 0.2296888372964329\n","[epoch : 260 / 500] Train Loss : 0.23126504901382658\n","[epoch : 270 / 500] Train Loss : 0.23164640532599556\n","[epoch : 280 / 500] Train Loss : 0.22956068399879667\n","[epoch : 290 / 500] Train Loss : 0.23060385882854462\n","[epoch : 300 / 500] Train Loss : 0.22966307981146705\n","[epoch : 310 / 500] Train Loss : 0.23004756536748674\n","Save item: 5 / best_val_loss: 0.24393469393253325\n","[epoch : 320 / 500] Train Loss : 0.22878013799587885\n","[epoch : 330 / 500] Train Loss : 0.22895901070700753\n","Save item: 5 / best_val_loss: 0.24224588572978972\n","[epoch : 340 / 500] Train Loss : 0.22910308755106396\n","[epoch : 350 / 500] Train Loss : 0.22923812601301405\n","[epoch : 360 / 500] Train Loss : 0.2280583166413837\n","[epoch : 370 / 500] Train Loss : 0.22643336488140953\n","[epoch : 380 / 500] Train Loss : 0.2269741031858656\n","[epoch : 390 / 500] Train Loss : 0.22565138753917482\n","[epoch : 400 / 500] Train Loss : 0.22584469036923516\n","[epoch : 410 / 500] Train Loss : 0.22596648666593763\n","[epoch : 420 / 500] Train Loss : 0.22641547355386946\n","[epoch : 430 / 500] Train Loss : 0.22603568848636416\n","[epoch : 440 / 500] Train Loss : 0.22624335686365762\n","[epoch : 450 / 500] Train Loss : 0.22602710872888565\n","[epoch : 460 / 500] Train Loss : 0.22493229061365128\n","[epoch : 470 / 500] Train Loss : 0.22587880078289244\n","[epoch : 480 / 500] Train Loss : 0.22458858788013458\n","[epoch : 490 / 500] Train Loss : 0.2261734132965406\n","[epoch : 500 / 500] Train Loss : 0.22444103327062395\n","1419\n","[   0.     2683.0286 1882.7411 2355.256  2597.4    3420.9941    0.\n","    0.        0.        0.        0.        0.        0.        0.\n","    0.        0.        0.     2978.641     0.        0.        0.\n","    0.        0.     2172.2937    0.     2897.1       0.     3050.7922]\n","0.0\n","[-1.         2.357143   1.3557822  1.9470172  2.25       3.2805233\n"," -1.        -1.        -1.        -1.        -1.        -1.\n"," -1.        -1.        -1.        -1.        -1.         2.7270284\n"," -1.        -1.        -1.        -1.        -1.         1.7180853\n"," -1.         2.6250002 -1.         2.8173077]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 6 / best_val_loss: 0.837555730342865\n","Save item: 6 / best_val_loss: 0.826264476776123\n","Save item: 6 / best_val_loss: 0.8098853945732116\n","Save item: 6 / best_val_loss: 0.7990811109542847\n","Save item: 6 / best_val_loss: 0.7870463490486145\n","Save item: 6 / best_val_loss: 0.7827750086784363\n","Save item: 6 / best_val_loss: 0.7807779908180237\n","Save item: 6 / best_val_loss: 0.7730116605758667\n","Save item: 6 / best_val_loss: 0.7724230408668518\n","[epoch : 10 / 500] Train Loss : 0.8359493083424039\n","Save item: 6 / best_val_loss: 0.7651313185691834\n","Save item: 6 / best_val_loss: 0.7622830033302307\n","Save item: 6 / best_val_loss: 0.7577093005180359\n","Save item: 6 / best_val_loss: 0.7557774901390075\n","[epoch : 20 / 500] Train Loss : 0.8090928594271342\n","Save item: 6 / best_val_loss: 0.7538552761077881\n","Save item: 6 / best_val_loss: 0.7505341291427612\n","Save item: 6 / best_val_loss: 0.7443096280097962\n","[epoch : 30 / 500] Train Loss : 0.8059141702122159\n","Save item: 6 / best_val_loss: 0.7439197897911072\n","Save item: 6 / best_val_loss: 0.7416160583496094\n","[epoch : 40 / 500] Train Loss : 0.7874100473192003\n","Save item: 6 / best_val_loss: 0.7412359952926636\n","Save item: 6 / best_val_loss: 0.7400455951690674\n","Save item: 6 / best_val_loss: 0.737953519821167\n","[epoch : 50 / 500] Train Loss : 0.7788068370686637\n","Save item: 6 / best_val_loss: 0.7345885515213013\n","Save item: 6 / best_val_loss: 0.7317557096481323\n","[epoch : 60 / 500] Train Loss : 0.7630955610010359\n","Save item: 6 / best_val_loss: 0.7270934820175171\n","Save item: 6 / best_val_loss: 0.7186966896057129\n","[epoch : 70 / 500] Train Loss : 0.7581763830449846\n","[epoch : 80 / 500] Train Loss : 0.7433964841895633\n","[epoch : 90 / 500] Train Loss : 0.7363638795084424\n","[epoch : 100 / 500] Train Loss : 0.7335185209910074\n","Save item: 6 / best_val_loss: 0.7125765323638916\n","Save item: 6 / best_val_loss: 0.7050399661064148\n","[epoch : 110 / 500] Train Loss : 0.730069186952379\n","[epoch : 120 / 500] Train Loss : 0.7283916142251756\n","[epoch : 130 / 500] Train Loss : 0.7247485551569197\n","[epoch : 140 / 500] Train Loss : 0.7206397884421878\n","[epoch : 150 / 500] Train Loss : 0.7190520730283525\n","[epoch : 160 / 500] Train Loss : 0.7223038441605039\n","[epoch : 170 / 500] Train Loss : 0.7171107033888499\n","[epoch : 180 / 500] Train Loss : 0.7125594086117215\n","[epoch : 190 / 500] Train Loss : 0.7178530792395273\n","Save item: 6 / best_val_loss: 0.7012436509132385\n","[epoch : 200 / 500] Train Loss : 0.7094984021451738\n","[epoch : 210 / 500] Train Loss : 0.7078260216448042\n","[epoch : 220 / 500] Train Loss : 0.7024895085228814\n","[epoch : 230 / 500] Train Loss : 0.7025775412718455\n","[epoch : 240 / 500] Train Loss : 0.7069015602270762\n","Save item: 6 / best_val_loss: 0.7010605812072754\n","Save item: 6 / best_val_loss: 0.6997113585472107\n","Save item: 6 / best_val_loss: 0.6961440324783326\n","[epoch : 250 / 500] Train Loss : 0.7036194966899024\n","[epoch : 260 / 500] Train Loss : 0.706587036450704\n","[epoch : 270 / 500] Train Loss : 0.7149769299560123\n","[epoch : 280 / 500] Train Loss : 0.7005907959408231\n","[epoch : 290 / 500] Train Loss : 0.7010331286324395\n","[epoch : 300 / 500] Train Loss : 0.7021188305483924\n","[epoch : 310 / 500] Train Loss : 0.7016464339362251\n","[epoch : 320 / 500] Train Loss : 0.7021230492326949\n","Save item: 6 / best_val_loss: 0.6954650521278382\n","[epoch : 330 / 500] Train Loss : 0.7028499643007914\n","[epoch : 340 / 500] Train Loss : 0.6882333606481552\n","[epoch : 350 / 500] Train Loss : 0.6996904280450609\n","[epoch : 360 / 500] Train Loss : 0.6943926066160202\n","[epoch : 370 / 500] Train Loss : 0.692449665731854\n","[epoch : 380 / 500] Train Loss : 0.6977039906713698\n","[epoch : 390 / 500] Train Loss : 0.6874831087059445\n","[epoch : 400 / 500] Train Loss : 0.6927306221591102\n","Save item: 6 / best_val_loss: 0.6945009469985962\n","[epoch : 410 / 500] Train Loss : 0.6845392717255486\n","Save item: 6 / best_val_loss: 0.6940996527671814\n","Save item: 6 / best_val_loss: 0.6899805665016174\n","[epoch : 420 / 500] Train Loss : 0.6871907479233212\n","[epoch : 430 / 500] Train Loss : 0.6928281717830234\n","[epoch : 440 / 500] Train Loss : 0.6957286530070834\n","[epoch : 450 / 500] Train Loss : 0.6919171098205779\n","Save item: 6 / best_val_loss: 0.6860181808471679\n","[epoch : 460 / 500] Train Loss : 0.6872315754493078\n","[epoch : 470 / 500] Train Loss : 0.6831130153603024\n","[epoch : 480 / 500] Train Loss : 0.6887729896439446\n","[epoch : 490 / 500] Train Loss : 0.6828958127233717\n","[epoch : 500 / 500] Train Loss : 0.6785061657428741\n","1419\n","[   0.     1870.7144 1850.9863 1827.3347 1847.3419 1861.3086 1890.9736\n","    0.     1957.7084 2001.004     0.        0.        0.        0.\n","    0.        0.        0.     1929.6348 1982.5137 2021.076  1888.834\n","    0.     2022.614  1837.3369 1839.317  1800.146  1803.6791 1751.5253]\n","0.0\n","[-1.          0.07463315  0.06330037  0.04971369  0.06120684  0.06923001\n","  0.08627111 -1.          0.12460692  0.14947814 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.10848002\n","  0.13885634  0.16100852  0.08504198 -1.          0.16189201  0.05545945\n","  0.05659693  0.03409511  0.03612469  0.0061649 ]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 7 / best_val_loss: 0.6879252552986145\n","Save item: 7 / best_val_loss: 0.6654870629310607\n","Save item: 7 / best_val_loss: 0.6279916048049927\n","Save item: 7 / best_val_loss: 0.5982020854949951\n","Save item: 7 / best_val_loss: 0.5836624324321746\n","Save item: 7 / best_val_loss: 0.5724878430366516\n","Save item: 7 / best_val_loss: 0.5645691812038421\n","Save item: 7 / best_val_loss: 0.5590999484062195\n","Save item: 7 / best_val_loss: 0.558156681060791\n","[epoch : 10 / 500] Train Loss : 0.4869748916890886\n","Save item: 7 / best_val_loss: 0.5468589127063751\n","Save item: 7 / best_val_loss: 0.538819420337677\n","Save item: 7 / best_val_loss: 0.5385638654232026\n","Save item: 7 / best_val_loss: 0.5321529448032379\n","Save item: 7 / best_val_loss: 0.5315262496471405\n","Save item: 7 / best_val_loss: 0.5313471555709839\n","[epoch : 20 / 500] Train Loss : 0.47211917572551304\n","Save item: 7 / best_val_loss: 0.5268926382064819\n","Save item: 7 / best_val_loss: 0.5251745223999024\n","Save item: 7 / best_val_loss: 0.5238067924976348\n","Save item: 7 / best_val_loss: 0.5225429236888885\n","Save item: 7 / best_val_loss: 0.5199877500534058\n","Save item: 7 / best_val_loss: 0.5147716224193573\n","[epoch : 30 / 500] Train Loss : 0.4582904328902562\n","Save item: 7 / best_val_loss: 0.5126719117164612\n","[epoch : 40 / 500] Train Loss : 0.45521022379398346\n","Save item: 7 / best_val_loss: 0.5106874585151673\n","Save item: 7 / best_val_loss: 0.509404855966568\n","[epoch : 50 / 500] Train Loss : 0.44863251348336536\n","Save item: 7 / best_val_loss: 0.5062099516391754\n","Save item: 7 / best_val_loss: 0.5061909198760987\n","Save item: 7 / best_val_loss: 0.5033397912979126\n","[epoch : 60 / 500] Train Loss : 0.44617408679591286\n","Save item: 7 / best_val_loss: 0.5032653570175171\n","Save item: 7 / best_val_loss: 0.502892118692398\n","[epoch : 70 / 500] Train Loss : 0.4443108124865426\n","Save item: 7 / best_val_loss: 0.5018981337547302\n","Save item: 7 / best_val_loss: 0.5009291112422943\n","[epoch : 80 / 500] Train Loss : 0.4373813056283527\n","Save item: 7 / best_val_loss: 0.499698281288147\n","[epoch : 90 / 500] Train Loss : 0.43458258443408543\n","Save item: 7 / best_val_loss: 0.4978788733482361\n","[epoch : 100 / 500] Train Loss : 0.43274708754486507\n","Save item: 7 / best_val_loss: 0.49600655436515806\n","Save item: 7 / best_val_loss: 0.49533714056015016\n","[epoch : 110 / 500] Train Loss : 0.43095066646734875\n","[epoch : 120 / 500] Train Loss : 0.43041657904783887\n","Save item: 7 / best_val_loss: 0.4930082023143768\n","Save item: 7 / best_val_loss: 0.49052215218544004\n","[epoch : 130 / 500] Train Loss : 0.4297362019618352\n","[epoch : 140 / 500] Train Loss : 0.42696913580099743\n","Save item: 7 / best_val_loss: 0.48749702572822573\n","[epoch : 150 / 500] Train Loss : 0.42588602006435394\n","[epoch : 160 / 500] Train Loss : 0.4253770560026169\n","[epoch : 170 / 500] Train Loss : 0.4189282688829634\n","[epoch : 180 / 500] Train Loss : 0.4179920670058992\n","Save item: 7 / best_val_loss: 0.48612986207008363\n","[epoch : 190 / 500] Train Loss : 0.4186973356538349\n","[epoch : 200 / 500] Train Loss : 0.41553975807295906\n","Save item: 7 / best_val_loss: 0.4855782866477966\n","Save item: 7 / best_val_loss: 0.4854621946811676\n","Save item: 7 / best_val_loss: 0.4846152126789093\n","[epoch : 210 / 500] Train Loss : 0.41725536187489826\n","[epoch : 220 / 500] Train Loss : 0.4145703828997082\n","[epoch : 230 / 500] Train Loss : 0.41295716332064736\n","Save item: 7 / best_val_loss: 0.4845833957195282\n","[epoch : 240 / 500] Train Loss : 0.4113095502058665\n","Save item: 7 / best_val_loss: 0.4843356668949127\n","Save item: 7 / best_val_loss: 0.4814781427383423\n","[epoch : 250 / 500] Train Loss : 0.40989623301559025\n","[epoch : 260 / 500] Train Loss : 0.41253331965870327\n","[epoch : 270 / 500] Train Loss : 0.40819109479586285\n","Save item: 7 / best_val_loss: 0.4783875644207001\n","Save item: 7 / best_val_loss: 0.4780222773551941\n","[epoch : 280 / 500] Train Loss : 0.40960728956593406\n","[epoch : 290 / 500] Train Loss : 0.40498951739735073\n","Save item: 7 / best_val_loss: 0.4767975568771362\n","[epoch : 300 / 500] Train Loss : 0.4039308528105418\n","Save item: 7 / best_val_loss: 0.47605815529823303\n","Save item: 7 / best_val_loss: 0.47370198369026184\n","Save item: 7 / best_val_loss: 0.4728879451751709\n","[epoch : 310 / 500] Train Loss : 0.3999458882543776\n","[epoch : 320 / 500] Train Loss : 0.39879611796802944\n","Save item: 7 / best_val_loss: 0.4727528810501099\n","[epoch : 330 / 500] Train Loss : 0.4004097580909729\n","Save item: 7 / best_val_loss: 0.46833728551864623\n","[epoch : 340 / 500] Train Loss : 0.3977668583393097\n","[epoch : 350 / 500] Train Loss : 0.3963131606578827\n","[epoch : 360 / 500] Train Loss : 0.3959414031770494\n","[epoch : 370 / 500] Train Loss : 0.3932747062709596\n","Save item: 7 / best_val_loss: 0.465205717086792\n","Save item: 7 / best_val_loss: 0.46487407088279725\n","[epoch : 380 / 500] Train Loss : 0.39169542160299087\n","[epoch : 390 / 500] Train Loss : 0.39279305272632176\n","Save item: 7 / best_val_loss: 0.4622284173965454\n","Save item: 7 / best_val_loss: 0.46170687675476074\n","[epoch : 400 / 500] Train Loss : 0.3915580006109344\n","[epoch : 410 / 500] Train Loss : 0.39043961630927193\n","Save item: 7 / best_val_loss: 0.4609841287136078\n","[epoch : 420 / 500] Train Loss : 0.3892902334531148\n","[epoch : 430 / 500] Train Loss : 0.3896283672915565\n","Save item: 7 / best_val_loss: 0.4609488666057587\n","Save item: 7 / best_val_loss: 0.459386533498764\n","Save item: 7 / best_val_loss: 0.455064469575882\n","[epoch : 440 / 500] Train Loss : 0.38695524136225384\n","[epoch : 450 / 500] Train Loss : 0.3891666250096427\n","[epoch : 460 / 500] Train Loss : 0.38958364559544456\n","[epoch : 470 / 500] Train Loss : 0.38662585616111755\n","[epoch : 480 / 500] Train Loss : 0.38893230590555405\n","[epoch : 490 / 500] Train Loss : 0.38812655376063454\n","[epoch : 500 / 500] Train Loss : 0.38588205145465004\n","1419\n","[   0.     2838.0662 3655.6155 3363.766  3716.2969 3161.7168 3196.8647\n","    0.     3452.9155 3130.9365    0.        0.        0.        0.\n","    0.        0.        0.     3322.0442 3207.4036 2981.0884 3280.8154\n","    0.     3384.5986 2894.8506 3073.2993 3033.2056 2870.8513 2682.7104]\n","0.0\n","[-0.99999994  0.09663556  0.41253856  0.29976726  0.435986    0.22169493\n","  0.23527618 -0.99999994  0.3342148   0.20980136 -0.99999994 -0.99999994\n"," -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.99999994  0.2836458\n","  0.23934841  0.1518997   0.26771492 -0.99999994  0.307817    0.1185772\n","  0.18753022  0.1720379   0.10930382  0.03660574]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 8 / best_val_loss: 0.2994828224182129\n","Save item: 8 / best_val_loss: 0.2925150990486145\n","Save item: 8 / best_val_loss: 0.2908631920814514\n","Save item: 8 / best_val_loss: 0.2895424783229828\n","Save item: 8 / best_val_loss: 0.28950833082199096\n","Save item: 8 / best_val_loss: 0.2890217065811157\n","Save item: 8 / best_val_loss: 0.28877408504486085\n","Save item: 8 / best_val_loss: 0.28837172985076903\n","[epoch : 10 / 500] Train Loss : 0.3035881105396483\n","Save item: 8 / best_val_loss: 0.28822932243347166\n","Save item: 8 / best_val_loss: 0.28798245787620547\n","Save item: 8 / best_val_loss: 0.28781569600105283\n","Save item: 8 / best_val_loss: 0.2873556137084961\n","Save item: 8 / best_val_loss: 0.28604257106781006\n","[epoch : 20 / 500] Train Loss : 0.30041085183620453\n","Save item: 8 / best_val_loss: 0.28596962690353395\n","Save item: 8 / best_val_loss: 0.28457282185554506\n","Save item: 8 / best_val_loss: 0.28347675800323485\n","Save item: 8 / best_val_loss: 0.28248544931411745\n","Save item: 8 / best_val_loss: 0.2823315143585205\n","[epoch : 30 / 500] Train Loss : 0.2943637917439143\n","Save item: 8 / best_val_loss: 0.2817529261112213\n","Save item: 8 / best_val_loss: 0.2811920762062073\n","Save item: 8 / best_val_loss: 0.28083701729774474\n","Save item: 8 / best_val_loss: 0.2802034914493561\n","[epoch : 40 / 500] Train Loss : 0.29057373106479645\n","Save item: 8 / best_val_loss: 0.27888503074646\n","[epoch : 50 / 500] Train Loss : 0.2861685554186503\n","Save item: 8 / best_val_loss: 0.27840191721916197\n","Save item: 8 / best_val_loss: 0.2769720613956451\n","Save item: 8 / best_val_loss: 0.27591910362243655\n","[epoch : 60 / 500] Train Loss : 0.2812609208954705\n","[epoch : 70 / 500] Train Loss : 0.2764871766169866\n","Save item: 8 / best_val_loss: 0.27547997832298277\n","Save item: 8 / best_val_loss: 0.2754244148731232\n","[epoch : 80 / 500] Train Loss : 0.27405109504858655\n","Save item: 8 / best_val_loss: 0.2742021918296814\n","[epoch : 90 / 500] Train Loss : 0.2712036371231079\n","Save item: 8 / best_val_loss: 0.27418436408042907\n","Save item: 8 / best_val_loss: 0.2726984739303589\n","[epoch : 100 / 500] Train Loss : 0.2670038524601195\n","[epoch : 110 / 500] Train Loss : 0.26417241824997795\n","[epoch : 120 / 500] Train Loss : 0.26438935928874546\n","[epoch : 130 / 500] Train Loss : 0.2621898700793584\n","[epoch : 140 / 500] Train Loss : 0.2602570288711124\n","[epoch : 150 / 500] Train Loss : 0.26030908938911224\n","[epoch : 160 / 500] Train Loss : 0.25813551329904133\n","Save item: 8 / best_val_loss: 0.2725906789302826\n","[epoch : 170 / 500] Train Loss : 0.25804805590046775\n","[epoch : 180 / 500] Train Loss : 0.2589272807041804\n","[epoch : 190 / 500] Train Loss : 0.25673891603946686\n","Save item: 8 / best_val_loss: 0.27181715369224546\n","[epoch : 200 / 500] Train Loss : 0.2562011778354645\n","[epoch : 210 / 500] Train Loss : 0.25544457303153145\n","Save item: 8 / best_val_loss: 0.27171107530593874\n","[epoch : 220 / 500] Train Loss : 0.25654400719536674\n","Save item: 8 / best_val_loss: 0.2716833233833313\n","[epoch : 230 / 500] Train Loss : 0.2551732261975606\n","[epoch : 240 / 500] Train Loss : 0.25503720839818317\n","[epoch : 250 / 500] Train Loss : 0.25342514200343025\n","[epoch : 260 / 500] Train Loss : 0.25444429450564915\n","[epoch : 270 / 500] Train Loss : 0.25563304540183807\n","[epoch : 280 / 500] Train Loss : 0.2546129549543063\n","[epoch : 290 / 500] Train Loss : 0.25530839297506547\n","Save item: 8 / best_val_loss: 0.27167701721191406\n","[epoch : 300 / 500] Train Loss : 0.2549898632698589\n","[epoch : 310 / 500] Train Loss : 0.254064093861315\n","[epoch : 320 / 500] Train Loss : 0.2540845647454262\n","[epoch : 330 / 500] Train Loss : 0.253056101500988\n","[epoch : 340 / 500] Train Loss : 0.2535950086183018\n","[epoch : 350 / 500] Train Loss : 0.25258473720815444\n","[epoch : 360 / 500] Train Loss : 0.25065172298087013\n","[epoch : 370 / 500] Train Loss : 0.25046467284361523\n","Save item: 8 / best_val_loss: 0.27161505818367004\n","[epoch : 380 / 500] Train Loss : 0.2520425965388616\n","[epoch : 390 / 500] Train Loss : 0.2521997061040666\n","[epoch : 400 / 500] Train Loss : 0.25093233419789207\n","[epoch : 410 / 500] Train Loss : 0.2504693518082301\n","Save item: 8 / best_val_loss: 0.2711950659751892\n","[epoch : 420 / 500] Train Loss : 0.2513154364294476\n","[epoch : 430 / 500] Train Loss : 0.2504653094543351\n","[epoch : 440 / 500] Train Loss : 0.251022859579987\n","[epoch : 450 / 500] Train Loss : 0.25037704987658393\n","[epoch : 460 / 500] Train Loss : 0.2501107388072544\n","[epoch : 470 / 500] Train Loss : 0.24994536654816735\n","Save item: 8 / best_val_loss: 0.27043030261993406\n","[epoch : 480 / 500] Train Loss : 0.25001644757058883\n","[epoch : 490 / 500] Train Loss : 0.24965084509717095\n","[epoch : 500 / 500] Train Loss : 0.2494964508546723\n","1419\n","[   0.     1523.6276 1524.9218 1509.5977 1597.7632 1562.6643 1467.2542\n","    0.     1496.7789 1500.3068    0.        0.        0.        0.\n","    0.        0.        0.     1420.6385 1529.7975 1540.5725 1667.2533\n","    0.     1663.7069 1407.6901 1627.5994 1593.5942 1543.9886 1655.3534]\n","0.0\n","[-1.          0.05793417  0.05883279  0.04819247  0.1094104   0.08503941\n","  0.01879116 -1.          0.03929176  0.04174132 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.01357649\n","  0.06221826  0.06969993  0.157661   -1.          0.15519857 -0.02256729\n","  0.13012722  0.10651568  0.07207192  0.14939828]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 9 / best_val_loss: 0.26748905181884763\n","Save item: 9 / best_val_loss: 0.25947906970977785\n","Save item: 9 / best_val_loss: 0.25746923983097075\n","Save item: 9 / best_val_loss: 0.2563380867242813\n","Save item: 9 / best_val_loss: 0.25571052730083466\n","Save item: 9 / best_val_loss: 0.2550513416528702\n","Save item: 9 / best_val_loss: 0.2547691076993942\n","Save item: 9 / best_val_loss: 0.25451183021068574\n","[epoch : 10 / 500] Train Loss : 0.25192711585097843\n","Save item: 9 / best_val_loss: 0.2539941668510437\n","Save item: 9 / best_val_loss: 0.2525801360607147\n","Save item: 9 / best_val_loss: 0.25122160613536837\n","Save item: 9 / best_val_loss: 0.24927983283996583\n","Save item: 9 / best_val_loss: 0.2458884596824646\n","Save item: 9 / best_val_loss: 0.2403877228498459\n","Save item: 9 / best_val_loss: 0.23739553689956666\n","Save item: 9 / best_val_loss: 0.2359389454126358\n","Save item: 9 / best_val_loss: 0.2311972498893738\n","[epoch : 20 / 500] Train Loss : 0.2308386473192109\n","Save item: 9 / best_val_loss: 0.22895623743534088\n","Save item: 9 / best_val_loss: 0.22871995270252227\n","Save item: 9 / best_val_loss: 0.22622189223766326\n","Save item: 9 / best_val_loss: 0.22420094311237335\n","Save item: 9 / best_val_loss: 0.22240496873855592\n","Save item: 9 / best_val_loss: 0.21939241588115693\n","[epoch : 30 / 500] Train Loss : 0.2207534619503551\n","Save item: 9 / best_val_loss: 0.2173172265291214\n","[epoch : 40 / 500] Train Loss : 0.21710015998946297\n","Save item: 9 / best_val_loss: 0.21664462685585023\n","Save item: 9 / best_val_loss: 0.21634651422500611\n","Save item: 9 / best_val_loss: 0.2146041512489319\n","[epoch : 50 / 500] Train Loss : 0.21324568076266182\n","Save item: 9 / best_val_loss: 0.2141362965106964\n","Save item: 9 / best_val_loss: 0.21300379633903505\n","Save item: 9 / best_val_loss: 0.21235195994377137\n","[epoch : 60 / 500] Train Loss : 0.21154584570063484\n","[epoch : 70 / 500] Train Loss : 0.20844927099015978\n","Save item: 9 / best_val_loss: 0.21195039749145508\n","Save item: 9 / best_val_loss: 0.21191610991954804\n","Save item: 9 / best_val_loss: 0.2114574909210205\n","[epoch : 80 / 500] Train Loss : 0.20750690251588821\n","Save item: 9 / best_val_loss: 0.2112549811601639\n","Save item: 9 / best_val_loss: 0.21064501702785493\n","Save item: 9 / best_val_loss: 0.2079949289560318\n","[epoch : 90 / 500] Train Loss : 0.2059041609366735\n","[epoch : 100 / 500] Train Loss : 0.20469005902608237\n","[epoch : 110 / 500] Train Loss : 0.20363150454229778\n","[epoch : 120 / 500] Train Loss : 0.20346936914655897\n","Save item: 9 / best_val_loss: 0.20798978805541993\n","Save item: 9 / best_val_loss: 0.20796443223953248\n","[epoch : 130 / 500] Train Loss : 0.20206626835796568\n","Save item: 9 / best_val_loss: 0.2078529715538025\n","Save item: 9 / best_val_loss: 0.20680399537086486\n","[epoch : 140 / 500] Train Loss : 0.20165740036302143\n","[epoch : 150 / 500] Train Loss : 0.20120596471760008\n","[epoch : 160 / 500] Train Loss : 0.20095296204090118\n","Save item: 9 / best_val_loss: 0.20614129900932313\n","[epoch : 170 / 500] Train Loss : 0.1998996709783872\n","Save item: 9 / best_val_loss: 0.20606692433357238\n","[epoch : 180 / 500] Train Loss : 0.20002206249369514\n","Save item: 9 / best_val_loss: 0.20540618598461152\n","[epoch : 190 / 500] Train Loss : 0.19992725799481073\n","Save item: 9 / best_val_loss: 0.20521205961704253\n","[epoch : 200 / 500] Train Loss : 0.19965800725751454\n","[epoch : 210 / 500] Train Loss : 0.19916508346796036\n","[epoch : 220 / 500] Train Loss : 0.19855036007033455\n","Save item: 9 / best_val_loss: 0.20512996912002562\n","[epoch : 230 / 500] Train Loss : 0.19810930060015786\n","Save item: 9 / best_val_loss: 0.20472145080566406\n","[epoch : 240 / 500] Train Loss : 0.19818423688411713\n","[epoch : 250 / 500] Train Loss : 0.19773370027542114\n","[epoch : 260 / 500] Train Loss : 0.19971730063358942\n","[epoch : 270 / 500] Train Loss : 0.19870214412609735\n","Save item: 9 / best_val_loss: 0.20459027588367462\n","[epoch : 280 / 500] Train Loss : 0.19796802351872125\n","[epoch : 290 / 500] Train Loss : 0.19762231906255087\n","[epoch : 300 / 500] Train Loss : 0.19762884080410004\n","Save item: 9 / best_val_loss: 0.2041231393814087\n","[epoch : 310 / 500] Train Loss : 0.19803745796283087\n","Save item: 9 / best_val_loss: 0.2034545958042145\n","[epoch : 320 / 500] Train Loss : 0.19774436371193993\n","[epoch : 330 / 500] Train Loss : 0.1967238270574146\n","Save item: 9 / best_val_loss: 0.20326094925403596\n","[epoch : 340 / 500] Train Loss : 0.1971826578179995\n","[epoch : 350 / 500] Train Loss : 0.19644716878732046\n","[epoch : 360 / 500] Train Loss : 0.1962345904774136\n","[epoch : 370 / 500] Train Loss : 0.19627831214004093\n","Save item: 9 / best_val_loss: 0.20284366607666016\n","[epoch : 380 / 500] Train Loss : 0.19559434718555874\n","Save item: 9 / best_val_loss: 0.2025212526321411\n","Save item: 9 / best_val_loss: 0.20227054953575135\n","[epoch : 390 / 500] Train Loss : 0.19562775062190163\n","[epoch : 400 / 500] Train Loss : 0.19592766215403876\n","Save item: 9 / best_val_loss: 0.20222279727458953\n","[epoch : 410 / 500] Train Loss : 0.19509564836819968\n","[epoch : 420 / 500] Train Loss : 0.19540043589141634\n","[epoch : 430 / 500] Train Loss : 0.19496919876999325\n","[epoch : 440 / 500] Train Loss : 0.1953596861826049\n","[epoch : 450 / 500] Train Loss : 0.1953506867090861\n","[epoch : 460 / 500] Train Loss : 0.19482647958729002\n","Save item: 9 / best_val_loss: 0.20189397037029266\n","[epoch : 470 / 500] Train Loss : 0.19488488303290474\n","[epoch : 480 / 500] Train Loss : 0.19457639339897367\n","[epoch : 490 / 500] Train Loss : 0.19435728672477934\n","[epoch : 500 / 500] Train Loss : 0.19440237763855192\n","1419\n","[   0.     1825.4404 1766.5602 1847.7324 1883.3611 1774.8738 1878.6941\n","    0.     1805.7385 1896.5317    0.        0.        0.        0.\n","    0.        0.        0.     1536.7987 1544.4507 1725.4554 1769.5376\n","    0.     1766.9098 1577.2987 1798.4742 1811.5336 1747.4215 1605.1718]\n","0.0\n","[-1.          0.133564    0.09700048  0.1474069   0.16953163  0.10216306\n","  0.16663352 -1.          0.12132949  0.17771035 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.04567705\n"," -0.04092532  0.07147522  0.09884939 -1.          0.09721757 -0.02052732\n","  0.11681851  0.1249281   0.08511572 -0.00321868]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 10 / best_val_loss: 0.30683586597442625\n","Save item: 10 / best_val_loss: 0.2982310652732849\n","Save item: 10 / best_val_loss: 0.29764329791069033\n","Save item: 10 / best_val_loss: 0.2968579471111298\n","Save item: 10 / best_val_loss: 0.29634389877319334\n","Save item: 10 / best_val_loss: 0.29589462876319883\n","Save item: 10 / best_val_loss: 0.29579814672470095\n","[epoch : 10 / 500] Train Loss : 0.2909892400105794\n","Save item: 10 / best_val_loss: 0.29575303196907043\n","Save item: 10 / best_val_loss: 0.29416056871414187\n","Save item: 10 / best_val_loss: 0.2936775505542755\n","Save item: 10 / best_val_loss: 0.29177876710891726\n","Save item: 10 / best_val_loss: 0.2896910130977631\n","Save item: 10 / best_val_loss: 0.28438088297843933\n","Save item: 10 / best_val_loss: 0.2816600322723389\n","Save item: 10 / best_val_loss: 0.27819804549217225\n","Save item: 10 / best_val_loss: 0.2752578854560852\n","[epoch : 20 / 500] Train Loss : 0.2731009100874265\n","Save item: 10 / best_val_loss: 0.2732881367206573\n","Save item: 10 / best_val_loss: 0.2701520979404449\n","Save item: 10 / best_val_loss: 0.2683952271938324\n","Save item: 10 / best_val_loss: 0.2677179634571075\n","Save item: 10 / best_val_loss: 0.2672090619802475\n","Save item: 10 / best_val_loss: 0.26631670594215395\n","[epoch : 30 / 500] Train Loss : 0.26321370402971905\n","Save item: 10 / best_val_loss: 0.26622729301452636\n","Save item: 10 / best_val_loss: 0.2622079223394394\n","Save item: 10 / best_val_loss: 0.26117193400859834\n","Save item: 10 / best_val_loss: 0.259480619430542\n","Save item: 10 / best_val_loss: 0.2581256031990051\n","[epoch : 40 / 500] Train Loss : 0.2531331678231557\n","Save item: 10 / best_val_loss: 0.25594385862350466\n","Save item: 10 / best_val_loss: 0.2538847684860229\n","Save item: 10 / best_val_loss: 0.25357171297073366\n","Save item: 10 / best_val_loss: 0.25340846478939055\n","Save item: 10 / best_val_loss: 0.2531711608171463\n","Save item: 10 / best_val_loss: 0.2519905000925064\n","[epoch : 50 / 500] Train Loss : 0.24645314282841152\n","Save item: 10 / best_val_loss: 0.24808608889579772\n","Save item: 10 / best_val_loss: 0.2474671334028244\n","Save item: 10 / best_val_loss: 0.24663397073745727\n","Save item: 10 / best_val_loss: 0.24554213881492615\n","Save item: 10 / best_val_loss: 0.24325392246246338\n","[epoch : 60 / 500] Train Loss : 0.2413833679424392\n","Save item: 10 / best_val_loss: 0.24314332902431487\n","Save item: 10 / best_val_loss: 0.24278869926929475\n","[epoch : 70 / 500] Train Loss : 0.2373892151647144\n","Save item: 10 / best_val_loss: 0.24221604466438293\n","Save item: 10 / best_val_loss: 0.23950595557689666\n","[epoch : 80 / 500] Train Loss : 0.23546257780657875\n","[epoch : 90 / 500] Train Loss : 0.2336852177977562\n","Save item: 10 / best_val_loss: 0.2391105055809021\n","Save item: 10 / best_val_loss: 0.23910367488861084\n","[epoch : 100 / 500] Train Loss : 0.2322279769513342\n","Save item: 10 / best_val_loss: 0.2383156955242157\n","Save item: 10 / best_val_loss: 0.23776493668556214\n","[epoch : 110 / 500] Train Loss : 0.23044312083058888\n","Save item: 10 / best_val_loss: 0.23717834949493408\n","[epoch : 120 / 500] Train Loss : 0.2302596809135543\n","[epoch : 130 / 500] Train Loss : 0.22932117763492796\n","Save item: 10 / best_val_loss: 0.2363264501094818\n","[epoch : 140 / 500] Train Loss : 0.22986802707115808\n","[epoch : 150 / 500] Train Loss : 0.2280258983373642\n","Save item: 10 / best_val_loss: 0.2361281096935272\n","[epoch : 160 / 500] Train Loss : 0.2275290803776847\n","[epoch : 170 / 500] Train Loss : 0.2271853925453292\n","[epoch : 180 / 500] Train Loss : 0.22765484038326475\n","Save item: 10 / best_val_loss: 0.23578684628009797\n","[epoch : 190 / 500] Train Loss : 0.2265421160393291\n","[epoch : 200 / 500] Train Loss : 0.22648913744423124\n","Save item: 10 / best_val_loss: 0.23574378788471223\n","[epoch : 210 / 500] Train Loss : 0.2255478890405761\n","[epoch : 220 / 500] Train Loss : 0.22530708875921038\n","Save item: 10 / best_val_loss: 0.23526093363761902\n","[epoch : 230 / 500] Train Loss : 0.2256538909342554\n","Save item: 10 / best_val_loss: 0.2339156836271286\n","[epoch : 240 / 500] Train Loss : 0.22555406557189095\n","[epoch : 250 / 500] Train Loss : 0.22454358637332916\n","[epoch : 260 / 500] Train Loss : 0.2259121835231781\n","Save item: 10 / best_val_loss: 0.23372746407985687\n","[epoch : 270 / 500] Train Loss : 0.22605779104762608\n","[epoch : 280 / 500] Train Loss : 0.22538118478324679\n","[epoch : 290 / 500] Train Loss : 0.22519630524847242\n","[epoch : 300 / 500] Train Loss : 0.22673783865239885\n","[epoch : 310 / 500] Train Loss : 0.22435248808728325\n","[epoch : 320 / 500] Train Loss : 0.22431829820076624\n","Save item: 10 / best_val_loss: 0.23313192129135132\n","[epoch : 330 / 500] Train Loss : 0.22453163233068255\n","[epoch : 340 / 500] Train Loss : 0.22486907160944408\n","[epoch : 350 / 500] Train Loss : 0.22333025766743553\n","Save item: 10 / best_val_loss: 0.2329801559448242\n","[epoch : 360 / 500] Train Loss : 0.22227988060977724\n","Save item: 10 / best_val_loss: 0.23169659078121185\n","[epoch : 370 / 500] Train Loss : 0.22239559723271263\n","[epoch : 380 / 500] Train Loss : 0.22265381117661795\n","[epoch : 390 / 500] Train Loss : 0.22196353723605475\n","[epoch : 400 / 500] Train Loss : 0.22131814807653427\n","Save item: 10 / best_val_loss: 0.23069029152393342\n","[epoch : 410 / 500] Train Loss : 0.22190256085660723\n","[epoch : 420 / 500] Train Loss : 0.22261017478174633\n","[epoch : 430 / 500] Train Loss : 0.2217539375027021\n","[epoch : 440 / 500] Train Loss : 0.22139279461569256\n","[epoch : 450 / 500] Train Loss : 0.221414961748653\n","[epoch : 460 / 500] Train Loss : 0.2218736501203643\n","[epoch : 470 / 500] Train Loss : 0.22148254182603624\n","[epoch : 480 / 500] Train Loss : 0.22052546424998176\n","[epoch : 490 / 500] Train Loss : 0.22092274576425552\n","[epoch : 500 / 500] Train Loss : 0.22084788646962908\n","1419\n","[   0.     2082.4792 2117.5178 2184.9417 2191.7183 2236.8618 2212.5183\n"," 3243.9075 2379.1714 2387.7734    0.        0.        0.        0.\n","    0.        0.        0.     2680.2021 2703.066  2806.7422 2744.4739\n","    0.     2874.2148 2920.937  2862.209  2958.5635 2985.103  2978.8552]\n","0.0\n","[-1.          0.19037431  0.21040285  0.24894325  0.25281686  0.27862155\n","  0.26470646  0.854263    0.3599677   0.36488476 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.53204113\n","  0.54511034  0.60437316  0.56877977 -1.          0.6429415   0.6696485\n","  0.6360788   0.6911563   0.7063267   0.7027554 ]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 11 / best_val_loss: 0.3866496741771698\n","Save item: 11 / best_val_loss: 0.37897831201553345\n","Save item: 11 / best_val_loss: 0.3786462604999542\n","Save item: 11 / best_val_loss: 0.37627534866333007\n","Save item: 11 / best_val_loss: 0.37592061161994933\n","Save item: 11 / best_val_loss: 0.37386865019798277\n","Save item: 11 / best_val_loss: 0.3714555263519287\n","Save item: 11 / best_val_loss: 0.3654427409172058\n","[epoch : 10 / 500] Train Loss : 0.37004010213745964\n","Save item: 11 / best_val_loss: 0.3608986258506775\n","Save item: 11 / best_val_loss: 0.3459643483161926\n","Save item: 11 / best_val_loss: 0.3289289176464081\n","Save item: 11 / best_val_loss: 0.31913365721702575\n","Save item: 11 / best_val_loss: 0.31469746232032775\n","Save item: 11 / best_val_loss: 0.30977670550346376\n","Save item: 11 / best_val_loss: 0.30395095348358153\n","Save item: 11 / best_val_loss: 0.3033001184463501\n","Save item: 11 / best_val_loss: 0.29867573976516726\n","Save item: 11 / best_val_loss: 0.2941628694534302\n","[epoch : 20 / 500] Train Loss : 0.31329505807823604\n","Save item: 11 / best_val_loss: 0.29226024746894835\n","Save item: 11 / best_val_loss: 0.29037476778030397\n","Save item: 11 / best_val_loss: 0.2902705013751984\n","Save item: 11 / best_val_loss: 0.2845793545246124\n","Save item: 11 / best_val_loss: 0.2788566708564758\n","[epoch : 30 / 500] Train Loss : 0.2985430426067776\n","Save item: 11 / best_val_loss: 0.27839553356170654\n","Save item: 11 / best_val_loss: 0.2778749346733093\n","[epoch : 40 / 500] Train Loss : 0.28157447940773433\n","Save item: 11 / best_val_loss: 0.2729199528694153\n","Save item: 11 / best_val_loss: 0.2713500767946243\n","Save item: 11 / best_val_loss: 0.2696129262447357\n","[epoch : 50 / 500] Train Loss : 0.2783674680524402\n","Save item: 11 / best_val_loss: 0.2666827797889709\n","[epoch : 60 / 500] Train Loss : 0.27260639270146686\n","Save item: 11 / best_val_loss: 0.2663481295108795\n","[epoch : 70 / 500] Train Loss : 0.2705159733692805\n","Save item: 11 / best_val_loss: 0.2662127614021301\n","Save item: 11 / best_val_loss: 0.26310832500457765\n","[epoch : 80 / 500] Train Loss : 0.2671057937873734\n","Save item: 11 / best_val_loss: 0.26227199733257295\n","Save item: 11 / best_val_loss: 0.26088805198669435\n","[epoch : 90 / 500] Train Loss : 0.26340349432494903\n","Save item: 11 / best_val_loss: 0.25915661454200745\n","Save item: 11 / best_val_loss: 0.2586411714553833\n","[epoch : 100 / 500] Train Loss : 0.2648078410161866\n","Save item: 11 / best_val_loss: 0.2584051012992859\n","[epoch : 110 / 500] Train Loss : 0.26016108360555434\n","Save item: 11 / best_val_loss: 0.2577726781368256\n","Save item: 11 / best_val_loss: 0.2575803637504578\n","[epoch : 120 / 500] Train Loss : 0.2585073485970497\n","Save item: 11 / best_val_loss: 0.25572381019592283\n","Save item: 11 / best_val_loss: 0.25368324518203733\n","[epoch : 130 / 500] Train Loss : 0.2568133895595868\n","Save item: 11 / best_val_loss: 0.25279518961906433\n","[epoch : 140 / 500] Train Loss : 0.25642714980575776\n","[epoch : 150 / 500] Train Loss : 0.2566700569457478\n","[epoch : 160 / 500] Train Loss : 0.2519802889890141\n","[epoch : 170 / 500] Train Loss : 0.25223910642994773\n","[epoch : 180 / 500] Train Loss : 0.25231576131449807\n","Save item: 11 / best_val_loss: 0.2523635298013687\n","[epoch : 190 / 500] Train Loss : 0.2515072946747144\n","Save item: 11 / best_val_loss: 0.2514737367630005\n","[epoch : 200 / 500] Train Loss : 0.24907222224606407\n","[epoch : 210 / 500] Train Loss : 0.24846082346306908\n","[epoch : 220 / 500] Train Loss : 0.24831553796927133\n","Save item: 11 / best_val_loss: 0.24909412264823913\n","[epoch : 230 / 500] Train Loss : 0.25032176656855476\n","[epoch : 240 / 500] Train Loss : 0.24899935722351074\n","[epoch : 250 / 500] Train Loss : 0.24793141997522777\n","[epoch : 260 / 500] Train Loss : 0.24979740381240845\n","[epoch : 270 / 500] Train Loss : 0.2507387176156044\n","[epoch : 280 / 500] Train Loss : 0.2504464363058408\n","[epoch : 290 / 500] Train Loss : 0.24727309081289503\n","[epoch : 300 / 500] Train Loss : 0.24687171230713525\n","Save item: 11 / best_val_loss: 0.2488359421491623\n","Save item: 11 / best_val_loss: 0.24806868135929108\n","[epoch : 310 / 500] Train Loss : 0.2473903993765513\n","[epoch : 320 / 500] Train Loss : 0.24763600611024433\n","[epoch : 330 / 500] Train Loss : 0.24629644552866617\n","Save item: 11 / best_val_loss: 0.24698227643966675\n","[epoch : 340 / 500] Train Loss : 0.24675953139861426\n","Save item: 11 / best_val_loss: 0.24682715833187102\n","Save item: 11 / best_val_loss: 0.24599937796592714\n","[epoch : 350 / 500] Train Loss : 0.24681509451733696\n","[epoch : 360 / 500] Train Loss : 0.24368305338753593\n","Save item: 11 / best_val_loss: 0.24549295604228974\n","[epoch : 370 / 500] Train Loss : 0.24380862133370507\n","[epoch : 380 / 500] Train Loss : 0.24250152044826084\n","Save item: 11 / best_val_loss: 0.24404798746109008\n","[epoch : 390 / 500] Train Loss : 0.24402104152573478\n","[epoch : 400 / 500] Train Loss : 0.24307683358589807\n","Save item: 11 / best_val_loss: 0.2432604044675827\n","[epoch : 410 / 500] Train Loss : 0.24341551545593473\n","[epoch : 420 / 500] Train Loss : 0.2439433303144243\n","[epoch : 430 / 500] Train Loss : 0.24266396711270014\n","[epoch : 440 / 500] Train Loss : 0.24123609066009521\n","[epoch : 450 / 500] Train Loss : 0.24196727905008528\n","[epoch : 460 / 500] Train Loss : 0.2424303318063418\n","[epoch : 470 / 500] Train Loss : 0.24190014021264183\n","[epoch : 480 / 500] Train Loss : 0.2413517932097117\n","[epoch : 490 / 500] Train Loss : 0.24003031104803085\n","[epoch : 500 / 500] Train Loss : 0.24041289422247145\n","1419\n","[   0.     2657.1611 3162.1729 2916.4177 3196.2234 2937.5242 3036.9187\n","    0.     2965.8105 3171.298     0.        0.        0.        0.\n","    0.        0.        0.     3096.5552 3098.8267 3177.88   3799.715\n","    0.     3525.6462 3022.0786 3230.0671 3069.2036 3378.4705 3360.535 ]\n","0.0\n","[-1.          0.08272871  0.28850874  0.1883695   0.3023835   0.19696985\n","  0.23747072 -1.          0.20849587  0.29222706 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.26177114\n","  0.2626967   0.29490897  0.54829174 -1.          0.43661535  0.23142374\n","  0.31617403  0.25062603  0.37664476  0.3693365 ]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 12 / best_val_loss: 0.3089719951152802\n","Save item: 12 / best_val_loss: 0.30287778973579405\n","Save item: 12 / best_val_loss: 0.3021524250507355\n","Save item: 12 / best_val_loss: 0.3012359499931335\n","Save item: 12 / best_val_loss: 0.299762898683548\n","Save item: 12 / best_val_loss: 0.2991482257843018\n","Save item: 12 / best_val_loss: 0.2975102424621582\n","Save item: 12 / best_val_loss: 0.2938062846660614\n","[epoch : 10 / 500] Train Loss : 0.29562581910027397\n","Save item: 12 / best_val_loss: 0.29240927696228025\n","Save item: 12 / best_val_loss: 0.2870054662227631\n","Save item: 12 / best_val_loss: 0.2847763001918793\n","Save item: 12 / best_val_loss: 0.28424444794654846\n","Save item: 12 / best_val_loss: 0.282802814245224\n","Save item: 12 / best_val_loss: 0.28187431693077086\n","Save item: 12 / best_val_loss: 0.2800097644329071\n","Save item: 12 / best_val_loss: 0.2797693729400635\n","Save item: 12 / best_val_loss: 0.27749103903770445\n","[epoch : 20 / 500] Train Loss : 0.27964771621757084\n","Save item: 12 / best_val_loss: 0.2755134284496307\n","Save item: 12 / best_val_loss: 0.2722347557544708\n","[epoch : 30 / 500] Train Loss : 0.27245137757725185\n","Save item: 12 / best_val_loss: 0.27017882466316223\n","Save item: 12 / best_val_loss: 0.26994627714157104\n","Save item: 12 / best_val_loss: 0.26913660764694214\n","Save item: 12 / best_val_loss: 0.26868011355400084\n","Save item: 12 / best_val_loss: 0.2661591708660126\n","[epoch : 40 / 500] Train Loss : 0.2641146489315563\n","Save item: 12 / best_val_loss: 0.26579135060310366\n","Save item: 12 / best_val_loss: 0.2647408783435822\n","Save item: 12 / best_val_loss: 0.26426625847816465\n","Save item: 12 / best_val_loss: 0.2629745304584503\n","[epoch : 50 / 500] Train Loss : 0.2592908466855685\n","Save item: 12 / best_val_loss: 0.26220253109931946\n","Save item: 12 / best_val_loss: 0.2615709245204926\n","[epoch : 60 / 500] Train Loss : 0.25698541435930466\n","Save item: 12 / best_val_loss: 0.26041204333305357\n","[epoch : 70 / 500] Train Loss : 0.25466736985577476\n","[epoch : 80 / 500] Train Loss : 0.25236670755677754\n","Save item: 12 / best_val_loss: 0.25873654186725614\n","[epoch : 90 / 500] Train Loss : 0.2509898394346237\n","[epoch : 100 / 500] Train Loss : 0.24984606438212925\n","[epoch : 110 / 500] Train Loss : 0.247724040514893\n","[epoch : 120 / 500] Train Loss : 0.24723077731000054\n","Save item: 12 / best_val_loss: 0.25853890776634214\n","Save item: 12 / best_val_loss: 0.25850026309490204\n","[epoch : 130 / 500] Train Loss : 0.24526576697826385\n","[epoch : 140 / 500] Train Loss : 0.24317219687832725\n","Save item: 12 / best_val_loss: 0.25845485627651216\n","Save item: 12 / best_val_loss: 0.2582146912813187\n","[epoch : 150 / 500] Train Loss : 0.24312695529725817\n","Save item: 12 / best_val_loss: 0.25725366473197936\n","[epoch : 160 / 500] Train Loss : 0.24418633348411983\n","[epoch : 170 / 500] Train Loss : 0.24260367867019442\n","Save item: 12 / best_val_loss: 0.25713334083557127\n","Save item: 12 / best_val_loss: 0.2571190446615219\n","[epoch : 180 / 500] Train Loss : 0.24174771457910538\n","Save item: 12 / best_val_loss: 0.2560878396034241\n","Save item: 12 / best_val_loss: 0.25562133491039274\n","[epoch : 190 / 500] Train Loss : 0.24111051691903007\n","[epoch : 200 / 500] Train Loss : 0.24116535236438116\n","[epoch : 210 / 500] Train Loss : 0.24139183676905102\n","[epoch : 220 / 500] Train Loss : 0.23878102087312275\n","[epoch : 230 / 500] Train Loss : 0.23945168985260856\n","[epoch : 240 / 500] Train Loss : 0.23879092186689377\n","Save item: 12 / best_val_loss: 0.2544739663600922\n","[epoch : 250 / 500] Train Loss : 0.23771117296483782\n","[epoch : 260 / 500] Train Loss : 0.2392296443382899\n","[epoch : 270 / 500] Train Loss : 0.24032869189977646\n","[epoch : 280 / 500] Train Loss : 0.23918713712029988\n","[epoch : 290 / 500] Train Loss : 0.24078486694229972\n","Save item: 12 / best_val_loss: 0.2536676287651062\n","[epoch : 300 / 500] Train Loss : 0.23791685120926964\n","[epoch : 310 / 500] Train Loss : 0.2396804326110416\n","[epoch : 320 / 500] Train Loss : 0.23826896730396482\n","[epoch : 330 / 500] Train Loss : 0.23885265075498158\n","[epoch : 340 / 500] Train Loss : 0.23715894420941672\n","[epoch : 350 / 500] Train Loss : 0.23771135260661444\n","[epoch : 360 / 500] Train Loss : 0.23671475797891617\n","[epoch : 370 / 500] Train Loss : 0.23528410577111775\n","[epoch : 380 / 500] Train Loss : 0.235391771627797\n","[epoch : 390 / 500] Train Loss : 0.23574763453669018\n","[epoch : 400 / 500] Train Loss : 0.2353471674852901\n","[epoch : 410 / 500] Train Loss : 0.2347389774190055\n","Save item: 12 / best_val_loss: 0.2536616712808609\n","[epoch : 420 / 500] Train Loss : 0.23557334062125948\n","[epoch : 430 / 500] Train Loss : 0.23506020423438814\n","Save item: 12 / best_val_loss: 0.2536183685064316\n","[epoch : 440 / 500] Train Loss : 0.23472760286596087\n","[epoch : 450 / 500] Train Loss : 0.23471640050411224\n","[epoch : 460 / 500] Train Loss : 0.23436948574251598\n","[epoch : 470 / 500] Train Loss : 0.23508384658230674\n","[epoch : 480 / 500] Train Loss : 0.23460801359679964\n","[epoch : 490 / 500] Train Loss : 0.23401074608167013\n","Save item: 12 / best_val_loss: 0.25273463428020476\n","[epoch : 500 / 500] Train Loss : 0.23410357534885406\n","1419\n","[   0.     3285.7615 3432.5537 3228.7976 3171.2815 3191.567  3862.5522\n"," 5940.1406 3368.749  3379.6091    0.        0.        0.        0.\n","    0.        0.        0.     3148.7773 3029.0005 3088.4521 3325.834\n","    0.     3037.3674 3121.1575 3183.846  3142.84   3200.1543 3118.649 ]\n","0.0\n","[-1.          0.15901344  0.21079265  0.1389201   0.11863197  0.1257874\n","  0.36246952  1.0953143   0.1882863   0.19211708 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.1106939\n","  0.06844403  0.08941489  0.17314853 -1.          0.07139537  0.10095131\n","  0.12306394  0.1085996   0.12881652  0.10006645]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 13 / best_val_loss: 0.3130020976066589\n","Save item: 13 / best_val_loss: 0.30725033283233644\n","Save item: 13 / best_val_loss: 0.3060318171977997\n","Save item: 13 / best_val_loss: 0.3057730674743652\n","Save item: 13 / best_val_loss: 0.3050998508930206\n","Save item: 13 / best_val_loss: 0.3042660176753998\n","Save item: 13 / best_val_loss: 0.30335658192634585\n","Save item: 13 / best_val_loss: 0.30277161598205565\n","[epoch : 10 / 500] Train Loss : 0.30334657099511886\n","Save item: 13 / best_val_loss: 0.30239142179489137\n","Save item: 13 / best_val_loss: 0.30233874917030334\n","Save item: 13 / best_val_loss: 0.3011587083339691\n","Save item: 13 / best_val_loss: 0.30025272369384765\n","Save item: 13 / best_val_loss: 0.2996488094329834\n","Save item: 13 / best_val_loss: 0.2982940971851349\n","Save item: 13 / best_val_loss: 0.29772854447364805\n","Save item: 13 / best_val_loss: 0.2959927499294281\n","Save item: 13 / best_val_loss: 0.29535268545150756\n","Save item: 13 / best_val_loss: 0.29405311942100526\n","[epoch : 20 / 500] Train Loss : 0.2917148636447059\n","Save item: 13 / best_val_loss: 0.2935150027275085\n","Save item: 13 / best_val_loss: 0.29039399027824403\n","Save item: 13 / best_val_loss: 0.2896104633808136\n","Save item: 13 / best_val_loss: 0.28922185897827146\n","Save item: 13 / best_val_loss: 0.2890935897827148\n","Save item: 13 / best_val_loss: 0.288373726606369\n","Save item: 13 / best_val_loss: 0.2867924213409424\n","[epoch : 30 / 500] Train Loss : 0.2806753052605523\n","Save item: 13 / best_val_loss: 0.28421151638031006\n","Save item: 13 / best_val_loss: 0.28357704877853396\n","Save item: 13 / best_val_loss: 0.2804758548736572\n","Save item: 13 / best_val_loss: 0.2788328766822815\n","Save item: 13 / best_val_loss: 0.27554413080215456\n","Save item: 13 / best_val_loss: 0.27336368560791013\n","[epoch : 40 / 500] Train Loss : 0.2717614455355538\n","Save item: 13 / best_val_loss: 0.27277069091796874\n","[epoch : 50 / 500] Train Loss : 0.2630501662691434\n","Save item: 13 / best_val_loss: 0.27029587924480436\n","Save item: 13 / best_val_loss: 0.26879187524318693\n","[epoch : 60 / 500] Train Loss : 0.2598981178469128\n","Save item: 13 / best_val_loss: 0.2675774931907654\n","Save item: 13 / best_val_loss: 0.2671893000602722\n","[epoch : 70 / 500] Train Loss : 0.25681595007578534\n","Save item: 13 / best_val_loss: 0.26644901037216184\n","Save item: 13 / best_val_loss: 0.2662957638502121\n","Save item: 13 / best_val_loss: 0.2652821928262711\n","Save item: 13 / best_val_loss: 0.26470462083816526\n","[epoch : 80 / 500] Train Loss : 0.2510419570737415\n","Save item: 13 / best_val_loss: 0.2627562642097473\n","[epoch : 90 / 500] Train Loss : 0.2514122633470429\n","[epoch : 100 / 500] Train Loss : 0.24663031680716407\n","[epoch : 110 / 500] Train Loss : 0.24538944992754194\n","Save item: 13 / best_val_loss: 0.26260809004306795\n","Save item: 13 / best_val_loss: 0.26234184205532074\n","[epoch : 120 / 500] Train Loss : 0.24495491137107214\n","Save item: 13 / best_val_loss: 0.2614076018333435\n","Save item: 13 / best_val_loss: 0.2593186616897583\n","[epoch : 130 / 500] Train Loss : 0.2429671660065651\n","[epoch : 140 / 500] Train Loss : 0.24116801801655027\n","Save item: 13 / best_val_loss: 0.2577428072690964\n","Save item: 13 / best_val_loss: 0.2577113389968872\n","[epoch : 150 / 500] Train Loss : 0.24232024947802225\n","[epoch : 160 / 500] Train Loss : 0.23906310730510288\n","Save item: 13 / best_val_loss: 0.25705985724925995\n","[epoch : 170 / 500] Train Loss : 0.2395571677221192\n","[epoch : 180 / 500] Train Loss : 0.23892130123244393\n","[epoch : 190 / 500] Train Loss : 0.23782910158236822\n","[epoch : 200 / 500] Train Loss : 0.23747784313228396\n","[epoch : 210 / 500] Train Loss : 0.23825569285286796\n","[epoch : 220 / 500] Train Loss : 0.23671220077408683\n","Save item: 13 / best_val_loss: 0.25689717531204226\n","Save item: 13 / best_val_loss: 0.25656984746456146\n","[epoch : 230 / 500] Train Loss : 0.2362815183069971\n","[epoch : 240 / 500] Train Loss : 0.23525378190808827\n","Save item: 13 / best_val_loss: 0.25309556126594546\n","[epoch : 250 / 500] Train Loss : 0.23565583096610176\n","[epoch : 260 / 500] Train Loss : 0.23815958119100994\n","[epoch : 270 / 500] Train Loss : 0.23784151838885415\n","[epoch : 280 / 500] Train Loss : 0.23653671890497208\n","[epoch : 290 / 500] Train Loss : 0.23700852774911457\n","[epoch : 300 / 500] Train Loss : 0.2362577501270506\n","[epoch : 310 / 500] Train Loss : 0.23558487412002352\n","[epoch : 320 / 500] Train Loss : 0.2341118413541052\n","[epoch : 330 / 500] Train Loss : 0.2338355647193061\n","[epoch : 340 / 500] Train Loss : 0.23495625207821527\n","[epoch : 350 / 500] Train Loss : 0.23422978901200825\n","[epoch : 360 / 500] Train Loss : 0.234568537109428\n","[epoch : 370 / 500] Train Loss : 0.23325728376706442\n","[epoch : 380 / 500] Train Loss : 0.23337543424632815\n","Save item: 13 / best_val_loss: 0.2516386777162552\n","[epoch : 390 / 500] Train Loss : 0.2330223884847429\n","[epoch : 400 / 500] Train Loss : 0.23216134889258278\n","[epoch : 410 / 500] Train Loss : 0.23180032604270512\n","[epoch : 420 / 500] Train Loss : 0.23154438700940874\n","[epoch : 430 / 500] Train Loss : 0.23185278061363432\n","[epoch : 440 / 500] Train Loss : 0.2314236437280973\n","[epoch : 450 / 500] Train Loss : 0.23080091178417206\n","[epoch : 460 / 500] Train Loss : 0.23213501440154183\n","[epoch : 470 / 500] Train Loss : 0.23117601457569334\n","[epoch : 480 / 500] Train Loss : 0.23175641232066685\n","[epoch : 490 / 500] Train Loss : 0.23149688045183817\n","[epoch : 500 / 500] Train Loss : 0.230424954659409\n","1419\n","[   0.     8060.652  8201.389  7534.9995 7857.1016 8121.9536 6736.333\n","    0.     7574.841  7228.922     0.        0.        0.        0.\n","    0.        0.        0.     6207.2275 8271.914  9699.653  7199.2905\n","    0.     9008.501  7645.7627 7426.3037 8055.839  7410.1016 7427.842 ]\n","0.0\n","[-1.          0.16027194  0.18052998  0.08460812  0.13097236  0.16909589\n"," -0.03035408 -1.          0.09034299  0.04055049 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.10651495\n","  0.1906816   0.39619422  0.03628527 -1.          0.2967079   0.10055168\n","  0.06896216  0.15957916  0.06662998  0.06918356]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 14 / best_val_loss: 0.37947877645492556\n","Save item: 14 / best_val_loss: 0.37435478568077085\n","Save item: 14 / best_val_loss: 0.3736458420753479\n","Save item: 14 / best_val_loss: 0.37331026792526245\n","Save item: 14 / best_val_loss: 0.37275549173355105\n","Save item: 14 / best_val_loss: 0.3720718681812286\n","Save item: 14 / best_val_loss: 0.3718067169189453\n","[epoch : 10 / 500] Train Loss : 1.4220583190520604\n","Save item: 14 / best_val_loss: 0.37158949971199035\n","Save item: 14 / best_val_loss: 0.37048165798187255\n","Save item: 14 / best_val_loss: 0.36927762627601624\n","Save item: 14 / best_val_loss: 0.3683093786239624\n","Save item: 14 / best_val_loss: 0.3659590184688568\n","Save item: 14 / best_val_loss: 0.36483917236328123\n","Save item: 14 / best_val_loss: 0.36282541155815123\n","Save item: 14 / best_val_loss: 0.3618322014808655\n","[epoch : 20 / 500] Train Loss : 1.4103222009208467\n","Save item: 14 / best_val_loss: 0.36168452501297\n","Save item: 14 / best_val_loss: 0.36073386669158936\n","Save item: 14 / best_val_loss: 0.3597377121448517\n","Save item: 14 / best_val_loss: 0.358182430267334\n","[epoch : 30 / 500] Train Loss : 1.402990041507615\n","Save item: 14 / best_val_loss: 0.35469071865081786\n","Save item: 14 / best_val_loss: 0.35124618411064146\n","Save item: 14 / best_val_loss: 0.3507376253604889\n","Save item: 14 / best_val_loss: 0.34993953108787534\n","[epoch : 40 / 500] Train Loss : 1.3951085689995024\n","Save item: 14 / best_val_loss: 0.3484852254390717\n","Save item: 14 / best_val_loss: 0.3473421335220337\n","Save item: 14 / best_val_loss: 0.3470360219478607\n","Save item: 14 / best_val_loss: 0.3469704329967499\n","Save item: 14 / best_val_loss: 0.3458509981632233\n","[epoch : 50 / 500] Train Loss : 1.386716698606809\n","Save item: 14 / best_val_loss: 0.3433059811592102\n","Save item: 14 / best_val_loss: 0.34297834038734437\n","Save item: 14 / best_val_loss: 0.3429556429386139\n","Save item: 14 / best_val_loss: 0.34205701351165774\n","Save item: 14 / best_val_loss: 0.3402673065662384\n","[epoch : 60 / 500] Train Loss : 1.3796980728705723\n","Save item: 14 / best_val_loss: 0.33876231908798216\n","[epoch : 70 / 500] Train Loss : 1.3746116790506575\n","Save item: 14 / best_val_loss: 0.338384336233139\n","[epoch : 80 / 500] Train Loss : 1.3703134506940842\n","Save item: 14 / best_val_loss: 0.33703247308731077\n","[epoch : 90 / 500] Train Loss : 1.367855644888348\n","Save item: 14 / best_val_loss: 0.3361054837703705\n","Save item: 14 / best_val_loss: 0.3345166504383087\n","[epoch : 100 / 500] Train Loss : 1.3641234404510922\n","Save item: 14 / best_val_loss: 0.3327948868274689\n","[epoch : 110 / 500] Train Loss : 1.7457191132836871\n","[epoch : 120 / 500] Train Loss : 1.3605363269646962\n","[epoch : 130 / 500] Train Loss : 1.358600452542305\n","[epoch : 140 / 500] Train Loss : 1.3555327107508977\n","[epoch : 150 / 500] Train Loss : 1.356245348850886\n","[epoch : 160 / 500] Train Loss : 1.3550529330968857\n","[epoch : 170 / 500] Train Loss : 1.3511884709199269\n","[epoch : 180 / 500] Train Loss : 1.3537193255292044\n","[epoch : 190 / 500] Train Loss : 1.3522590034537845\n","[epoch : 200 / 500] Train Loss : 1.3507899194955826\n","[epoch : 210 / 500] Train Loss : 1.7331510037183762\n","[epoch : 220 / 500] Train Loss : 1.347268237007989\n","[epoch : 230 / 500] Train Loss : 1.348290589120653\n","[epoch : 240 / 500] Train Loss : 1.3499772499005\n","[epoch : 250 / 500] Train Loss : 1.34648630519708\n","Save item: 14 / best_val_loss: 0.33242288827896116\n","[epoch : 260 / 500] Train Loss : 1.3503034661213558\n","[epoch : 270 / 500] Train Loss : 1.3520601077212229\n","Save item: 14 / best_val_loss: 0.33133759498596194\n","[epoch : 280 / 500] Train Loss : 1.349737470348676\n","[epoch : 290 / 500] Train Loss : 1.3526543759637408\n","[epoch : 300 / 500] Train Loss : 1.3489694330427382\n","[epoch : 310 / 500] Train Loss : 1.34788982073466\n","Save item: 14 / best_val_loss: 0.330272251367569\n","[epoch : 320 / 500] Train Loss : 1.34521012670464\n","[epoch : 330 / 500] Train Loss : 1.3456969973113801\n","[epoch : 340 / 500] Train Loss : 1.3463793214824464\n","[epoch : 350 / 500] Train Loss : 1.3434855656491385\n","[epoch : 360 / 500] Train Loss : 1.344391029742029\n","[epoch : 370 / 500] Train Loss : 1.3426203380028408\n","Save item: 14 / best_val_loss: 0.3291944324970245\n","[epoch : 380 / 500] Train Loss : 1.3430471983220842\n","[epoch : 390 / 500] Train Loss : 1.3423530293835535\n","[epoch : 400 / 500] Train Loss : 1.3420068836874433\n","[epoch : 410 / 500] Train Loss : 1.3421961002879672\n","[epoch : 420 / 500] Train Loss : 1.3431502497858472\n","Save item: 14 / best_val_loss: 0.3291128516197205\n","[epoch : 430 / 500] Train Loss : 1.3424863484170702\n","[epoch : 440 / 500] Train Loss : 1.3418332305219438\n","[epoch : 450 / 500] Train Loss : 1.3443175090683832\n","[epoch : 460 / 500] Train Loss : 1.3420266873306699\n","[epoch : 470 / 500] Train Loss : 1.3413964062929153\n","[epoch : 480 / 500] Train Loss : 1.341177021463712\n","[epoch : 490 / 500] Train Loss : 1.3430853419833713\n","Save item: 14 / best_val_loss: 0.3282989263534546\n","[epoch : 500 / 500] Train Loss : 1.3418294952975378\n","1419\n","[   0.     1365.8031 1671.7744 1515.5458 1456.9727 1806.1057 1998.9817\n"," 1755.1871 2057.7605 2206.866     0.        0.        0.        0.\n","    0.        0.        0.     2626.2944 3367.233  3123.3804 3090.0557\n","    0.     3067.6152 3202.5312 3195.0693 2991.539  2943.3457 2779.9414]\n","0.0\n","[-1.0000000e+00 -2.4397674e-01 -7.4610144e-02 -1.6108856e-01\n"," -1.9351098e-01 -2.5273170e-04  1.0651136e-01 -2.8438076e-02\n","  1.3904764e-01  2.2158310e-01 -1.0000000e+00 -1.0000000e+00\n"," -1.0000000e+00 -1.0000000e+00 -1.0000000e+00 -1.0000000e+00\n"," -1.0000000e+00  4.5375249e-01  8.6388975e-01  7.2890824e-01\n","  7.1046174e-01 -1.0000000e+00  6.9804013e-01  7.7272123e-01\n","  7.6859075e-01  6.5592909e-01  6.2925225e-01  5.3880185e-01]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 15 / best_val_loss: 0.40949292182922364\n","Save item: 15 / best_val_loss: 0.40170632004737855\n","Save item: 15 / best_val_loss: 0.39972413182258604\n","Save item: 15 / best_val_loss: 0.39553563594818114\n","Save item: 15 / best_val_loss: 0.39446437954902647\n","Save item: 15 / best_val_loss: 0.3939831018447876\n","Save item: 15 / best_val_loss: 0.39307457208633423\n","Save item: 15 / best_val_loss: 0.3895559549331665\n","[epoch : 10 / 500] Train Loss : 0.38860930999120075\n","Save item: 15 / best_val_loss: 0.3867268621921539\n","Save item: 15 / best_val_loss: 0.38472694158554077\n","Save item: 15 / best_val_loss: 0.38337820768356323\n","Save item: 15 / best_val_loss: 0.38246861696243284\n","Save item: 15 / best_val_loss: 0.3808245837688446\n","Save item: 15 / best_val_loss: 0.3768324613571167\n","Save item: 15 / best_val_loss: 0.37238508462905884\n","[epoch : 20 / 500] Train Loss : 0.3682213905784819\n","Save item: 15 / best_val_loss: 0.36857702136039733\n","Save item: 15 / best_val_loss: 0.3672866702079773\n","Save item: 15 / best_val_loss: 0.3652768611907959\n","[epoch : 30 / 500] Train Loss : 0.3571968790557649\n","Save item: 15 / best_val_loss: 0.3640405833721161\n","Save item: 15 / best_val_loss: 0.3630970358848572\n","Save item: 15 / best_val_loss: 0.3589870274066925\n","Save item: 15 / best_val_loss: 0.3585392236709595\n","Save item: 15 / best_val_loss: 0.35564913749694826\n","Save item: 15 / best_val_loss: 0.3506873071193695\n","[epoch : 40 / 500] Train Loss : 0.34216858943303424\n","Save item: 15 / best_val_loss: 0.3467229902744293\n","Save item: 15 / best_val_loss: 0.34370713829994204\n","Save item: 15 / best_val_loss: 0.34355531334877015\n","Save item: 15 / best_val_loss: 0.3362365126609802\n","Save item: 15 / best_val_loss: 0.33402496576309204\n","[epoch : 50 / 500] Train Loss : 0.32365064322948456\n","Save item: 15 / best_val_loss: 0.32886402010917665\n","Save item: 15 / best_val_loss: 0.3241796731948853\n","Save item: 15 / best_val_loss: 0.32263401746749876\n","Save item: 15 / best_val_loss: 0.3145543038845062\n","[epoch : 60 / 500] Train Loss : 0.30556222630871666\n","Save item: 15 / best_val_loss: 0.3143643200397491\n","Save item: 15 / best_val_loss: 0.31136312484741213\n","Save item: 15 / best_val_loss: 0.3042355179786682\n","[epoch : 70 / 500] Train Loss : 0.29398975935247207\n","Save item: 15 / best_val_loss: 0.30336993336677553\n","[epoch : 80 / 500] Train Loss : 0.29170947935846114\n","Save item: 15 / best_val_loss: 0.3027160167694092\n","Save item: 15 / best_val_loss: 0.3014379382133484\n","Save item: 15 / best_val_loss: 0.2994990885257721\n","[epoch : 90 / 500] Train Loss : 0.28569108413325417\n","Save item: 15 / best_val_loss: 0.2972717881202698\n","Save item: 15 / best_val_loss: 0.2966844797134399\n","[epoch : 100 / 500] Train Loss : 0.2837400005923377\n","Save item: 15 / best_val_loss: 0.2950491964817047\n","Save item: 15 / best_val_loss: 0.29163884520530703\n","[epoch : 110 / 500] Train Loss : 0.2795433716641532\n","[epoch : 120 / 500] Train Loss : 0.28150461117426556\n","Save item: 15 / best_val_loss: 0.2908505141735077\n","[epoch : 130 / 500] Train Loss : 0.27750321063730454\n","[epoch : 140 / 500] Train Loss : 0.27783208588759106\n","[epoch : 150 / 500] Train Loss : 0.2763332409991158\n","[epoch : 160 / 500] Train Loss : 0.27601081960731083\n","[epoch : 170 / 500] Train Loss : 0.27330392102400464\n","Save item: 15 / best_val_loss: 0.28935037851333617\n","Save item: 15 / best_val_loss: 0.28825314044952394\n","[epoch : 180 / 500] Train Loss : 0.2737802035278744\n","Save item: 15 / best_val_loss: 0.28773091435432435\n","[epoch : 190 / 500] Train Loss : 0.27057457798057133\n","[epoch : 200 / 500] Train Loss : 0.26838747825887466\n","[epoch : 210 / 500] Train Loss : 0.26952921433581245\n","Save item: 15 / best_val_loss: 0.2848509311676025\n","[epoch : 220 / 500] Train Loss : 0.2699212572640843\n","Save item: 15 / best_val_loss: 0.28427913784980774\n","[epoch : 230 / 500] Train Loss : 0.2703157199753655\n","Save item: 15 / best_val_loss: 0.28302788734436035\n","[epoch : 240 / 500] Train Loss : 0.2683446970250871\n","[epoch : 250 / 500] Train Loss : 0.2685775135954221\n","[epoch : 260 / 500] Train Loss : 0.27305300202634597\n","[epoch : 270 / 500] Train Loss : 0.2680283486843109\n","[epoch : 280 / 500] Train Loss : 0.26664435863494873\n","Save item: 15 / best_val_loss: 0.2824814975261688\n","[epoch : 290 / 500] Train Loss : 0.2695295123590363\n","[epoch : 300 / 500] Train Loss : 0.26975642806953853\n","[epoch : 310 / 500] Train Loss : 0.26698415726423264\n","[epoch : 320 / 500] Train Loss : 0.2668551339043511\n","[epoch : 330 / 500] Train Loss : 0.26533757895231247\n","Save item: 15 / best_val_loss: 0.2809194207191467\n","[epoch : 340 / 500] Train Loss : 0.2665254928999477\n","Save item: 15 / best_val_loss: 0.2800394594669342\n","[epoch : 350 / 500] Train Loss : 0.2663797578877873\n","[epoch : 360 / 500] Train Loss : 0.26385341419114006\n","[epoch : 370 / 500] Train Loss : 0.2638722774055269\n","[epoch : 380 / 500] Train Loss : 0.262784024907483\n","Save item: 15 / best_val_loss: 0.2794332206249237\n","[epoch : 390 / 500] Train Loss : 0.26244162519772846\n","[epoch : 400 / 500] Train Loss : 0.2613070433338483\n","Save item: 15 / best_val_loss: 0.2787664532661438\n","[epoch : 410 / 500] Train Loss : 0.26327840983867645\n","[epoch : 420 / 500] Train Loss : 0.26278553158044815\n","Save item: 15 / best_val_loss: 0.2752978026866913\n","[epoch : 430 / 500] Train Loss : 0.2616467641459571\n","[epoch : 440 / 500] Train Loss : 0.26220786654286915\n","[epoch : 450 / 500] Train Loss : 0.26289040512508816\n","[epoch : 460 / 500] Train Loss : 0.2609604050715764\n","[epoch : 470 / 500] Train Loss : 0.2613892952601115\n","[epoch : 480 / 500] Train Loss : 0.2608928001589245\n","[epoch : 490 / 500] Train Loss : 0.26208459254768157\n","[epoch : 500 / 500] Train Loss : 0.261709440085623\n","1419\n","[   0.     3679.0647 2911.0198 3433.0632 4417.073  3318.4397 3696.5413\n","    0.     4136.2603 3991.7676    0.        0.        0.        0.\n","    0.        0.        0.     6124.235  5696.5815 5808.288  5700.842\n","    0.     6418.821  5881.1357 5788.7705 5825.532  5885.196  6059.2056]\n","0.0\n","[-1.         -0.11340306 -0.29848987 -0.17268555  0.06444544 -0.20030802\n"," -0.10919148 -1.         -0.0032261  -0.03804656 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.47584462\n","  0.37278688  0.3997064   0.37381354 -1.          0.54683524  0.41726154\n","  0.39500296  0.40386197  0.41823995  0.46017358]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 16 / best_val_loss: 0.5613817691802978\n","Save item: 16 / best_val_loss: 0.5550431489944458\n","Save item: 16 / best_val_loss: 0.5510350108146668\n","Save item: 16 / best_val_loss: 0.547210967540741\n","Save item: 16 / best_val_loss: 0.5427588999271393\n","Save item: 16 / best_val_loss: 0.5424667119979858\n","Save item: 16 / best_val_loss: 0.5374623954296112\n","Save item: 16 / best_val_loss: 0.5329755663871765\n","Save item: 16 / best_val_loss: 0.5286726593971253\n","[epoch : 10 / 500] Train Loss : 0.5034844709767236\n","Save item: 16 / best_val_loss: 0.5262657999992371\n","Save item: 16 / best_val_loss: 0.5225511789321899\n","Save item: 16 / best_val_loss: 0.5190966904163361\n","Save item: 16 / best_val_loss: 0.5183051645755767\n","Save item: 16 / best_val_loss: 0.5131944715976715\n","Save item: 16 / best_val_loss: 0.5125829160213471\n","[epoch : 20 / 500] Train Loss : 0.4790672991010878\n","Save item: 16 / best_val_loss: 0.5125599205493927\n","Save item: 16 / best_val_loss: 0.5048445165157318\n","Save item: 16 / best_val_loss: 0.5040116012096405\n","Save item: 16 / best_val_loss: 0.5010998964309692\n","[epoch : 30 / 500] Train Loss : 0.47018056114514667\n","Save item: 16 / best_val_loss: 0.4995945870876312\n","Save item: 16 / best_val_loss: 0.49635077714920045\n","Save item: 16 / best_val_loss: 0.49389730095863343\n","[epoch : 40 / 500] Train Loss : 0.4544134951300091\n","Save item: 16 / best_val_loss: 0.49009792804718016\n","Save item: 16 / best_val_loss: 0.4874884009361267\n","Save item: 16 / best_val_loss: 0.4860533893108368\n","Save item: 16 / best_val_loss: 0.48325044512748716\n","Save item: 16 / best_val_loss: 0.47671458721160886\n","[epoch : 50 / 500] Train Loss : 0.4407139370838801\n","Save item: 16 / best_val_loss: 0.4741813957691193\n","Save item: 16 / best_val_loss: 0.4695929229259491\n","[epoch : 60 / 500] Train Loss : 0.42647742066118455\n","Save item: 16 / best_val_loss: 0.46940079927444456\n","Save item: 16 / best_val_loss: 0.4674688637256622\n","[epoch : 70 / 500] Train Loss : 0.42100779877768624\n","Save item: 16 / best_val_loss: 0.4649667739868164\n","Save item: 16 / best_val_loss: 0.4625979959964752\n","Save item: 16 / best_val_loss: 0.45919702649116517\n","[epoch : 80 / 500] Train Loss : 0.415831552611457\n","[epoch : 90 / 500] Train Loss : 0.4120170755518807\n","Save item: 16 / best_val_loss: 0.4579685807228088\n","Save item: 16 / best_val_loss: 0.4536009967327118\n","[epoch : 100 / 500] Train Loss : 0.40836389859517414\n","[epoch : 110 / 500] Train Loss : 0.40663714706897736\n","[epoch : 120 / 500] Train Loss : 0.4044291592306561\n","Save item: 16 / best_val_loss: 0.4508371651172638\n","[epoch : 130 / 500] Train Loss : 0.4022374302148819\n","[epoch : 140 / 500] Train Loss : 0.40276433361901176\n","[epoch : 150 / 500] Train Loss : 0.40143095122443306\n","[epoch : 160 / 500] Train Loss : 0.3965846382909351\n","[epoch : 170 / 500] Train Loss : 0.39669859906037647\n","[epoch : 180 / 500] Train Loss : 0.3944617261489232\n","[epoch : 190 / 500] Train Loss : 0.3929014487398995\n","Save item: 16 / best_val_loss: 0.4503463268280029\n","[epoch : 200 / 500] Train Loss : 0.3924875673320558\n","[epoch : 210 / 500] Train Loss : 0.39262412157323623\n","Save item: 16 / best_val_loss: 0.4495944619178772\n","[epoch : 220 / 500] Train Loss : 0.38974249362945557\n","Save item: 16 / best_val_loss: 0.4491098463535309\n","Save item: 16 / best_val_loss: 0.44830875396728515\n","[epoch : 230 / 500] Train Loss : 0.38976698120435077\n","Save item: 16 / best_val_loss: 0.4479291200637817\n","Save item: 16 / best_val_loss: 0.4460818886756897\n","[epoch : 240 / 500] Train Loss : 0.3897334784269333\n","[epoch : 250 / 500] Train Loss : 0.3910262617799971\n","Save item: 16 / best_val_loss: 0.4451653063297272\n","[epoch : 260 / 500] Train Loss : 0.3919023821751277\n","[epoch : 270 / 500] Train Loss : 0.39002459247907\n","Save item: 16 / best_val_loss: 0.4434730768203735\n","[epoch : 280 / 500] Train Loss : 0.3909984843598472\n","[epoch : 290 / 500] Train Loss : 0.3901901708708869\n","[epoch : 300 / 500] Train Loss : 0.3902004410823186\n","[epoch : 310 / 500] Train Loss : 0.3873445640007655\n","Save item: 16 / best_val_loss: 0.44135903716087344\n","[epoch : 320 / 500] Train Loss : 0.3882398390107685\n","[epoch : 330 / 500] Train Loss : 0.38616005414062077\n","Save item: 16 / best_val_loss: 0.43907464742660524\n","[epoch : 340 / 500] Train Loss : 0.3877548608514998\n","[epoch : 350 / 500] Train Loss : 0.3867383218473858\n","[epoch : 360 / 500] Train Loss : 0.3832083029879464\n","[epoch : 370 / 500] Train Loss : 0.38471130861176384\n","[epoch : 380 / 500] Train Loss : 0.3826316263940599\n","[epoch : 390 / 500] Train Loss : 0.3796916835837894\n","[epoch : 400 / 500] Train Loss : 0.38097219665845233\n","[epoch : 410 / 500] Train Loss : 0.38003555105792153\n","[epoch : 420 / 500] Train Loss : 0.3814305199517144\n","[epoch : 430 / 500] Train Loss : 0.38058249321248794\n","[epoch : 440 / 500] Train Loss : 0.3827687485350503\n","Save item: 16 / best_val_loss: 0.43693398833274844\n","[epoch : 450 / 500] Train Loss : 0.37997784713904065\n","[epoch : 460 / 500] Train Loss : 0.3794017599688636\n","[epoch : 470 / 500] Train Loss : 0.37677678134706283\n","[epoch : 480 / 500] Train Loss : 0.3785088277525372\n","Save item: 16 / best_val_loss: 0.43559027314186094\n","[epoch : 490 / 500] Train Loss : 0.37723344730006325\n","[epoch : 500 / 500] Train Loss : 0.37818444934156203\n","1419\n","[   0.     2691.361  2626.698  2641.7498 2685.8555 2693.5476 2569.902\n"," 1355.64   2672.618  2600.731     0.        0.        0.        0.\n","    0.        0.        0.     2522.346  2554.4153 2720.6343 2691.2864\n","    0.     2940.7373 2849.807  2918.8289 2999.151  2960.7444 2920.9604]\n","0.0\n","[-1.         -0.14996052 -0.1703837  -0.16562976 -0.15169941 -0.14926992\n"," -0.18832213 -0.5718347  -0.15588036 -0.17858514 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.20334226\n"," -0.19321348 -0.14071487 -0.14998412 -1.         -0.07119754 -0.09991699\n"," -0.0781171  -0.0527482  -0.0648785  -0.07744386]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 17 / best_val_loss: 0.4130125045776367\n","Save item: 17 / best_val_loss: 0.40602230429649355\n","Save item: 17 / best_val_loss: 0.4040661871433258\n","Save item: 17 / best_val_loss: 0.40128602385520934\n","Save item: 17 / best_val_loss: 0.4010004043579102\n","Save item: 17 / best_val_loss: 0.3972226917743683\n","Save item: 17 / best_val_loss: 0.3932234764099121\n","Save item: 17 / best_val_loss: 0.39184693098068235\n","[epoch : 10 / 500] Train Loss : 0.39629272785451675\n","Save item: 17 / best_val_loss: 0.3856197953224182\n","Save item: 17 / best_val_loss: 0.3809514582157135\n","Save item: 17 / best_val_loss: 0.37727086544036864\n","Save item: 17 / best_val_loss: 0.37672154903411864\n","Save item: 17 / best_val_loss: 0.372045236825943\n","Save item: 17 / best_val_loss: 0.37105169892311096\n","Save item: 17 / best_val_loss: 0.36980122327804565\n","Save item: 17 / best_val_loss: 0.36909862160682677\n","[epoch : 20 / 500] Train Loss : 0.3745315985547172\n","Save item: 17 / best_val_loss: 0.36769800186157225\n","Save item: 17 / best_val_loss: 0.36697099804878236\n","Save item: 17 / best_val_loss: 0.3667785882949829\n","Save item: 17 / best_val_loss: 0.3642148435115814\n","Save item: 17 / best_val_loss: 0.36106773018836974\n","Save item: 17 / best_val_loss: 0.35988059639930725\n","Save item: 17 / best_val_loss: 0.3583029627799988\n","[epoch : 30 / 500] Train Loss : 0.3594575673341751\n","Save item: 17 / best_val_loss: 0.355308473110199\n","Save item: 17 / best_val_loss: 0.3542034924030304\n","Save item: 17 / best_val_loss: 0.352689391374588\n","Save item: 17 / best_val_loss: 0.3490114152431488\n","Save item: 17 / best_val_loss: 0.34838863611221316\n","Save item: 17 / best_val_loss: 0.34379799365997316\n","[epoch : 40 / 500] Train Loss : 0.3394551972548167\n","Save item: 17 / best_val_loss: 0.34091129899024963\n","Save item: 17 / best_val_loss: 0.3390706300735474\n","Save item: 17 / best_val_loss: 0.3373119175434113\n","[epoch : 50 / 500] Train Loss : 0.3258320689201355\n","Save item: 17 / best_val_loss: 0.3350449502468109\n","Save item: 17 / best_val_loss: 0.33350332975387575\n","Save item: 17 / best_val_loss: 0.32885432839393614\n","[epoch : 60 / 500] Train Loss : 0.3192567345168855\n","Save item: 17 / best_val_loss: 0.32777718305587766\n","[epoch : 70 / 500] Train Loss : 0.3148183077573776\n","Save item: 17 / best_val_loss: 0.326514858007431\n","Save item: 17 / best_val_loss: 0.3199265718460083\n","[epoch : 80 / 500] Train Loss : 0.31086889902750653\n","[epoch : 90 / 500] Train Loss : 0.30621371335453457\n","Save item: 17 / best_val_loss: 0.31946154236793517\n","Save item: 17 / best_val_loss: 0.3161365032196045\n","[epoch : 100 / 500] Train Loss : 0.3043666448858049\n","Save item: 17 / best_val_loss: 0.31277955174446104\n","[epoch : 110 / 500] Train Loss : 0.3023068093591266\n","Save item: 17 / best_val_loss: 0.3124121904373169\n","[epoch : 120 / 500] Train Loss : 0.30374281770653194\n","[epoch : 130 / 500] Train Loss : 0.3008754137489531\n","Save item: 17 / best_val_loss: 0.31045365929603574\n","[epoch : 140 / 500] Train Loss : 0.29892273909515804\n","[epoch : 150 / 500] Train Loss : 0.2972082429462009\n","Save item: 17 / best_val_loss: 0.31009283661842346\n","[epoch : 160 / 500] Train Loss : 0.29888396130667794\n","Save item: 17 / best_val_loss: 0.30938506722450254\n","[epoch : 170 / 500] Train Loss : 0.2944112287627326\n","Save item: 17 / best_val_loss: 0.30883963108062745\n","[epoch : 180 / 500] Train Loss : 0.29566971295409733\n","Save item: 17 / best_val_loss: 0.30874829888343813\n","[epoch : 190 / 500] Train Loss : 0.2929065053661664\n","Save item: 17 / best_val_loss: 0.3068000376224518\n","[epoch : 200 / 500] Train Loss : 0.2924099423819118\n","[epoch : 210 / 500] Train Loss : 0.29149496058623\n","Save item: 17 / best_val_loss: 0.30618964433670043\n","[epoch : 220 / 500] Train Loss : 0.29283386800024247\n","Save item: 17 / best_val_loss: 0.3037254512310028\n","[epoch : 230 / 500] Train Loss : 0.29045240581035614\n","[epoch : 240 / 500] Train Loss : 0.29187195830874973\n","[epoch : 250 / 500] Train Loss : 0.2908211946487427\n","[epoch : 260 / 500] Train Loss : 0.29537054730786216\n","[epoch : 270 / 500] Train Loss : 0.29351336591773564\n","[epoch : 280 / 500] Train Loss : 0.2914886491166221\n","Save item: 17 / best_val_loss: 0.3015469193458557\n","[epoch : 290 / 500] Train Loss : 0.29090915454758537\n","[epoch : 300 / 500] Train Loss : 0.2932474778758155\n","[epoch : 310 / 500] Train Loss : 0.2896261447005802\n","[epoch : 320 / 500] Train Loss : 0.2891065892246034\n","[epoch : 330 / 500] Train Loss : 0.29080886311001247\n","Save item: 17 / best_val_loss: 0.30128856301307677\n","Save item: 17 / best_val_loss: 0.2992098927497864\n","[epoch : 340 / 500] Train Loss : 0.28903665641943616\n","Save item: 17 / best_val_loss: 0.29716408252716064\n","[epoch : 350 / 500] Train Loss : 0.2904238286945555\n","[epoch : 360 / 500] Train Loss : 0.2879813578393724\n","[epoch : 370 / 500] Train Loss : 0.28810545470979476\n","[epoch : 380 / 500] Train Loss : 0.2862175967958238\n","[epoch : 390 / 500] Train Loss : 0.28524453689654666\n","Save item: 17 / best_val_loss: 0.2965784013271332\n","[epoch : 400 / 500] Train Loss : 0.28510351644621956\n","[epoch : 410 / 500] Train Loss : 0.28525980230834747\n","Save item: 17 / best_val_loss: 0.2964690089225769\n","[epoch : 420 / 500] Train Loss : 0.2848724689748552\n","Save item: 17 / best_val_loss: 0.2952413022518158\n","[epoch : 430 / 500] Train Loss : 0.2858858298924234\n","[epoch : 440 / 500] Train Loss : 0.2849329710006714\n","[epoch : 450 / 500] Train Loss : 0.2834588090578715\n","[epoch : 460 / 500] Train Loss : 0.2832458309001393\n","Save item: 17 / best_val_loss: 0.2950063109397888\n","[epoch : 470 / 500] Train Loss : 0.28613871667120194\n","Save item: 17 / best_val_loss: 0.2949228823184967\n","[epoch : 480 / 500] Train Loss : 0.28573350194427705\n","[epoch : 490 / 500] Train Loss : 0.2828374256690343\n","[epoch : 500 / 500] Train Loss : 0.2848730981349945\n","1419\n","[   0.     7181.392  7218.1313 7500.9604 7918.9473 8413.383  8947.943\n"," 9482.338  9380.031  9653.397     0.        0.        0.        0.\n","    0.     6848.7944    0.     5773.214  5700.8135 6065.2227 6505.6426\n","    0.     6264.4985 6061.6045 6267.5615 6811.633  6748.285  6626.0205]\n","0.0\n","[-1.         -0.3198505  -0.31637093 -0.2895842  -0.24999668 -0.20316869\n"," -0.15254048 -0.10192798 -0.11161745 -0.08572694 -1.         -1.\n"," -1.         -1.         -1.         -0.3513508  -1.         -0.45321906\n"," -0.4600761  -0.42556292 -0.38385072 -1.         -0.4066895  -0.4259056\n"," -0.4063994  -0.3548704  -0.36087006 -0.37244973]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 18 / best_val_loss: 0.8435135245323181\n","Save item: 18 / best_val_loss: 0.8324381351470947\n","Save item: 18 / best_val_loss: 0.8282992720603943\n","Save item: 18 / best_val_loss: 0.8252144455909729\n","Save item: 18 / best_val_loss: 0.8232471466064453\n","Save item: 18 / best_val_loss: 0.817398339509964\n","Save item: 18 / best_val_loss: 0.8142395377159118\n","Save item: 18 / best_val_loss: 0.8133639514446258\n","Save item: 18 / best_val_loss: 0.8099545836448669\n","[epoch : 10 / 500] Train Loss : 0.7439539134502411\n","Save item: 18 / best_val_loss: 0.8072738707065582\n","Save item: 18 / best_val_loss: 0.8060372054576874\n","Save item: 18 / best_val_loss: 0.8027049124240875\n","Save item: 18 / best_val_loss: 0.7986939132213593\n","Save item: 18 / best_val_loss: 0.7955626249313354\n","Save item: 18 / best_val_loss: 0.7941544711589813\n","[epoch : 20 / 500] Train Loss : 0.720384505059984\n","Save item: 18 / best_val_loss: 0.7916880786418915\n","Save item: 18 / best_val_loss: 0.7914402782917023\n","Save item: 18 / best_val_loss: 0.7887534618377685\n","Save item: 18 / best_val_loss: 0.7844047844409943\n","[epoch : 30 / 500] Train Loss : 0.710194867518213\n","Save item: 18 / best_val_loss: 0.7834221541881561\n","Save item: 18 / best_val_loss: 0.7810534119606019\n","Save item: 18 / best_val_loss: 0.7715213418006897\n","Save item: 18 / best_val_loss: 0.768286794424057\n","Save item: 18 / best_val_loss: 0.7679480016231537\n","[epoch : 40 / 500] Train Loss : 0.6897339787748125\n","Save item: 18 / best_val_loss: 0.761315131187439\n","Save item: 18 / best_val_loss: 0.7611515581607818\n","Save item: 18 / best_val_loss: 0.7579254269599914\n","Save item: 18 / best_val_loss: 0.7513886392116547\n","[epoch : 50 / 500] Train Loss : 0.6755967736244202\n","Save item: 18 / best_val_loss: 0.7489096641540527\n","[epoch : 60 / 500] Train Loss : 0.6621702677673764\n","Save item: 18 / best_val_loss: 0.7469516217708587\n","Save item: 18 / best_val_loss: 0.7458851933479309\n","[epoch : 70 / 500] Train Loss : 0.6493107891745038\n","Save item: 18 / best_val_loss: 0.7402655899524688\n","Save item: 18 / best_val_loss: 0.7397589981555939\n","[epoch : 80 / 500] Train Loss : 0.643955914510621\n","Save item: 18 / best_val_loss: 0.731681102514267\n","[epoch : 90 / 500] Train Loss : 0.6434308787186941\n","Save item: 18 / best_val_loss: 0.7254640817642212\n","[epoch : 100 / 500] Train Loss : 0.6347491410043504\n","[epoch : 110 / 500] Train Loss : 0.6265486280123392\n","[epoch : 120 / 500] Train Loss : 0.6168021112680435\n","[epoch : 130 / 500] Train Loss : 0.6169692509704165\n","[epoch : 140 / 500] Train Loss : 0.6210364252328873\n","[epoch : 150 / 500] Train Loss : 0.6186475091510348\n","[epoch : 160 / 500] Train Loss : 0.6138476944632001\n","[epoch : 170 / 500] Train Loss : 0.6091141667630937\n","Save item: 18 / best_val_loss: 0.7233539462089539\n","[epoch : 180 / 500] Train Loss : 0.6106619818343056\n","Save item: 18 / best_val_loss: 0.7189702868461609\n","[epoch : 190 / 500] Train Loss : 0.6071134044064416\n","[epoch : 200 / 500] Train Loss : 0.6102830088800855\n","[epoch : 210 / 500] Train Loss : 0.6034072538216909\n","Save item: 18 / best_val_loss: 0.7122340083122254\n","[epoch : 220 / 500] Train Loss : 0.5944672723611196\n","[epoch : 230 / 500] Train Loss : 0.5990424073404736\n","[epoch : 240 / 500] Train Loss : 0.600025420387586\n","[epoch : 250 / 500] Train Loss : 0.5949841721190346\n","[epoch : 260 / 500] Train Loss : 0.6067940062946744\n","[epoch : 270 / 500] Train Loss : 0.6079703685310152\n","[epoch : 280 / 500] Train Loss : 0.6034881356689665\n","[epoch : 290 / 500] Train Loss : 0.5976237157980601\n","Save item: 18 / best_val_loss: 0.7089605391025543\n","[epoch : 300 / 500] Train Loss : 0.6030744744671716\n","[epoch : 310 / 500] Train Loss : 0.6087346921364466\n","Save item: 18 / best_val_loss: 0.7088558077812195\n","[epoch : 320 / 500] Train Loss : 0.5896602703465356\n","[epoch : 330 / 500] Train Loss : 0.5989933792087767\n","[epoch : 340 / 500] Train Loss : 0.5901163270076116\n","[epoch : 350 / 500] Train Loss : 0.5896074126164118\n","[epoch : 360 / 500] Train Loss : 0.5872099780374103\n","[epoch : 370 / 500] Train Loss : 0.587269225054317\n","[epoch : 380 / 500] Train Loss : 0.5877548936340544\n","[epoch : 390 / 500] Train Loss : 0.5799272374974357\n","[epoch : 400 / 500] Train Loss : 0.5792765882280138\n","[epoch : 410 / 500] Train Loss : 0.5814545717504289\n","[epoch : 420 / 500] Train Loss : 0.5748129470480813\n","[epoch : 430 / 500] Train Loss : 0.5778818660312228\n","[epoch : 440 / 500] Train Loss : 0.5805422531233894\n","[epoch : 450 / 500] Train Loss : 0.5826257583167818\n","[epoch : 460 / 500] Train Loss : 0.5844763070344925\n","[epoch : 470 / 500] Train Loss : 0.582875112692515\n","[epoch : 480 / 500] Train Loss : 0.576826446586185\n","[epoch : 490 / 500] Train Loss : 0.5818765925036536\n","[epoch : 500 / 500] Train Loss : 0.5699076851209005\n","1419\n","[   0.     2801.1226 2548.4924 2687.2097 2583.3596 2793.0454 2954.3767\n","    0.     3146.2495 3007.1228    0.        0.        0.        0.\n","    0.        0.        0.     1902.2067 2141.4697 2165.4792 2064.271\n","    0.     2020.0823 2059.249  2100.805  2231.3076 2217.1135 2196.4338]\n","0.0\n","[-1.          0.02740495 -0.06525555 -0.01437637 -0.05246685  0.02444239\n","  0.08361602 -1.          0.15399174  0.1029624  -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.30230236\n"," -0.21454467 -0.20573838 -0.24285989 -1.         -0.25906757 -0.24470186\n"," -0.22945984 -0.18159366 -0.18679981 -0.19438475]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 19 / best_val_loss: 0.45666199922561646\n","Save item: 19 / best_val_loss: 0.45018631815910337\n","Save item: 19 / best_val_loss: 0.4480594158172607\n","Save item: 19 / best_val_loss: 0.4457436740398407\n","Save item: 19 / best_val_loss: 0.44527336955070496\n","Save item: 19 / best_val_loss: 0.44430320262908934\n","Save item: 19 / best_val_loss: 0.4387826263904572\n","[epoch : 10 / 500] Train Loss : 0.4083609531323115\n","Save item: 19 / best_val_loss: 0.43604456186294555\n","Save item: 19 / best_val_loss: 0.4320975303649902\n","Save item: 19 / best_val_loss: 0.42661961913108826\n","Save item: 19 / best_val_loss: 0.41937116980552674\n","Save item: 19 / best_val_loss: 0.414990758895874\n","Save item: 19 / best_val_loss: 0.4098773062229156\n","Save item: 19 / best_val_loss: 0.4068920075893402\n","Save item: 19 / best_val_loss: 0.40500332713127135\n","[epoch : 20 / 500] Train Loss : 0.37755020459493\n","Save item: 19 / best_val_loss: 0.40226033329963684\n","Save item: 19 / best_val_loss: 0.4013639032840729\n","Save item: 19 / best_val_loss: 0.40004385709762574\n","Save item: 19 / best_val_loss: 0.3974411427974701\n","Save item: 19 / best_val_loss: 0.3930496275424957\n","Save item: 19 / best_val_loss: 0.3883424162864685\n","Save item: 19 / best_val_loss: 0.38551926612854004\n","Save item: 19 / best_val_loss: 0.3828272521495819\n","Save item: 19 / best_val_loss: 0.38199515342712403\n","[epoch : 30 / 500] Train Loss : 0.35480371283160317\n","Save item: 19 / best_val_loss: 0.37843274474143984\n","Save item: 19 / best_val_loss: 0.3732218503952026\n","Save item: 19 / best_val_loss: 0.37072605490684507\n","Save item: 19 / best_val_loss: 0.367453396320343\n","Save item: 19 / best_val_loss: 0.36609033942222596\n","[epoch : 40 / 500] Train Loss : 0.33756282925605774\n","Save item: 19 / best_val_loss: 0.36351048946380615\n","Save item: 19 / best_val_loss: 0.3631526708602905\n","Save item: 19 / best_val_loss: 0.36090927124023436\n","Save item: 19 / best_val_loss: 0.3574529767036438\n","[epoch : 50 / 500] Train Loss : 0.3304574423366123\n","Save item: 19 / best_val_loss: 0.3566503167152405\n","Save item: 19 / best_val_loss: 0.35425624847412107\n","[epoch : 60 / 500] Train Loss : 0.32660866114828324\n","Save item: 19 / best_val_loss: 0.3508449912071228\n","[epoch : 70 / 500] Train Loss : 0.32266460690233445\n","Save item: 19 / best_val_loss: 0.35075042843818666\n","[epoch : 80 / 500] Train Loss : 0.318391309844123\n","Save item: 19 / best_val_loss: 0.35072453022003175\n","Save item: 19 / best_val_loss: 0.3452296793460846\n","[epoch : 90 / 500] Train Loss : 0.3151342471440633\n","Save item: 19 / best_val_loss: 0.344363933801651\n","Save item: 19 / best_val_loss: 0.3435747981071472\n","Save item: 19 / best_val_loss: 0.34344412088394166\n","Save item: 19 / best_val_loss: 0.3429053544998169\n","[epoch : 100 / 500] Train Loss : 0.3143473698033227\n","Save item: 19 / best_val_loss: 0.3406226336956024\n","[epoch : 110 / 500] Train Loss : 0.31365131835142773\n","[epoch : 120 / 500] Train Loss : 0.3107561369736989\n","[epoch : 130 / 500] Train Loss : 0.3101844804154502\n","Save item: 19 / best_val_loss: 0.3404880702495575\n","[epoch : 140 / 500] Train Loss : 0.31085310379664105\n","Save item: 19 / best_val_loss: 0.3400894641876221\n","[epoch : 150 / 500] Train Loss : 0.30881824758317733\n","Save item: 19 / best_val_loss: 0.3380617320537567\n","[epoch : 160 / 500] Train Loss : 0.30814360909991795\n","[epoch : 170 / 500] Train Loss : 0.30755682786305744\n","[epoch : 180 / 500] Train Loss : 0.3064102480808894\n","Save item: 19 / best_val_loss: 0.3375545680522919\n","Save item: 19 / best_val_loss: 0.3369009494781494\n","[epoch : 190 / 500] Train Loss : 0.3069700002670288\n","Save item: 19 / best_val_loss: 0.3365681529045105\n","[epoch : 200 / 500] Train Loss : 0.30444272855917615\n","Save item: 19 / best_val_loss: 0.333299458026886\n","[epoch : 210 / 500] Train Loss : 0.3072855207655165\n","[epoch : 220 / 500] Train Loss : 0.3032444185680813\n","[epoch : 230 / 500] Train Loss : 0.3047688321934806\n","[epoch : 240 / 500] Train Loss : 0.3038203567266464\n","Save item: 19 / best_val_loss: 0.33118043541908265\n","[epoch : 250 / 500] Train Loss : 0.3032701164484024\n","[epoch : 260 / 500] Train Loss : 0.3086220473051071\n","[epoch : 270 / 500] Train Loss : 0.3034457829263475\n","[epoch : 280 / 500] Train Loss : 0.3041486359304852\n","[epoch : 290 / 500] Train Loss : 0.3044597754875819\n","[epoch : 300 / 500] Train Loss : 0.3025902244779799\n","[epoch : 310 / 500] Train Loss : 0.3032256133026547\n","[epoch : 320 / 500] Train Loss : 0.3040037982993656\n","[epoch : 330 / 500] Train Loss : 0.3020634237262938\n","Save item: 19 / best_val_loss: 0.3303683757781982\n","[epoch : 340 / 500] Train Loss : 0.3037430892388026\n","Save item: 19 / best_val_loss: 0.32996183037757876\n","[epoch : 350 / 500] Train Loss : 0.30372514492935604\n","Save item: 19 / best_val_loss: 0.32952468395233153\n","[epoch : 360 / 500] Train Loss : 0.30055589146084255\n","Save item: 19 / best_val_loss: 0.3283857643604279\n","[epoch : 370 / 500] Train Loss : 0.2997524191935857\n","[epoch : 380 / 500] Train Loss : 0.2998247527413898\n","Save item: 19 / best_val_loss: 0.3279006838798523\n","[epoch : 390 / 500] Train Loss : 0.2987508641348945\n","Save item: 19 / best_val_loss: 0.3271561324596405\n","[epoch : 400 / 500] Train Loss : 0.2988698184490204\n","Save item: 19 / best_val_loss: 0.3270150005817413\n","[epoch : 410 / 500] Train Loss : 0.3003405084212621\n","Save item: 19 / best_val_loss: 0.32674249410629275\n","[epoch : 420 / 500] Train Loss : 0.29928171469105613\n","Save item: 19 / best_val_loss: 0.32487857937812803\n","[epoch : 430 / 500] Train Loss : 0.2987153364552392\n","[epoch : 440 / 500] Train Loss : 0.2986968970961041\n","[epoch : 450 / 500] Train Loss : 0.299243258105384\n","[epoch : 460 / 500] Train Loss : 0.3004724664820565\n","[epoch : 470 / 500] Train Loss : 0.30066971811983323\n","[epoch : 480 / 500] Train Loss : 0.2977357490195168\n","[epoch : 490 / 500] Train Loss : 0.29823683202266693\n","[epoch : 500 / 500] Train Loss : 0.2977890570958455\n","1419\n","[   0.     2392.1536 2318.887  2451.7913 2415.2114 2554.2815 2504.3518\n"," 3730.1897 2520.267  2388.69      0.        0.        0.        0.\n","    0.        0.        0.     1498.3047 1730.7688 1767.7341 1686.3486\n","    0.     1682.8148 1618.4313 1605.632  1598.565  1627.0471 1510.9286]\n","0.0\n","[-1.          0.33678794  0.29584497  0.3701148   0.34967318  0.42738858\n","  0.39948678  1.0845119   0.4083806   0.3348524  -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.16271445\n"," -0.0328084  -0.01215136 -0.05763136 -1.         -0.05960613 -0.09558507\n"," -0.10273761 -0.10668682 -0.09077035 -0.15565993]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 20 / best_val_loss: 0.44099321961402893\n","Save item: 20 / best_val_loss: 0.43462511897087097\n","Save item: 20 / best_val_loss: 0.4318639159202576\n","Save item: 20 / best_val_loss: 0.43125436902046205\n","Save item: 20 / best_val_loss: 0.4288261294364929\n","Save item: 20 / best_val_loss: 0.4254996120929718\n","Save item: 20 / best_val_loss: 0.4248384594917297\n","Save item: 20 / best_val_loss: 0.4210042178630829\n","[epoch : 10 / 500] Train Loss : 0.4135877738396327\n","Save item: 20 / best_val_loss: 0.41922775506973264\n","Save item: 20 / best_val_loss: 0.4152040183544159\n","Save item: 20 / best_val_loss: 0.4115524411201477\n","Save item: 20 / best_val_loss: 0.4026777744293213\n","Save item: 20 / best_val_loss: 0.4015964984893799\n","Save item: 20 / best_val_loss: 0.39773014187812805\n","Save item: 20 / best_val_loss: 0.39730616807937624\n","Save item: 20 / best_val_loss: 0.3926370024681091\n","[epoch : 20 / 500] Train Loss : 0.38634946445624035\n","Save item: 20 / best_val_loss: 0.38876444697380064\n","Save item: 20 / best_val_loss: 0.38836742639541627\n","Save item: 20 / best_val_loss: 0.3832312345504761\n","Save item: 20 / best_val_loss: 0.3773689270019531\n","Save item: 20 / best_val_loss: 0.37445381879806516\n","Save item: 20 / best_val_loss: 0.374266529083252\n","[epoch : 30 / 500] Train Loss : 0.3677321324745814\n","Save item: 20 / best_val_loss: 0.372111439704895\n","Save item: 20 / best_val_loss: 0.37010557651519777\n","Save item: 20 / best_val_loss: 0.36847474575042727\n","Save item: 20 / best_val_loss: 0.36224826574325564\n","[epoch : 40 / 500] Train Loss : 0.3509839458598031\n","Save item: 20 / best_val_loss: 0.36080647706985475\n","Save item: 20 / best_val_loss: 0.35895150899887085\n","Save item: 20 / best_val_loss: 0.3581081748008728\n","Save item: 20 / best_val_loss: 0.3560973048210144\n","[epoch : 50 / 500] Train Loss : 0.3440488162967894\n","Save item: 20 / best_val_loss: 0.3531332492828369\n","Save item: 20 / best_val_loss: 0.3521320760250092\n","Save item: 20 / best_val_loss: 0.3491238832473755\n","[epoch : 60 / 500] Train Loss : 0.3367697281969918\n","Save item: 20 / best_val_loss: 0.34734815955162046\n","Save item: 20 / best_val_loss: 0.3459851622581482\n","[epoch : 70 / 500] Train Loss : 0.3341354644960827\n","Save item: 20 / best_val_loss: 0.34521099328994753\n","Save item: 20 / best_val_loss: 0.34447948932647704\n","Save item: 20 / best_val_loss: 0.3438348829746246\n","Save item: 20 / best_val_loss: 0.34243165254592894\n","[epoch : 80 / 500] Train Loss : 0.3290654304954741\n","Save item: 20 / best_val_loss: 0.3403319001197815\n","[epoch : 90 / 500] Train Loss : 0.3264712178044849\n","Save item: 20 / best_val_loss: 0.34029672741889955\n","Save item: 20 / best_val_loss: 0.33924131393432616\n","Save item: 20 / best_val_loss: 0.3366296112537384\n","[epoch : 100 / 500] Train Loss : 0.3234232034948137\n","Save item: 20 / best_val_loss: 0.3352852642536163\n","[epoch : 110 / 500] Train Loss : 0.3237125277519226\n","Save item: 20 / best_val_loss: 0.3339621901512146\n","[epoch : 120 / 500] Train Loss : 0.3194252649943034\n","[epoch : 130 / 500] Train Loss : 0.31792933245499927\n","Save item: 20 / best_val_loss: 0.3324751853942871\n","[epoch : 140 / 500] Train Loss : 0.314880081348949\n","Save item: 20 / best_val_loss: 0.3313217878341675\n","[epoch : 150 / 500] Train Loss : 0.3166517698102527\n","[epoch : 160 / 500] Train Loss : 0.31193464663293624\n","Save item: 20 / best_val_loss: 0.3301945745944977\n","[epoch : 170 / 500] Train Loss : 0.31366269787152606\n","[epoch : 180 / 500] Train Loss : 0.3115888883670171\n","Save item: 20 / best_val_loss: 0.3290497660636902\n","[epoch : 190 / 500] Train Loss : 0.31151020030180615\n","Save item: 20 / best_val_loss: 0.32820948362350466\n","[epoch : 200 / 500] Train Loss : 0.31201086110538906\n","[epoch : 210 / 500] Train Loss : 0.3103982028033998\n","Save item: 20 / best_val_loss: 0.32781015038490297\n","[epoch : 220 / 500] Train Loss : 0.30810750524202984\n","[epoch : 230 / 500] Train Loss : 0.3094322548972236\n","[epoch : 240 / 500] Train Loss : 0.30782145924038357\n","Save item: 20 / best_val_loss: 0.3275177776813507\n","Save item: 20 / best_val_loss: 0.3263978362083435\n","[epoch : 250 / 500] Train Loss : 0.30989394585291546\n","[epoch : 260 / 500] Train Loss : 0.31610804465081954\n","[epoch : 270 / 500] Train Loss : 0.3098876194821464\n","[epoch : 280 / 500] Train Loss : 0.3108617133564419\n","[epoch : 290 / 500] Train Loss : 0.3075103908777237\n","[epoch : 300 / 500] Train Loss : 0.3078177918990453\n","Save item: 20 / best_val_loss: 0.3251779317855835\n","[epoch : 310 / 500] Train Loss : 0.30846712158785927\n","[epoch : 320 / 500] Train Loss : 0.30653589136070675\n","Save item: 20 / best_val_loss: 0.32348328828811646\n","[epoch : 330 / 500] Train Loss : 0.304826236433453\n","[epoch : 340 / 500] Train Loss : 0.30649224585956997\n","Save item: 20 / best_val_loss: 0.32174326181411744\n","[epoch : 350 / 500] Train Loss : 0.3049747364388572\n","[epoch : 360 / 500] Train Loss : 0.30242131981584763\n","Save item: 20 / best_val_loss: 0.32153109908103944\n","[epoch : 370 / 500] Train Loss : 0.3039262824588352\n","[epoch : 380 / 500] Train Loss : 0.30152270363436806\n","[epoch : 390 / 500] Train Loss : 0.30096396803855896\n","Save item: 20 / best_val_loss: 0.3210597574710846\n","[epoch : 400 / 500] Train Loss : 0.302299193210072\n","[epoch : 410 / 500] Train Loss : 0.3010832766691844\n","[epoch : 420 / 500] Train Loss : 0.300365149974823\n","Save item: 20 / best_val_loss: 0.3208065748214722\n","[epoch : 430 / 500] Train Loss : 0.30000720421473187\n","[epoch : 440 / 500] Train Loss : 0.3035293287701077\n","[epoch : 450 / 500] Train Loss : 0.29976729386382633\n","Save item: 20 / best_val_loss: 0.3204151153564453\n","[epoch : 460 / 500] Train Loss : 0.2996546791659461\n","[epoch : 470 / 500] Train Loss : 0.3008181369966931\n","[epoch : 480 / 500] Train Loss : 0.30129682686593795\n","[epoch : 490 / 500] Train Loss : 0.30293462839391494\n","[epoch : 500 / 500] Train Loss : 0.30108487771617043\n","1419\n","[  0.      742.7664  803.8785  792.0679  747.1577  783.2436  786.63324\n"," 855.33594 764.32556 730.2544    0.        0.        0.        0.\n","   0.        0.        0.      833.77814 842.27905 856.7358  831.35986\n","   0.      830.3112  820.28925 807.86005 794.52045 772.8589  810.36743]\n","0.0\n","[-1.          0.01489845  0.09840053  0.08226279  0.02089862  0.07020551\n","  0.07483704  0.16871078  0.04435636 -0.00219768 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.13925472\n","  0.15087016  0.1706235   0.13595045 -1.          0.1345176   0.12082382\n","  0.10384085  0.08561394  0.05601609  0.10726688]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 21 / best_val_loss: 0.4120327651500702\n","Save item: 21 / best_val_loss: 0.4044356822967529\n","Save item: 21 / best_val_loss: 0.40357916951179507\n","Save item: 21 / best_val_loss: 0.40219887495040896\n","Save item: 21 / best_val_loss: 0.4013342261314392\n","Save item: 21 / best_val_loss: 0.4007657289505005\n","Save item: 21 / best_val_loss: 0.39848406314849855\n","[epoch : 10 / 500] Train Loss : 0.3977886471483443\n","Save item: 21 / best_val_loss: 0.39651467800140383\n","Save item: 21 / best_val_loss: 0.3937627375125885\n","Save item: 21 / best_val_loss: 0.3926362991333008\n","Save item: 21 / best_val_loss: 0.3895802915096283\n","Save item: 21 / best_val_loss: 0.3792548179626465\n","Save item: 21 / best_val_loss: 0.3766062557697296\n","Save item: 21 / best_val_loss: 0.37014976143836975\n","Save item: 21 / best_val_loss: 0.3691197335720062\n","Save item: 21 / best_val_loss: 0.36708927154541016\n","[epoch : 20 / 500] Train Loss : 0.3721847931543986\n","Save item: 21 / best_val_loss: 0.36216974854469297\n","Save item: 21 / best_val_loss: 0.3579278111457825\n","Save item: 21 / best_val_loss: 0.3576990723609924\n","Save item: 21 / best_val_loss: 0.35602064728736876\n","Save item: 21 / best_val_loss: 0.3517198920249939\n","Save item: 21 / best_val_loss: 0.3489732086658478\n","Save item: 21 / best_val_loss: 0.3488710284233093\n","[epoch : 30 / 500] Train Loss : 0.3539210442039702\n","Save item: 21 / best_val_loss: 0.34547415375709534\n","Save item: 21 / best_val_loss: 0.34498741626739504\n","Save item: 21 / best_val_loss: 0.34221720695495605\n","Save item: 21 / best_val_loss: 0.33945062160491946\n","Save item: 21 / best_val_loss: 0.3348716557025909\n","Save item: 21 / best_val_loss: 0.33410850167274475\n","[epoch : 40 / 500] Train Loss : 0.3365504244963328\n","Save item: 21 / best_val_loss: 0.327536404132843\n","Save item: 21 / best_val_loss: 0.3272083640098572\n","[epoch : 50 / 500] Train Loss : 0.3245837555991279\n","Save item: 21 / best_val_loss: 0.32645623087882997\n","Save item: 21 / best_val_loss: 0.32433352470397947\n","Save item: 21 / best_val_loss: 0.3223802387714386\n","Save item: 21 / best_val_loss: 0.32222620248794553\n","[epoch : 60 / 500] Train Loss : 0.31458503835731083\n","Save item: 21 / best_val_loss: 0.32138487696647644\n","Save item: 21 / best_val_loss: 0.3185442566871643\n","Save item: 21 / best_val_loss: 0.3172228097915649\n","Save item: 21 / best_val_loss: 0.31572445631027224\n","Save item: 21 / best_val_loss: 0.31248011589050295\n","[epoch : 70 / 500] Train Loss : 0.3046838889519374\n","Save item: 21 / best_val_loss: 0.3123904883861542\n","Save item: 21 / best_val_loss: 0.31178051233291626\n","Save item: 21 / best_val_loss: 0.3116514503955841\n","[epoch : 80 / 500] Train Loss : 0.299641736679607\n","Save item: 21 / best_val_loss: 0.30865380764007566\n","Save item: 21 / best_val_loss: 0.3068383872509003\n","Save item: 21 / best_val_loss: 0.30170676708221433\n","[epoch : 90 / 500] Train Loss : 0.2985273599624634\n","Save item: 21 / best_val_loss: 0.30105413794517516\n","[epoch : 100 / 500] Train Loss : 0.29481441775957745\n","[epoch : 110 / 500] Train Loss : 0.2943876584370931\n","Save item: 21 / best_val_loss: 0.29823474287986756\n","Save item: 21 / best_val_loss: 0.29726290702819824\n","Save item: 21 / best_val_loss: 0.2962479293346405\n","[epoch : 120 / 500] Train Loss : 0.28885319497850204\n","[epoch : 130 / 500] Train Loss : 0.287277274661594\n","Save item: 21 / best_val_loss: 0.2959656536579132\n","[epoch : 140 / 500] Train Loss : 0.28281547294722664\n","Save item: 21 / best_val_loss: 0.29564717411994934\n","[epoch : 150 / 500] Train Loss : 0.28142135010825264\n","Save item: 21 / best_val_loss: 0.290583872795105\n","[epoch : 160 / 500] Train Loss : 0.28036707391341525\n","Save item: 21 / best_val_loss: 0.28882397413253785\n","[epoch : 170 / 500] Train Loss : 0.28276706652508843\n","Save item: 21 / best_val_loss: 0.28865715861320496\n","[epoch : 180 / 500] Train Loss : 0.27990950644016266\n","Save item: 21 / best_val_loss: 0.2879785418510437\n","[epoch : 190 / 500] Train Loss : 0.27871283143758774\n","[epoch : 200 / 500] Train Loss : 0.279636498954561\n","[epoch : 210 / 500] Train Loss : 0.2786159763733546\n","[epoch : 220 / 500] Train Loss : 0.2778880116012361\n","Save item: 21 / best_val_loss: 0.2878772974014282\n","[epoch : 230 / 500] Train Loss : 0.2761865374114778\n","Save item: 21 / best_val_loss: 0.28776176571846007\n","Save item: 21 / best_val_loss: 0.286467456817627\n","[epoch : 240 / 500] Train Loss : 0.27583494948016274\n","[epoch : 250 / 500] Train Loss : 0.27573131769895554\n","[epoch : 260 / 500] Train Loss : 0.2784140259027481\n","Save item: 21 / best_val_loss: 0.2862441658973694\n","[epoch : 270 / 500] Train Loss : 0.27648038582669365\n","[epoch : 280 / 500] Train Loss : 0.2787315282556746\n","[epoch : 290 / 500] Train Loss : 0.27754106952084434\n","Save item: 21 / best_val_loss: 0.28609566688537597\n","[epoch : 300 / 500] Train Loss : 0.2762702786260181\n","[epoch : 310 / 500] Train Loss : 0.27574080063237083\n","Save item: 21 / best_val_loss: 0.28360362648963927\n","[epoch : 320 / 500] Train Loss : 0.2763762010468377\n","[epoch : 330 / 500] Train Loss : 0.2772509621249305\n","[epoch : 340 / 500] Train Loss : 0.2742149316602283\n","[epoch : 350 / 500] Train Loss : 0.2759178678194682\n","Save item: 21 / best_val_loss: 0.2814980149269104\n","[epoch : 360 / 500] Train Loss : 0.2721007814009984\n","Save item: 21 / best_val_loss: 0.2814180076122284\n","[epoch : 370 / 500] Train Loss : 0.2702849639786614\n","Save item: 21 / best_val_loss: 0.28008350133895876\n","[epoch : 380 / 500] Train Loss : 0.2702101609773106\n","Save item: 21 / best_val_loss: 0.2794089734554291\n","[epoch : 390 / 500] Train Loss : 0.2703738287091255\n","[epoch : 400 / 500] Train Loss : 0.2701134838991695\n","[epoch : 410 / 500] Train Loss : 0.2692302440603574\n","Save item: 21 / best_val_loss: 0.27719115018844603\n","[epoch : 420 / 500] Train Loss : 0.2706260391407543\n","[epoch : 430 / 500] Train Loss : 0.26979734417464996\n","[epoch : 440 / 500] Train Loss : 0.2699227233727773\n","[epoch : 450 / 500] Train Loss : 0.2691301844186253\n","[epoch : 460 / 500] Train Loss : 0.2690308830804295\n","[epoch : 470 / 500] Train Loss : 0.2677696438299285\n","[epoch : 480 / 500] Train Loss : 0.2684643632835812\n","[epoch : 490 / 500] Train Loss : 0.26805060770776534\n","[epoch : 500 / 500] Train Loss : 0.2679506010479397\n","1419\n","[   0.       746.4231   699.2948   737.8905   725.1781   693.9847\n","  784.2461   867.1689   964.2277   830.83356    0.         0.\n","    0.         0.         0.         0.         0.      1031.2217\n","  949.50555  918.19214  897.41644    0.       897.9917   867.7433\n","  824.7269   787.5405   841.32104  883.1802 ]\n","0.0\n","[-1.         -0.08368548 -0.14154053 -0.09416015 -0.10976599 -0.14805926\n"," -0.03725369  0.06454295  0.1836931   0.01993743 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.2659354\n","  0.16562006  0.12717947  0.10167507 -1.          0.10238126  0.06524809\n","  0.01244089 -0.03320941  0.03281195  0.08419853]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 22 / best_val_loss: 0.44268234372138976\n","Save item: 22 / best_val_loss: 0.43599276542663573\n","Save item: 22 / best_val_loss: 0.4328066647052765\n","Save item: 22 / best_val_loss: 0.4322905302047729\n","Save item: 22 / best_val_loss: 0.4314568281173706\n","Save item: 22 / best_val_loss: 0.4300939977169037\n","Save item: 22 / best_val_loss: 0.4298268795013428\n","Save item: 22 / best_val_loss: 0.4263548791408539\n","[epoch : 10 / 500] Train Loss : 0.4345604297187593\n","Save item: 22 / best_val_loss: 0.42511129975318906\n","Save item: 22 / best_val_loss: 0.421727055311203\n","Save item: 22 / best_val_loss: 0.42073490023612975\n","Save item: 22 / best_val_loss: 0.41641477346420286\n","Save item: 22 / best_val_loss: 0.4160571277141571\n","Save item: 22 / best_val_loss: 0.4097079634666443\n","Save item: 22 / best_val_loss: 0.40923827290534975\n","Save item: 22 / best_val_loss: 0.40546205043792727\n","[epoch : 20 / 500] Train Loss : 0.41753553847471875\n","Save item: 22 / best_val_loss: 0.40513224005699155\n","Save item: 22 / best_val_loss: 0.4019537329673767\n","Save item: 22 / best_val_loss: 0.39960371851921084\n","Save item: 22 / best_val_loss: 0.3948819160461426\n","Save item: 22 / best_val_loss: 0.3930258333683014\n","[epoch : 30 / 500] Train Loss : 0.4046712451510959\n","Save item: 22 / best_val_loss: 0.3917949914932251\n","Save item: 22 / best_val_loss: 0.39140044450759887\n","Save item: 22 / best_val_loss: 0.3884600460529327\n","[epoch : 40 / 500] Train Loss : 0.3883226050270928\n","Save item: 22 / best_val_loss: 0.38501203060150146\n","Save item: 22 / best_val_loss: 0.3839153289794922\n","Save item: 22 / best_val_loss: 0.38200969696044923\n","Save item: 22 / best_val_loss: 0.37976176738739015\n","Save item: 22 / best_val_loss: 0.378427129983902\n","Save item: 22 / best_val_loss: 0.3751038372516632\n","Save item: 22 / best_val_loss: 0.37127583026885985\n","[epoch : 50 / 500] Train Loss : 0.3696622865067588\n","Save item: 22 / best_val_loss: 0.36470248103141784\n","Save item: 22 / best_val_loss: 0.36173057556152344\n","Save item: 22 / best_val_loss: 0.3565413475036621\n","Save item: 22 / best_val_loss: 0.3554161787033081\n","[epoch : 60 / 500] Train Loss : 0.35460682378874886\n","Save item: 22 / best_val_loss: 0.35102598667144774\n","[epoch : 70 / 500] Train Loss : 0.34476982057094574\n","Save item: 22 / best_val_loss: 0.34480043649673464\n","[epoch : 80 / 500] Train Loss : 0.33722485105196637\n","Save item: 22 / best_val_loss: 0.34047381281852723\n","Save item: 22 / best_val_loss: 0.33879005908966064\n","[epoch : 90 / 500] Train Loss : 0.33172980613178676\n","Save item: 22 / best_val_loss: 0.33535796999931333\n","[epoch : 100 / 500] Train Loss : 0.32595758305655587\n","Save item: 22 / best_val_loss: 0.3298083782196045\n","[epoch : 110 / 500] Train Loss : 0.32209303147262996\n","[epoch : 120 / 500] Train Loss : 0.3191638969712787\n","[epoch : 130 / 500] Train Loss : 0.31767746806144714\n","Save item: 22 / best_val_loss: 0.3206067204475403\n","[epoch : 140 / 500] Train Loss : 0.3147842403915193\n","[epoch : 150 / 500] Train Loss : 0.3151901281542248\n","[epoch : 160 / 500] Train Loss : 0.3112219423055649\n","[epoch : 170 / 500] Train Loss : 0.31090549131234485\n","[epoch : 180 / 500] Train Loss : 0.31033000349998474\n","Save item: 22 / best_val_loss: 0.3191551983356476\n","[epoch : 190 / 500] Train Loss : 0.3080506771802902\n","[epoch : 200 / 500] Train Loss : 0.30795760121610427\n","[epoch : 210 / 500] Train Loss : 0.3076278765996297\n","[epoch : 220 / 500] Train Loss : 0.3065386298629973\n","Save item: 22 / best_val_loss: 0.3174462616443634\n","[epoch : 230 / 500] Train Loss : 0.3059488402472602\n","[epoch : 240 / 500] Train Loss : 0.3026473621527354\n","Save item: 22 / best_val_loss: 0.31663095355033877\n","[epoch : 250 / 500] Train Loss : 0.305503969391187\n","[epoch : 260 / 500] Train Loss : 0.30817150904072654\n","[epoch : 270 / 500] Train Loss : 0.3094927900367313\n","[epoch : 280 / 500] Train Loss : 0.3074788467751609\n","[epoch : 290 / 500] Train Loss : 0.30786673890219796\n","[epoch : 300 / 500] Train Loss : 0.3087780889537599\n","[epoch : 310 / 500] Train Loss : 0.30781274537245434\n","Save item: 22 / best_val_loss: 0.3126105308532715\n","[epoch : 320 / 500] Train Loss : 0.30559931695461273\n","[epoch : 330 / 500] Train Loss : 0.30198046565055847\n","Save item: 22 / best_val_loss: 0.312250542640686\n","[epoch : 340 / 500] Train Loss : 0.3044600519869063\n","[epoch : 350 / 500] Train Loss : 0.3044066760275099\n","Save item: 22 / best_val_loss: 0.312155681848526\n","[epoch : 360 / 500] Train Loss : 0.30109677380985683\n","[epoch : 370 / 500] Train Loss : 0.30067752136124504\n","[epoch : 380 / 500] Train Loss : 0.3012186619970534\n","Save item: 22 / best_val_loss: 0.30867915153503417\n","[epoch : 390 / 500] Train Loss : 0.2998603880405426\n","[epoch : 400 / 500] Train Loss : 0.3004962139659458\n","[epoch : 410 / 500] Train Loss : 0.2970216025908788\n","[epoch : 420 / 500] Train Loss : 0.298768969045745\n","[epoch : 430 / 500] Train Loss : 0.2973577462964588\n","[epoch : 440 / 500] Train Loss : 0.29744340313805473\n","[epoch : 450 / 500] Train Loss : 0.29601773454083335\n","Save item: 22 / best_val_loss: 0.3065565347671509\n","[epoch : 460 / 500] Train Loss : 0.29632924331559074\n","[epoch : 470 / 500] Train Loss : 0.2940053128533893\n","[epoch : 480 / 500] Train Loss : 0.2967556234863069\n","[epoch : 490 / 500] Train Loss : 0.29629601041475934\n","[epoch : 500 / 500] Train Loss : 0.29566166798273724\n","1419\n","[   0.     1658.5231 1647.7876 1727.7239 1759.9583 1955.0096 2045.1292\n"," 2072.5715 1831.1168 1786.5154    0.        0.        0.        0.\n","    0.        0.        0.     1845.9785 1808.1078 1638.0089 1467.5085\n","    0.     1554.0753 1339.016  1239.8298 1205.69   1231.8452 1207.4777]\n","0.0\n","[-1.         -0.25148705 -0.2563321  -0.22025584 -0.20570804 -0.11767882\n"," -0.07700671 -0.06462161 -0.17359325 -0.19372247 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.16688599\n"," -0.18397753 -0.26074535 -0.33769438 -1.         -0.29862568 -0.39568472\n"," -0.44044873 -0.4558565  -0.44405228 -0.45504966]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 23 / best_val_loss: 0.5799987077713012\n","Save item: 23 / best_val_loss: 0.5742124438285827\n","Save item: 23 / best_val_loss: 0.5735278487205505\n","Save item: 23 / best_val_loss: 0.5707487344741822\n","Save item: 23 / best_val_loss: 0.5699234008789062\n","Save item: 23 / best_val_loss: 0.5656047224998474\n","Save item: 23 / best_val_loss: 0.5615992069244384\n","Save item: 23 / best_val_loss: 0.5548861265182495\n","[epoch : 10 / 500] Train Loss : 0.562414265341229\n","Save item: 23 / best_val_loss: 0.5481395483016968\n","Save item: 23 / best_val_loss: 0.5413379907608032\n","Save item: 23 / best_val_loss: 0.5343611299991607\n","Save item: 23 / best_val_loss: 0.5333209931850433\n","Save item: 23 / best_val_loss: 0.5270253539085388\n","Save item: 23 / best_val_loss: 0.526853346824646\n","Save item: 23 / best_val_loss: 0.526458352804184\n","Save item: 23 / best_val_loss: 0.5260857343673706\n","Save item: 23 / best_val_loss: 0.5200386285781861\n","[epoch : 20 / 500] Train Loss : 0.5196207662423452\n","Save item: 23 / best_val_loss: 0.5170616567134857\n","Save item: 23 / best_val_loss: 0.5135429978370667\n","Save item: 23 / best_val_loss: 0.5088990688323974\n","Save item: 23 / best_val_loss: 0.5045656204223633\n","Save item: 23 / best_val_loss: 0.5025513529777527\n","Save item: 23 / best_val_loss: 0.5024975180625916\n","Save item: 23 / best_val_loss: 0.4973344147205353\n","[epoch : 30 / 500] Train Loss : 0.4963456392288208\n","Save item: 23 / best_val_loss: 0.4926464319229126\n","Save item: 23 / best_val_loss: 0.48636104464530944\n","Save item: 23 / best_val_loss: 0.4857211112976074\n","[epoch : 40 / 500] Train Loss : 0.47702229188548195\n","Save item: 23 / best_val_loss: 0.48325947523117063\n","Save item: 23 / best_val_loss: 0.4821887075901031\n","[epoch : 50 / 500] Train Loss : 0.4670139253139496\n","Save item: 23 / best_val_loss: 0.48004394173622134\n","Save item: 23 / best_val_loss: 0.47857922315597534\n","Save item: 23 / best_val_loss: 0.47841134667396545\n","Save item: 23 / best_val_loss: 0.47658294439315796\n","[epoch : 60 / 500] Train Loss : 0.46137310067812604\n","Save item: 23 / best_val_loss: 0.4736518919467926\n","Save item: 23 / best_val_loss: 0.4723444104194641\n","[epoch : 70 / 500] Train Loss : 0.4520116051038106\n","[epoch : 80 / 500] Train Loss : 0.44880041976769763\n","Save item: 23 / best_val_loss: 0.4674347937107086\n","[epoch : 90 / 500] Train Loss : 0.44366029567188686\n","Save item: 23 / best_val_loss: 0.46321381330490113\n","[epoch : 100 / 500] Train Loss : 0.440556150343683\n","Save item: 23 / best_val_loss: 0.4571700990200043\n","[epoch : 110 / 500] Train Loss : 0.4380545715490977\n","[epoch : 120 / 500] Train Loss : 0.4304160293605592\n","[epoch : 130 / 500] Train Loss : 0.426932026942571\n","Save item: 23 / best_val_loss: 0.4541840374469757\n","[epoch : 140 / 500] Train Loss : 0.4277000261677636\n","Save item: 23 / best_val_loss: 0.45416436195373533\n","[epoch : 150 / 500] Train Loss : 0.42495939797825283\n","[epoch : 160 / 500] Train Loss : 0.42132162385516697\n","Save item: 23 / best_val_loss: 0.45280025601387025\n","[epoch : 170 / 500] Train Loss : 0.4249911606311798\n","Save item: 23 / best_val_loss: 0.4525695741176605\n","[epoch : 180 / 500] Train Loss : 0.4176804804139667\n","Save item: 23 / best_val_loss: 0.4512122988700867\n","Save item: 23 / best_val_loss: 0.44959625601768494\n","[epoch : 190 / 500] Train Loss : 0.4189263532559077\n","Save item: 23 / best_val_loss: 0.44902793169021604\n","[epoch : 200 / 500] Train Loss : 0.41646114488442737\n","[epoch : 210 / 500] Train Loss : 0.4163211103942659\n","Save item: 23 / best_val_loss: 0.4468602955341339\n","[epoch : 220 / 500] Train Loss : 0.41598768532276154\n","Save item: 23 / best_val_loss: 0.44355623722076415\n","[epoch : 230 / 500] Train Loss : 0.4124754981862174\n","[epoch : 240 / 500] Train Loss : 0.41118580599625904\n","[epoch : 250 / 500] Train Loss : 0.41274646917978924\n","[epoch : 260 / 500] Train Loss : 0.4170834703577889\n","[epoch : 270 / 500] Train Loss : 0.416484362549252\n","[epoch : 280 / 500] Train Loss : 0.4142852955394321\n","Save item: 23 / best_val_loss: 0.44181992411613463\n","Save item: 23 / best_val_loss: 0.44033501148223875\n","[epoch : 290 / 500] Train Loss : 0.41079257759783006\n","[epoch : 300 / 500] Train Loss : 0.4152170502477222\n","[epoch : 310 / 500] Train Loss : 0.41515426999992794\n","[epoch : 320 / 500] Train Loss : 0.4155352993143929\n","[epoch : 330 / 500] Train Loss : 0.408432016770045\n","[epoch : 340 / 500] Train Loss : 0.40991421043872833\n","Save item: 23 / best_val_loss: 0.43928333520889284\n","Save item: 23 / best_val_loss: 0.4381721019744873\n","[epoch : 350 / 500] Train Loss : 0.40859463314215344\n","[epoch : 360 / 500] Train Loss : 0.4030444737937715\n","Save item: 23 / best_val_loss: 0.43197883367538453\n","[epoch : 370 / 500] Train Loss : 0.4067369865046607\n","[epoch : 380 / 500] Train Loss : 0.4086356841855579\n","Save item: 23 / best_val_loss: 0.431027227640152\n","[epoch : 390 / 500] Train Loss : 0.4025733172893524\n","[epoch : 400 / 500] Train Loss : 0.40640618403752643\n","[epoch : 410 / 500] Train Loss : 0.40196386641926235\n","Save item: 23 / best_val_loss: 0.4302712678909302\n","[epoch : 420 / 500] Train Loss : 0.40249116387632156\n","[epoch : 430 / 500] Train Loss : 0.40277182228035396\n","Save item: 23 / best_val_loss: 0.4302027106285095\n","[epoch : 440 / 500] Train Loss : 0.4013964931170146\n","[epoch : 450 / 500] Train Loss : 0.40110980636543697\n","[epoch : 460 / 500] Train Loss : 0.3995361394352383\n","[epoch : 470 / 500] Train Loss : 0.40192945798238117\n","[epoch : 480 / 500] Train Loss : 0.399737685918808\n","Save item: 23 / best_val_loss: 0.42997550368309023\n","[epoch : 490 / 500] Train Loss : 0.39720093872812057\n","[epoch : 500 / 500] Train Loss : 0.39965295791625977\n","1419\n","[   0.       802.9331   821.5647   715.2875   686.3074   828.8376\n","  785.5349     0.       748.85486  713.66974    0.         0.\n","    0.         0.         0.         0.         0.       994.96313\n"," 1037.1273  1025.366    768.5439     0.       878.7516   779.9704\n","  770.0579   752.19226  697.1547   618.546  ]\n","0.0\n","[-1.         -0.3545335  -0.33955583 -0.42499056 -0.44828728 -0.33370924\n"," -0.36851966 -1.         -0.39800623 -0.42629105 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.20016329\n"," -0.1662681  -0.17572288 -0.38217852 -1.         -0.2935841  -0.3729929\n"," -0.3809614  -0.39532334 -0.43956724 -0.50275964]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 24 / best_val_loss: 0.4614107429981232\n","Save item: 24 / best_val_loss: 0.45694836378097536\n","Save item: 24 / best_val_loss: 0.455148309469223\n","Save item: 24 / best_val_loss: 0.4534179508686066\n","Save item: 24 / best_val_loss: 0.45248377323150635\n","Save item: 24 / best_val_loss: 0.4512901544570923\n","Save item: 24 / best_val_loss: 0.4478190362453461\n","Save item: 24 / best_val_loss: 0.44681106209754945\n","Save item: 24 / best_val_loss: 0.4455205798149109\n","[epoch : 10 / 500] Train Loss : 0.4584277487463421\n","Save item: 24 / best_val_loss: 0.4387792646884918\n","Save item: 24 / best_val_loss: 0.4348926067352295\n","Save item: 24 / best_val_loss: 0.4324772536754608\n","Save item: 24 / best_val_loss: 0.42834139466285703\n","Save item: 24 / best_val_loss: 0.4196455001831055\n","Save item: 24 / best_val_loss: 0.4163444101810455\n","Save item: 24 / best_val_loss: 0.4163332998752594\n","Save item: 24 / best_val_loss: 0.41255366802215576\n","[epoch : 20 / 500] Train Loss : 0.42835357122951084\n","Save item: 24 / best_val_loss: 0.40893265008926394\n","Save item: 24 / best_val_loss: 0.4076686680316925\n","Save item: 24 / best_val_loss: 0.4065577447414398\n","[epoch : 30 / 500] Train Loss : 0.4138288166787889\n","Save item: 24 / best_val_loss: 0.40137205719947816\n","Save item: 24 / best_val_loss: 0.4012864589691162\n","Save item: 24 / best_val_loss: 0.4006280839443207\n","Save item: 24 / best_val_loss: 0.39420815110206603\n","Save item: 24 / best_val_loss: 0.39360219836235044\n","[epoch : 40 / 500] Train Loss : 0.3935358938243654\n","Save item: 24 / best_val_loss: 0.38596426844596865\n","Save item: 24 / best_val_loss: 0.3829129755496979\n","[epoch : 50 / 500] Train Loss : 0.37791378961669075\n","Save item: 24 / best_val_loss: 0.3818714261054993\n","Save item: 24 / best_val_loss: 0.38135788440704343\n","Save item: 24 / best_val_loss: 0.38002924919128417\n","Save item: 24 / best_val_loss: 0.3799239218235016\n","[epoch : 60 / 500] Train Loss : 0.3670177194807265\n","Save item: 24 / best_val_loss: 0.3780443012714386\n","Save item: 24 / best_val_loss: 0.3743465781211853\n","[epoch : 70 / 500] Train Loss : 0.3600195464160707\n","Save item: 24 / best_val_loss: 0.3724691987037659\n","Save item: 24 / best_val_loss: 0.37047014236450193\n","[epoch : 80 / 500] Train Loss : 0.3594454245434867\n","Save item: 24 / best_val_loss: 0.36796688437461855\n","Save item: 24 / best_val_loss: 0.36081955432891843\n","[epoch : 90 / 500] Train Loss : 0.3516922245422999\n","[epoch : 100 / 500] Train Loss : 0.34913809763060677\n","[epoch : 110 / 500] Train Loss : 0.3498178952270084\n","Save item: 24 / best_val_loss: 0.35788063406944276\n","[epoch : 120 / 500] Train Loss : 0.34332170254654354\n","[epoch : 130 / 500] Train Loss : 0.3441037717792723\n","[epoch : 140 / 500] Train Loss : 0.3422609004709456\n","Save item: 24 / best_val_loss: 0.3564162254333496\n","Save item: 24 / best_val_loss: 0.3548214554786682\n","[epoch : 150 / 500] Train Loss : 0.3403579460250007\n","Save item: 24 / best_val_loss: 0.35174071192741396\n","[epoch : 160 / 500] Train Loss : 0.33791396849685246\n","[epoch : 170 / 500] Train Loss : 0.33907108505566913\n","[epoch : 180 / 500] Train Loss : 0.3364273922310935\n","[epoch : 190 / 500] Train Loss : 0.33695632384883034\n","[epoch : 200 / 500] Train Loss : 0.33673349354002213\n","[epoch : 210 / 500] Train Loss : 0.33563343187173206\n","[epoch : 220 / 500] Train Loss : 0.3355471541484197\n","[epoch : 230 / 500] Train Loss : 0.3327830483516057\n","Save item: 24 / best_val_loss: 0.35160496830940247\n","[epoch : 240 / 500] Train Loss : 0.33330270151297253\n","Save item: 24 / best_val_loss: 0.3498061776161194\n","[epoch : 250 / 500] Train Loss : 0.3322143405675888\n","Save item: 24 / best_val_loss: 0.3490368962287903\n","[epoch : 260 / 500] Train Loss : 0.3379046668608983\n","[epoch : 270 / 500] Train Loss : 0.3357993894153171\n","[epoch : 280 / 500] Train Loss : 0.33523304263750714\n","[epoch : 290 / 500] Train Loss : 0.33534106943342423\n","[epoch : 300 / 500] Train Loss : 0.33244962493578595\n","[epoch : 310 / 500] Train Loss : 0.3329765912559297\n","Save item: 24 / best_val_loss: 0.3482006430625916\n","[epoch : 320 / 500] Train Loss : 0.331666949722502\n","[epoch : 330 / 500] Train Loss : 0.3334588524368074\n","[epoch : 340 / 500] Train Loss : 0.3309372166792552\n","Save item: 24 / best_val_loss: 0.3469677627086639\n","[epoch : 350 / 500] Train Loss : 0.3290381266011132\n","Save item: 24 / best_val_loss: 0.3453279435634613\n","[epoch : 360 / 500] Train Loss : 0.32857896718713975\n","[epoch : 370 / 500] Train Loss : 0.3276267151037852\n","[epoch : 380 / 500] Train Loss : 0.33047234018643695\n","[epoch : 390 / 500] Train Loss : 0.3272712644603517\n","[epoch : 400 / 500] Train Loss : 0.3272141267855962\n","[epoch : 410 / 500] Train Loss : 0.32663950986332363\n","[epoch : 420 / 500] Train Loss : 0.32669693728288013\n","[epoch : 430 / 500] Train Loss : 0.326715855134858\n","[epoch : 440 / 500] Train Loss : 0.32636627554893494\n","[epoch : 450 / 500] Train Loss : 0.3256366749604543\n","Save item: 24 / best_val_loss: 0.34472010731697084\n","[epoch : 460 / 500] Train Loss : 0.32421831952200997\n","[epoch : 470 / 500] Train Loss : 0.3259248087803523\n","Save item: 24 / best_val_loss: 0.34321900010108947\n","[epoch : 480 / 500] Train Loss : 0.3263454950518078\n","[epoch : 490 / 500] Train Loss : 0.3236839969952901\n","[epoch : 500 / 500] Train Loss : 0.32444154222806293\n","1419\n","[   0.     2064.386  1957.3972 2016.2161 2100.3079 2137.935  2458.2534\n"," 3436.9485 2724.2556 2565.5261    0.        0.        0.        0.\n","    0.        0.        0.     2665.0813 2670.1155 2468.9531 2278.734\n","    0.     2119.9504 1835.5586 1741.0427 1647.3365 1712.5509 1491.3065]\n","0.0\n","[-1.         -0.22408243 -0.2642951  -0.24218751 -0.21058089 -0.19643837\n"," -0.07604392  0.2918072   0.02393534 -0.03572453 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.00169415\n","  0.00358629 -0.07202234 -0.14351791 -1.         -0.20319805 -0.3100892\n"," -0.34561384 -0.3808341  -0.35632274 -0.43947938]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 25 / best_val_loss: 0.4572255492210388\n","Save item: 25 / best_val_loss: 0.4510287344455719\n","Save item: 25 / best_val_loss: 0.44857199788093566\n","Save item: 25 / best_val_loss: 0.44651153683662415\n","Save item: 25 / best_val_loss: 0.44446773529052735\n","Save item: 25 / best_val_loss: 0.44323205947875977\n","Save item: 25 / best_val_loss: 0.44148396253585814\n","Save item: 25 / best_val_loss: 0.43725553154945374\n","[epoch : 10 / 500] Train Loss : 0.454443516002761\n","Save item: 25 / best_val_loss: 0.42906793355941775\n","Save item: 25 / best_val_loss: 0.41937691569328306\n","Save item: 25 / best_val_loss: 0.40997411608695983\n","Save item: 25 / best_val_loss: 0.40403805375099183\n","Save item: 25 / best_val_loss: 0.3956969976425171\n","Save item: 25 / best_val_loss: 0.39374890327453616\n","Save item: 25 / best_val_loss: 0.39345270991325376\n","[epoch : 20 / 500] Train Loss : 0.4093518290254805\n","Save item: 25 / best_val_loss: 0.3847511768341064\n","Save item: 25 / best_val_loss: 0.3839787781238556\n","Save item: 25 / best_val_loss: 0.3778310000896454\n","Save item: 25 / best_val_loss: 0.37627350091934203\n","Save item: 25 / best_val_loss: 0.3709596574306488\n","[epoch : 30 / 500] Train Loss : 0.38381364610460067\n","Save item: 25 / best_val_loss: 0.37035759091377257\n","Save item: 25 / best_val_loss: 0.36508412957191466\n","Save item: 25 / best_val_loss: 0.35988712310791016\n","Save item: 25 / best_val_loss: 0.35615838766098024\n","Save item: 25 / best_val_loss: 0.3532139003276825\n","Save item: 25 / best_val_loss: 0.3500541150569916\n","Save item: 25 / best_val_loss: 0.3484653413295746\n","[epoch : 40 / 500] Train Loss : 0.35802959899107617\n","Save item: 25 / best_val_loss: 0.343495762348175\n","Save item: 25 / best_val_loss: 0.33622907400131224\n","[epoch : 50 / 500] Train Loss : 0.34395398530695176\n","Save item: 25 / best_val_loss: 0.33342993855476377\n","[epoch : 60 / 500] Train Loss : 0.33992481231689453\n","Save item: 25 / best_val_loss: 0.33285562992095946\n","Save item: 25 / best_val_loss: 0.33080979585647585\n","Save item: 25 / best_val_loss: 0.32403002977371215\n","[epoch : 70 / 500] Train Loss : 0.3344292226764891\n","[epoch : 80 / 500] Train Loss : 0.3300194922420714\n","Save item: 25 / best_val_loss: 0.3221921980381012\n","[epoch : 90 / 500] Train Loss : 0.3272288607226478\n","Save item: 25 / best_val_loss: 0.31944499015808103\n","[epoch : 100 / 500] Train Loss : 0.3255988409121831\n","[epoch : 110 / 500] Train Loss : 0.32434552411238354\n","Save item: 25 / best_val_loss: 0.3180035352706909\n","[epoch : 120 / 500] Train Loss : 0.3211819479862849\n","[epoch : 130 / 500] Train Loss : 0.31945160031318665\n","Save item: 25 / best_val_loss: 0.31705939769744873\n","Save item: 25 / best_val_loss: 0.3160460114479065\n","[epoch : 140 / 500] Train Loss : 0.31786571277512443\n","[epoch : 150 / 500] Train Loss : 0.31934330860773724\n","[epoch : 160 / 500] Train Loss : 0.3179081281026204\n","[epoch : 170 / 500] Train Loss : 0.3155011501577165\n","Save item: 25 / best_val_loss: 0.31282282471656797\n","[epoch : 180 / 500] Train Loss : 0.31132197711202836\n","[epoch : 190 / 500] Train Loss : 0.31255949205822414\n","[epoch : 200 / 500] Train Loss : 0.31320879856745404\n","[epoch : 210 / 500] Train Loss : 0.31279832786983913\n","Save item: 25 / best_val_loss: 0.31161128282546996\n","[epoch : 220 / 500] Train Loss : 0.3103925983111064\n","[epoch : 230 / 500] Train Loss : 0.31200717555152047\n","Save item: 25 / best_val_loss: 0.30789888501167295\n","[epoch : 240 / 500] Train Loss : 0.3104616817500856\n","[epoch : 250 / 500] Train Loss : 0.3096868826283349\n","[epoch : 260 / 500] Train Loss : 0.3116474747657776\n","[epoch : 270 / 500] Train Loss : 0.3110322720474667\n","[epoch : 280 / 500] Train Loss : 0.31100495159626007\n","[epoch : 290 / 500] Train Loss : 0.3101013782951567\n","[epoch : 300 / 500] Train Loss : 0.31083063946829903\n","[epoch : 310 / 500] Train Loss : 0.30688512325286865\n","[epoch : 320 / 500] Train Loss : 0.30933435095681083\n","[epoch : 330 / 500] Train Loss : 0.30928217040167916\n","[epoch : 340 / 500] Train Loss : 0.30782658689551884\n","Save item: 25 / best_val_loss: 0.3077491223812103\n","[epoch : 350 / 500] Train Loss : 0.3090489175584581\n","[epoch : 360 / 500] Train Loss : 0.3052716470426983\n","[epoch : 370 / 500] Train Loss : 0.3055897172954347\n","[epoch : 380 / 500] Train Loss : 0.3041955845223533\n","Save item: 25 / best_val_loss: 0.30622568130493166\n","[epoch : 390 / 500] Train Loss : 0.3040101014905506\n","Save item: 25 / best_val_loss: 0.3060051083564758\n","[epoch : 400 / 500] Train Loss : 0.3021253744761149\n","[epoch : 410 / 500] Train Loss : 0.30556947986284894\n","[epoch : 420 / 500] Train Loss : 0.30270306600464714\n","[epoch : 430 / 500] Train Loss : 0.30258771777153015\n","Save item: 25 / best_val_loss: 0.30461140275001525\n","[epoch : 440 / 500] Train Loss : 0.3038794795672099\n","Save item: 25 / best_val_loss: 0.3037876605987549\n","[epoch : 450 / 500] Train Loss : 0.3036948889493942\n","[epoch : 460 / 500] Train Loss : 0.3033929069836934\n","[epoch : 470 / 500] Train Loss : 0.3021673891279433\n","[epoch : 480 / 500] Train Loss : 0.3013462159368727\n","Save item: 25 / best_val_loss: 0.30370357632637024\n","Save item: 25 / best_val_loss: 0.30243422985076907\n","[epoch : 490 / 500] Train Loss : 0.30034171872668797\n","[epoch : 500 / 500] Train Loss : 0.3023176242907842\n","1419\n","[   0.     2896.808  2836.0059 2959.5679 3659.3506 3480.348  3403.4292\n"," 2397.6    3371.5088 4160.654     0.        0.        0.        0.\n","    0.        0.        0.     4266.153  3069.1636 2773.516  2298.9548\n","    0.     2395.3047 2383.595  2190.     2646.0178 2585.8572 2448.404 ]\n","0.0\n","[-0.99999994  0.37001592  0.3412601   0.3996975   0.7306526   0.6459951\n","  0.6096172   0.13392055  0.59452075  0.96773887 -0.99999994 -0.99999994\n"," -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.99999994  1.0176336\n","  0.45152968  0.31170622  0.08726728 -0.99999994  0.13283497  0.12729697\n","  0.0357382   0.2514072   0.22295482  0.15794776]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 26 / best_val_loss: 0.5577936768531799\n","Save item: 26 / best_val_loss: 0.5551831841468811\n","Save item: 26 / best_val_loss: 0.5516878604888916\n","Save item: 26 / best_val_loss: 0.5456420660018921\n","Save item: 26 / best_val_loss: 0.5445919275283814\n","Save item: 26 / best_val_loss: 0.5429740250110626\n","Save item: 26 / best_val_loss: 0.5363003373146057\n","Save item: 26 / best_val_loss: 0.532749342918396\n","Save item: 26 / best_val_loss: 0.5279127180576324\n","[epoch : 10 / 500] Train Loss : 0.5365108135673735\n","Save item: 26 / best_val_loss: 0.523786211013794\n","Save item: 26 / best_val_loss: 0.5187470436096191\n","Save item: 26 / best_val_loss: 0.5157128989696502\n","Save item: 26 / best_val_loss: 0.5126060903072357\n","Save item: 26 / best_val_loss: 0.510743248462677\n","Save item: 26 / best_val_loss: 0.5087454140186309\n","Save item: 26 / best_val_loss: 0.5067477524280548\n","Save item: 26 / best_val_loss: 0.5062871694564819\n","Save item: 26 / best_val_loss: 0.5038441956043244\n","[epoch : 20 / 500] Train Loss : 0.5130844149324629\n","Save item: 26 / best_val_loss: 0.5019815742969513\n","Save item: 26 / best_val_loss: 0.501908826828003\n","Save item: 26 / best_val_loss: 0.5001219034194946\n","Save item: 26 / best_val_loss: 0.4966308295726776\n","Save item: 26 / best_val_loss: 0.48754737377166746\n","Save item: 26 / best_val_loss: 0.48265684247016905\n","Save item: 26 / best_val_loss: 0.4819478988647461\n","Save item: 26 / best_val_loss: 0.47605331540107726\n","[epoch : 30 / 500] Train Loss : 0.4692096792989307\n","Save item: 26 / best_val_loss: 0.4660159289836884\n","Save item: 26 / best_val_loss: 0.45975797772407534\n","Save item: 26 / best_val_loss: 0.4573098659515381\n","[epoch : 40 / 500] Train Loss : 0.45352547864119214\n","Save item: 26 / best_val_loss: 0.4516363382339478\n","[epoch : 50 / 500] Train Loss : 0.4395533303419749\n","[epoch : 60 / 500] Train Loss : 0.4358113259077072\n","Save item: 26 / best_val_loss: 0.44103904366493224\n","Save item: 26 / best_val_loss: 0.44083263278007506\n","[epoch : 70 / 500] Train Loss : 0.4235997498035431\n","[epoch : 80 / 500] Train Loss : 0.418000512652927\n","[epoch : 90 / 500] Train Loss : 0.4191477861669328\n","[epoch : 100 / 500] Train Loss : 0.4118182924058702\n","Save item: 26 / best_val_loss: 0.44042940735816954\n","[epoch : 110 / 500] Train Loss : 0.41031619409720105\n","Save item: 26 / best_val_loss: 0.4372469484806061\n","[epoch : 120 / 500] Train Loss : 0.40474717484580147\n","[epoch : 130 / 500] Train Loss : 0.40724840263525647\n","Save item: 26 / best_val_loss: 0.4356209397315979\n","[epoch : 140 / 500] Train Loss : 0.40010564029216766\n","Save item: 26 / best_val_loss: 0.4301955223083496\n","Save item: 26 / best_val_loss: 0.42979133129119873\n","[epoch : 150 / 500] Train Loss : 0.4002651191420025\n","Save item: 26 / best_val_loss: 0.4296631753444672\n","[epoch : 160 / 500] Train Loss : 0.3962823318110572\n","[epoch : 170 / 500] Train Loss : 0.4030439870225059\n","[epoch : 180 / 500] Train Loss : 0.3984440316756566\n","[epoch : 190 / 500] Train Loss : 0.3959122399489085\n","[epoch : 200 / 500] Train Loss : 0.3975035597880681\n","Save item: 26 / best_val_loss: 0.4289525032043457\n","[epoch : 210 / 500] Train Loss : 0.3949636138147778\n","[epoch : 220 / 500] Train Loss : 0.3924630317423079\n","Save item: 26 / best_val_loss: 0.42799707055091857\n","Save item: 26 / best_val_loss: 0.427597975730896\n","[epoch : 230 / 500] Train Loss : 0.3926335937447018\n","[epoch : 240 / 500] Train Loss : 0.3925869862238566\n","Save item: 26 / best_val_loss: 0.4249995231628418\n","[epoch : 250 / 500] Train Loss : 0.3925985511806276\n","[epoch : 260 / 500] Train Loss : 0.3920430988073349\n","[epoch : 270 / 500] Train Loss : 0.3936031129625108\n","[epoch : 280 / 500] Train Loss : 0.3945549958282047\n","[epoch : 290 / 500] Train Loss : 0.39106905294789207\n","Save item: 26 / best_val_loss: 0.4243947625160217\n","[epoch : 300 / 500] Train Loss : 0.38865843911965686\n","[epoch : 310 / 500] Train Loss : 0.39172661966747707\n","[epoch : 320 / 500] Train Loss : 0.3869726293616825\n","[epoch : 330 / 500] Train Loss : 0.38905806177192265\n","Save item: 26 / best_val_loss: 0.42408178448677064\n","[epoch : 340 / 500] Train Loss : 0.386119791203075\n","[epoch : 350 / 500] Train Loss : 0.3866179436445236\n","Save item: 26 / best_val_loss: 0.42245851159095765\n","Save item: 26 / best_val_loss: 0.4220299005508423\n","[epoch : 360 / 500] Train Loss : 0.3842845443222258\n","Save item: 26 / best_val_loss: 0.42030214667320254\n","Save item: 26 / best_val_loss: 0.42025381326675415\n","[epoch : 370 / 500] Train Loss : 0.3874306066168679\n","[epoch : 380 / 500] Train Loss : 0.38029211428430343\n","Save item: 26 / best_val_loss: 0.4151871621608734\n","[epoch : 390 / 500] Train Loss : 0.38198213113678825\n","[epoch : 400 / 500] Train Loss : 0.38208027018441093\n","[epoch : 410 / 500] Train Loss : 0.38130752742290497\n","[epoch : 420 / 500] Train Loss : 0.37899548643165165\n","[epoch : 430 / 500] Train Loss : 0.38247743911213344\n","[epoch : 440 / 500] Train Loss : 0.37927403880490196\n","[epoch : 450 / 500] Train Loss : 0.38024575842751396\n","[epoch : 460 / 500] Train Loss : 0.37810273799631333\n","Save item: 26 / best_val_loss: 0.41475197672843933\n","[epoch : 470 / 500] Train Loss : 0.3821067280239529\n","[epoch : 480 / 500] Train Loss : 0.37813184161980945\n","[epoch : 490 / 500] Train Loss : 0.3814479493432575\n","[epoch : 500 / 500] Train Loss : 0.38007888197898865\n","1419\n","[    0.      5859.1016  6049.2993  6300.4956  6510.7     7770.831\n","  7924.6655 11692.737   7342.571   6722.7144     0.         0.\n","     0.         0.         0.         0.         0.      7168.5703\n","  6630.0493  5708.2734  4795.763      0.      4305.321   4071.5186\n","  3839.0752  3735.0664  3940.269   3706.5376]\n","0.0\n","[-1.         -0.40123177 -0.3817946  -0.3561237  -0.33464193 -0.20586343\n"," -0.1901424   0.19493401 -0.24962929 -0.31297526 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.2674112\n"," -0.3224451  -0.4166456  -0.50989914 -1.         -0.5600197  -0.583913\n"," -0.60766745 -0.61829656 -0.597326   -0.62121207]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 27 / best_val_loss: 0.43523179888725283\n","Save item: 27 / best_val_loss: 0.4281026065349579\n","Save item: 27 / best_val_loss: 0.42558935284614563\n","Save item: 27 / best_val_loss: 0.4248771250247955\n","Save item: 27 / best_val_loss: 0.42190575003623965\n","Save item: 27 / best_val_loss: 0.4218347370624542\n","Save item: 27 / best_val_loss: 0.41760910153388975\n","Save item: 27 / best_val_loss: 0.41321627497673036\n","Save item: 27 / best_val_loss: 0.406677657365799\n","[epoch : 10 / 500] Train Loss : 0.4087391909625795\n","Save item: 27 / best_val_loss: 0.40387595295906065\n","Save item: 27 / best_val_loss: 0.3975243866443634\n","Save item: 27 / best_val_loss: 0.39165173172950746\n","Save item: 27 / best_val_loss: 0.38839674592018125\n","Save item: 27 / best_val_loss: 0.3868036508560181\n","Save item: 27 / best_val_loss: 0.38574164509773257\n","Save item: 27 / best_val_loss: 0.38403564095497134\n","Save item: 27 / best_val_loss: 0.3819034337997437\n","Save item: 27 / best_val_loss: 0.3772317349910736\n","[epoch : 20 / 500] Train Loss : 0.37796544863118064\n","Save item: 27 / best_val_loss: 0.3740752458572388\n","Save item: 27 / best_val_loss: 0.373525470495224\n","Save item: 27 / best_val_loss: 0.37072513103485105\n","Save item: 27 / best_val_loss: 0.36457450985908507\n","Save item: 27 / best_val_loss: 0.36182125806808474\n","Save item: 27 / best_val_loss: 0.3614540219306946\n","[epoch : 30 / 500] Train Loss : 0.35498546891742283\n","Save item: 27 / best_val_loss: 0.35622020363807677\n","Save item: 27 / best_val_loss: 0.35458258390426634\n","Save item: 27 / best_val_loss: 0.34843074679374697\n","[epoch : 40 / 500] Train Loss : 0.33985069394111633\n","Save item: 27 / best_val_loss: 0.34655256271362306\n","Save item: 27 / best_val_loss: 0.34409294128417967\n","[epoch : 50 / 500] Train Loss : 0.33533013032542336\n","[epoch : 60 / 500] Train Loss : 0.33182910912566715\n","Save item: 27 / best_val_loss: 0.3440918385982513\n","Save item: 27 / best_val_loss: 0.3434648633003235\n","[epoch : 70 / 500] Train Loss : 0.32382692727777695\n","Save item: 27 / best_val_loss: 0.3418883740901947\n","[epoch : 80 / 500] Train Loss : 0.32370668318536544\n","Save item: 27 / best_val_loss: 0.33970760703086855\n","Save item: 27 / best_val_loss: 0.3392850816249847\n","[epoch : 90 / 500] Train Loss : 0.3185992356803682\n","Save item: 27 / best_val_loss: 0.33740028738975525\n","Save item: 27 / best_val_loss: 0.33617183566093445\n","[epoch : 100 / 500] Train Loss : 0.31733689043256974\n","Save item: 27 / best_val_loss: 0.33565241694450376\n","Save item: 27 / best_val_loss: 0.33449655771255493\n","[epoch : 110 / 500] Train Loss : 0.31639912558926475\n","Save item: 27 / best_val_loss: 0.3320097506046295\n","[epoch : 120 / 500] Train Loss : 0.3149009115166134\n","Save item: 27 / best_val_loss: 0.33122740387916566\n","[epoch : 130 / 500] Train Loss : 0.3155174305041631\n","[epoch : 140 / 500] Train Loss : 0.31229274140463936\n","[epoch : 150 / 500] Train Loss : 0.3120361136065589\n","Save item: 27 / best_val_loss: 0.3284867167472839\n","[epoch : 160 / 500] Train Loss : 0.3099033534526825\n","[epoch : 170 / 500] Train Loss : 0.3093893412086699\n","[epoch : 180 / 500] Train Loss : 0.30973568393124473\n","[epoch : 190 / 500] Train Loss : 0.3065321958727307\n","[epoch : 200 / 500] Train Loss : 0.30595480567879146\n","[epoch : 210 / 500] Train Loss : 0.3064860055843989\n","Save item: 27 / best_val_loss: 0.3267203688621521\n","[epoch : 220 / 500] Train Loss : 0.3053865217500263\n","Save item: 27 / best_val_loss: 0.3252767503261566\n","[epoch : 230 / 500] Train Loss : 0.3078909715016683\n","[epoch : 240 / 500] Train Loss : 0.30472712881035274\n","[epoch : 250 / 500] Train Loss : 0.3041753139760759\n","[epoch : 260 / 500] Train Loss : 0.30839523010783726\n","Save item: 27 / best_val_loss: 0.3244104444980621\n","[epoch : 270 / 500] Train Loss : 0.30819717215167153\n","[epoch : 280 / 500] Train Loss : 0.3068676342566808\n","[epoch : 290 / 500] Train Loss : 0.30451226565572953\n","[epoch : 300 / 500] Train Loss : 0.30422942340373993\n","[epoch : 310 / 500] Train Loss : 0.30469458136293626\n","[epoch : 320 / 500] Train Loss : 0.3038541343477037\n","[epoch : 330 / 500] Train Loss : 0.30384088224834865\n","[epoch : 340 / 500] Train Loss : 0.3050459888246324\n","[epoch : 350 / 500] Train Loss : 0.30206313067012364\n","Save item: 27 / best_val_loss: 0.3240437924861908\n","[epoch : 360 / 500] Train Loss : 0.3008214020066791\n","Save item: 27 / best_val_loss: 0.3236827373504639\n","[epoch : 370 / 500] Train Loss : 0.3001776221725676\n","Save item: 27 / best_val_loss: 0.3235607147216797\n","[epoch : 380 / 500] Train Loss : 0.3007291422949897\n","Save item: 27 / best_val_loss: 0.32121325731277467\n","[epoch : 390 / 500] Train Loss : 0.2990676048729155\n","[epoch : 400 / 500] Train Loss : 0.3005145755079057\n","[epoch : 410 / 500] Train Loss : 0.2998306039306853\n","[epoch : 420 / 500] Train Loss : 0.2985574934217665\n","[epoch : 430 / 500] Train Loss : 0.2987944516870711\n","[epoch : 440 / 500] Train Loss : 0.29847274389531875\n","[epoch : 450 / 500] Train Loss : 0.29780032237370807\n","[epoch : 460 / 500] Train Loss : 0.3000367167923186\n","[epoch : 470 / 500] Train Loss : 0.2986636575725343\n","[epoch : 480 / 500] Train Loss : 0.29779617819521165\n","[epoch : 490 / 500] Train Loss : 0.2990322957436244\n","[epoch : 500 / 500] Train Loss : 0.2965453647904926\n","1419\n","[  0.      754.39777 777.70184 794.2257  815.1534  791.8394  758.3613\n"," 772.92426 706.9391  707.49054   0.        0.        0.        0.\n","   0.        0.        0.      829.389   875.28235 886.10297 872.39557\n","   0.      800.7594  791.15857 815.5845  722.78516 700.29004 711.3997 ]\n","0.0\n","[-0.99999994 -0.11775888 -0.09050559 -0.07118153 -0.04670737 -0.07397221\n"," -0.11312363 -0.09609281 -0.1732601  -0.1726152  -0.99999994 -0.99999994\n"," -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.03005935\n","  0.02361131  0.03626563  0.02023532 -0.99999994 -0.06354061 -0.07476844\n"," -0.04620322 -0.1547287  -0.18103592 -0.16804355]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 28 / best_val_loss: 0.39225074648857117\n","Save item: 28 / best_val_loss: 0.38590178489685056\n","Save item: 28 / best_val_loss: 0.3818289339542389\n","Save item: 28 / best_val_loss: 0.38147603869438174\n","Save item: 28 / best_val_loss: 0.3803079307079315\n","Save item: 28 / best_val_loss: 0.37878809571266175\n","Save item: 28 / best_val_loss: 0.3785986304283142\n","Save item: 28 / best_val_loss: 0.37604419589042665\n","[epoch : 10 / 500] Train Loss : 0.3897724697987239\n","Save item: 28 / best_val_loss: 0.3740325033664703\n","Save item: 28 / best_val_loss: 0.37376317381858826\n","Save item: 28 / best_val_loss: 0.369228333234787\n","Save item: 28 / best_val_loss: 0.36640043258666993\n","Save item: 28 / best_val_loss: 0.36054913997650145\n","Save item: 28 / best_val_loss: 0.35680281519889834\n","Save item: 28 / best_val_loss: 0.3562216401100159\n","Save item: 28 / best_val_loss: 0.35365220308303835\n","Save item: 28 / best_val_loss: 0.3529113233089447\n","[epoch : 20 / 500] Train Loss : 0.36642105711830986\n","Save item: 28 / best_val_loss: 0.3502614676952362\n","Save item: 28 / best_val_loss: 0.3497121334075928\n","Save item: 28 / best_val_loss: 0.34648668169975283\n","Save item: 28 / best_val_loss: 0.3461854517459869\n","[epoch : 30 / 500] Train Loss : 0.35173527068561977\n","Save item: 28 / best_val_loss: 0.3416153430938721\n","Save item: 28 / best_val_loss: 0.341154021024704\n","Save item: 28 / best_val_loss: 0.3339322030544281\n","Save item: 28 / best_val_loss: 0.33006649017333983\n","[epoch : 40 / 500] Train Loss : 0.3296037432220247\n","Save item: 28 / best_val_loss: 0.32944992184638977\n","Save item: 28 / best_val_loss: 0.32106007933616637\n","Save item: 28 / best_val_loss: 0.31685741543769835\n","[epoch : 50 / 500] Train Loss : 0.3153952740960651\n","Save item: 28 / best_val_loss: 0.31684368252754214\n","Save item: 28 / best_val_loss: 0.3138083338737488\n","[epoch : 60 / 500] Train Loss : 0.3050975071059333\n","Save item: 28 / best_val_loss: 0.311436265707016\n","Save item: 28 / best_val_loss: 0.3102952837944031\n","Save item: 28 / best_val_loss: 0.3098787009716034\n","[epoch : 70 / 500] Train Loss : 0.3000556876262029\n","Save item: 28 / best_val_loss: 0.30896868109703063\n","[epoch : 80 / 500] Train Loss : 0.29909117850992417\n","Save item: 28 / best_val_loss: 0.307228809595108\n","Save item: 28 / best_val_loss: 0.3035295486450195\n","Save item: 28 / best_val_loss: 0.30289468765258787\n","[epoch : 90 / 500] Train Loss : 0.2964054114288754\n","[epoch : 100 / 500] Train Loss : 0.29620006183783215\n","Save item: 28 / best_val_loss: 0.3022767066955566\n","[epoch : 110 / 500] Train Loss : 0.2929680910375383\n","Save item: 28 / best_val_loss: 0.30195537209510803\n","Save item: 28 / best_val_loss: 0.3014228045940399\n","[epoch : 120 / 500] Train Loss : 0.29354636039998794\n","Save item: 28 / best_val_loss: 0.30017359256744386\n","[epoch : 130 / 500] Train Loss : 0.2910192691617542\n","Save item: 28 / best_val_loss: 0.29929018020629883\n","Save item: 28 / best_val_loss: 0.2937179505825043\n","[epoch : 140 / 500] Train Loss : 0.28953426082928974\n","[epoch : 150 / 500] Train Loss : 0.2889759855137931\n","[epoch : 160 / 500] Train Loss : 0.28756413360436756\n","[epoch : 170 / 500] Train Loss : 0.28610145052274066\n","[epoch : 180 / 500] Train Loss : 0.28615520728958976\n","[epoch : 190 / 500] Train Loss : 0.2852076631453302\n","Save item: 28 / best_val_loss: 0.2922792613506317\n","[epoch : 200 / 500] Train Loss : 0.28583303921752506\n","Save item: 28 / best_val_loss: 0.2918020009994507\n","[epoch : 210 / 500] Train Loss : 0.28464104069603813\n","[epoch : 220 / 500] Train Loss : 0.28393301367759705\n","[epoch : 230 / 500] Train Loss : 0.2839797834555308\n","Save item: 28 / best_val_loss: 0.2912693679332733\n","[epoch : 240 / 500] Train Loss : 0.28359711170196533\n","Save item: 28 / best_val_loss: 0.2912392795085907\n","[epoch : 250 / 500] Train Loss : 0.28278839422596824\n","[epoch : 260 / 500] Train Loss : 0.2849267257584466\n","Save item: 28 / best_val_loss: 0.2904932975769043\n","[epoch : 270 / 500] Train Loss : 0.286216613319185\n","[epoch : 280 / 500] Train Loss : 0.28476088907983566\n","Save item: 28 / best_val_loss: 0.28975444436073305\n","[epoch : 290 / 500] Train Loss : 0.2849064767360687\n","[epoch : 300 / 500] Train Loss : 0.28403353525532615\n","[epoch : 310 / 500] Train Loss : 0.284077617029349\n","Save item: 28 / best_val_loss: 0.28873171210289\n","[epoch : 320 / 500] Train Loss : 0.2829645011160109\n","Save item: 28 / best_val_loss: 0.28871879577636717\n","[epoch : 330 / 500] Train Loss : 0.28104182415538365\n","Save item: 28 / best_val_loss: 0.287332683801651\n","[epoch : 340 / 500] Train Loss : 0.2828058832221561\n","[epoch : 350 / 500] Train Loss : 0.28252052432960933\n","Save item: 28 / best_val_loss: 0.2866120457649231\n","[epoch : 360 / 500] Train Loss : 0.2806870871120029\n","[epoch : 370 / 500] Train Loss : 0.28040340460009044\n","[epoch : 380 / 500] Train Loss : 0.2791628978318638\n","[epoch : 390 / 500] Train Loss : 0.280608964463075\n","Save item: 28 / best_val_loss: 0.2857501685619354\n","[epoch : 400 / 500] Train Loss : 0.2789612387617429\n","[epoch : 410 / 500] Train Loss : 0.27963775893052417\n","[epoch : 420 / 500] Train Loss : 0.2796148161093394\n","[epoch : 430 / 500] Train Loss : 0.2788148174683253\n","[epoch : 440 / 500] Train Loss : 0.2785317475597064\n","Save item: 28 / best_val_loss: 0.2851754009723663\n","[epoch : 450 / 500] Train Loss : 0.2778840942515267\n","[epoch : 460 / 500] Train Loss : 0.2787265073921945\n","[epoch : 470 / 500] Train Loss : 0.27860819465584225\n","[epoch : 480 / 500] Train Loss : 0.2794946100976732\n","Save item: 28 / best_val_loss: 0.28447123169898986\n","[epoch : 490 / 500] Train Loss : 0.27886306908395553\n","[epoch : 500 / 500] Train Loss : 0.2772556046644847\n","1419\n","[   0.     1617.6421 1578.0985 1588.119  1482.4943 1434.2744 1404.3615\n","    0.     1232.3887 1324.1284    0.        0.        0.        0.\n","    0.        0.        0.     1425.4476 1646.8667 1460.2305 1429.0186\n","    0.     1286.463  1180.3159 1271.9819 1239.1432 1251.219   973.1092]\n","0.0\n","[-0.99999994  0.06883547  0.04270757  0.04932849 -0.02046166 -0.05232228\n"," -0.07208688 -0.99999994 -0.1857156  -0.1250998  -0.99999994 -0.99999994\n"," -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.05815446\n","  0.08814523 -0.03517217 -0.05579502 -0.99999994 -0.1499867  -0.22012198\n"," -0.15955488 -0.18125264 -0.17327371 -0.35703108]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 29 / best_val_loss: 0.310687792301178\n","Save item: 29 / best_val_loss: 0.30374839901924133\n","Save item: 29 / best_val_loss: 0.3016966700553894\n","Save item: 29 / best_val_loss: 0.30085369348526003\n","Save item: 29 / best_val_loss: 0.30024234652519227\n","Save item: 29 / best_val_loss: 0.2976931631565094\n","Save item: 29 / best_val_loss: 0.29625526666641233\n","[epoch : 10 / 500] Train Loss : 0.2934444414244758\n","Save item: 29 / best_val_loss: 0.29539747834205626\n","Save item: 29 / best_val_loss: 0.2913581609725952\n","Save item: 29 / best_val_loss: 0.2888778746128082\n","Save item: 29 / best_val_loss: 0.2849820852279663\n","Save item: 29 / best_val_loss: 0.2813902199268341\n","Save item: 29 / best_val_loss: 0.280455607175827\n","Save item: 29 / best_val_loss: 0.2788208305835724\n","Save item: 29 / best_val_loss: 0.278646320104599\n","[epoch : 20 / 500] Train Loss : 0.2756451219320297\n","Save item: 29 / best_val_loss: 0.27793375253677366\n","Save item: 29 / best_val_loss: 0.2744986414909363\n","Save item: 29 / best_val_loss: 0.2725195735692978\n","[epoch : 30 / 500] Train Loss : 0.2687820924652947\n","Save item: 29 / best_val_loss: 0.2717420220375061\n","Save item: 29 / best_val_loss: 0.2709038257598877\n","Save item: 29 / best_val_loss: 0.26709542274475095\n","[epoch : 40 / 500] Train Loss : 0.26305222511291504\n","Save item: 29 / best_val_loss: 0.26703548431396484\n","Save item: 29 / best_val_loss: 0.2668562263250351\n","Save item: 29 / best_val_loss: 0.2660178244113922\n","Save item: 29 / best_val_loss: 0.26269079744815826\n","[epoch : 50 / 500] Train Loss : 0.2551683667633269\n","Save item: 29 / best_val_loss: 0.26099596321582796\n","Save item: 29 / best_val_loss: 0.2602726399898529\n","Save item: 29 / best_val_loss: 0.25972052216529845\n","Save item: 29 / best_val_loss: 0.2560098201036453\n","[epoch : 60 / 500] Train Loss : 0.24951141907109153\n","Save item: 29 / best_val_loss: 0.25517959594726564\n","[epoch : 70 / 500] Train Loss : 0.24705307765139473\n","Save item: 29 / best_val_loss: 0.2534093797206879\n","[epoch : 80 / 500] Train Loss : 0.2420793515112665\n","Save item: 29 / best_val_loss: 0.2532787561416626\n","Save item: 29 / best_val_loss: 0.2531378537416458\n","[epoch : 90 / 500] Train Loss : 0.2420667600300577\n","Save item: 29 / best_val_loss: 0.25282080471515656\n","Save item: 29 / best_val_loss: 0.25281298756599424\n","Save item: 29 / best_val_loss: 0.2524551093578339\n","[epoch : 100 / 500] Train Loss : 0.24009079982837042\n","Save item: 29 / best_val_loss: 0.25228464007377627\n","Save item: 29 / best_val_loss: 0.25046661496162415\n","[epoch : 110 / 500] Train Loss : 0.23865945802794564\n","[epoch : 120 / 500] Train Loss : 0.23757370230224398\n","[epoch : 130 / 500] Train Loss : 0.2384756894575225\n","Save item: 29 / best_val_loss: 0.25021120309829714\n","[epoch : 140 / 500] Train Loss : 0.23682120856311586\n","Save item: 29 / best_val_loss: 0.24966350793838502\n","[epoch : 150 / 500] Train Loss : 0.23536907550361422\n","Save item: 29 / best_val_loss: 0.24956524074077607\n","Save item: 29 / best_val_loss: 0.24920913875102996\n","[epoch : 160 / 500] Train Loss : 0.23531734777821434\n","[epoch : 170 / 500] Train Loss : 0.23387115614281762\n","Save item: 29 / best_val_loss: 0.24810881018638611\n","[epoch : 180 / 500] Train Loss : 0.2350450712773535\n","[epoch : 190 / 500] Train Loss : 0.23363769468333986\n","Save item: 29 / best_val_loss: 0.24770630300045013\n","[epoch : 200 / 500] Train Loss : 0.2330478553970655\n","Save item: 29 / best_val_loss: 0.24757059216499328\n","[epoch : 210 / 500] Train Loss : 0.23323852154943678\n","[epoch : 220 / 500] Train Loss : 0.23390292790200976\n","Save item: 29 / best_val_loss: 0.24707939922809602\n","Save item: 29 / best_val_loss: 0.24648604691028594\n","[epoch : 230 / 500] Train Loss : 0.23265734811623892\n","[epoch : 240 / 500] Train Loss : 0.2330207700530688\n","Save item: 29 / best_val_loss: 0.24575157463550568\n","[epoch : 250 / 500] Train Loss : 0.23329616255230373\n","[epoch : 260 / 500] Train Loss : 0.23397570103406906\n","[epoch : 270 / 500] Train Loss : 0.23363289733727774\n","Save item: 29 / best_val_loss: 0.24559333622455598\n","[epoch : 280 / 500] Train Loss : 0.2340186064441999\n","[epoch : 290 / 500] Train Loss : 0.23280683077043957\n","[epoch : 300 / 500] Train Loss : 0.2319800787501865\n","[epoch : 310 / 500] Train Loss : 0.23232677578926086\n","Save item: 29 / best_val_loss: 0.24513967633247374\n","[epoch : 320 / 500] Train Loss : 0.2317767706182268\n","[epoch : 330 / 500] Train Loss : 0.23147005753384697\n","[epoch : 340 / 500] Train Loss : 0.23252853833966786\n","[epoch : 350 / 500] Train Loss : 0.23064291642771828\n","[epoch : 360 / 500] Train Loss : 0.2303667664527893\n","[epoch : 370 / 500] Train Loss : 0.23001601464218563\n","Save item: 29 / best_val_loss: 0.24469184577465058\n","[epoch : 380 / 500] Train Loss : 0.22939738796816933\n","[epoch : 390 / 500] Train Loss : 0.2303692532910241\n","[epoch : 400 / 500] Train Loss : 0.22898725006315443\n","Save item: 29 / best_val_loss: 0.24304646849632264\n","[epoch : 410 / 500] Train Loss : 0.22999597754743364\n","[epoch : 420 / 500] Train Loss : 0.22915390216641957\n","[epoch : 430 / 500] Train Loss : 0.22954744514491823\n","[epoch : 440 / 500] Train Loss : 0.22936908569600847\n","[epoch : 450 / 500] Train Loss : 0.228079278435972\n","[epoch : 460 / 500] Train Loss : 0.22948571460114586\n","[epoch : 470 / 500] Train Loss : 0.22889787620968288\n","[epoch : 480 / 500] Train Loss : 0.22898210171196196\n","Save item: 29 / best_val_loss: 0.24264392852783204\n","[epoch : 490 / 500] Train Loss : 0.22854962365494835\n","[epoch : 500 / 500] Train Loss : 0.22890093591478136\n","1419\n","[   0.     1101.3265 1043.0643 1104.314  1061.0054 1103.5216 1114.0975\n","    0.     1100.934  1072.0914    0.        0.        0.        0.\n","    0.        0.        0.     1175.7897 1229.8918 1224.4176 1211.0245\n","    0.     1226.3055 1241.7096 1184.098  1189.2087 1206.1227 1210.9199]\n","0.0\n","[-0.99999994  0.24388863  0.17808463  0.24726278  0.19834806  0.24636784\n","  0.2583128  -0.99999994  0.24344523  0.21086916 -0.99999994 -0.99999994\n"," -0.99999994 -0.99999994 -0.99999994 -0.99999994 -0.99999994  0.3279907\n","  0.38909617  0.38291332  0.3677866  -0.99999994  0.38504565  0.40244368\n","  0.33737454  0.34314683  0.3622502   0.36766842]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 30 / best_val_loss: 0.2875242650508881\n","Save item: 30 / best_val_loss: 0.27630714178085325\n","Save item: 30 / best_val_loss: 0.27433645725250244\n","Save item: 30 / best_val_loss: 0.2737515687942505\n","Save item: 30 / best_val_loss: 0.2724491536617279\n","Save item: 30 / best_val_loss: 0.2722283661365509\n","Save item: 30 / best_val_loss: 0.272040992975235\n","Save item: 30 / best_val_loss: 0.2719419598579407\n","[epoch : 10 / 500] Train Loss : 0.27996650172604454\n","Save item: 30 / best_val_loss: 0.27140088081359864\n","Save item: 30 / best_val_loss: 0.27128779888153076\n","Save item: 30 / best_val_loss: 0.27111181020736697\n","Save item: 30 / best_val_loss: 0.2709055483341217\n","Save item: 30 / best_val_loss: 0.270582914352417\n","Save item: 30 / best_val_loss: 0.2704441249370575\n","[epoch : 20 / 500] Train Loss : 0.2795170462793774\n","Save item: 30 / best_val_loss: 0.269979864358902\n","Save item: 30 / best_val_loss: 0.2694988131523132\n","Save item: 30 / best_val_loss: 0.2693432211875916\n","Save item: 30 / best_val_loss: 0.26781620979309084\n","[epoch : 30 / 500] Train Loss : 0.2752214123805364\n","Save item: 30 / best_val_loss: 0.2669072329998016\n","Save item: 30 / best_val_loss: 0.265554279088974\n","Save item: 30 / best_val_loss: 0.26234063506126404\n","Save item: 30 / best_val_loss: 0.2591851443052292\n","Save item: 30 / best_val_loss: 0.2583868682384491\n","Save item: 30 / best_val_loss: 0.25542067289352416\n","[epoch : 40 / 500] Train Loss : 0.26141781277126735\n","Save item: 30 / best_val_loss: 0.25536141991615297\n","Save item: 30 / best_val_loss: 0.2535479962825775\n","Save item: 30 / best_val_loss: 0.2526459038257599\n","Save item: 30 / best_val_loss: 0.2516764611005783\n","Save item: 30 / best_val_loss: 0.24988601803779603\n","Save item: 30 / best_val_loss: 0.24950079321861268\n","Save item: 30 / best_val_loss: 0.24852557778358458\n","[epoch : 50 / 500] Train Loss : 0.2510893154475424\n","Save item: 30 / best_val_loss: 0.2470630556344986\n","Save item: 30 / best_val_loss: 0.2454746276140213\n","Save item: 30 / best_val_loss: 0.244137179851532\n","Save item: 30 / best_val_loss: 0.24319076240062715\n","Save item: 30 / best_val_loss: 0.23951684236526488\n","[epoch : 60 / 500] Train Loss : 0.2426123105817371\n","Save item: 30 / best_val_loss: 0.2391002893447876\n","Save item: 30 / best_val_loss: 0.2384011685848236\n","Save item: 30 / best_val_loss: 0.23715210556983948\n","[epoch : 70 / 500] Train Loss : 0.23642701903978983\n","Save item: 30 / best_val_loss: 0.235491544008255\n","Save item: 30 / best_val_loss: 0.23453484773635863\n","[epoch : 80 / 500] Train Loss : 0.23098283261060715\n","Save item: 30 / best_val_loss: 0.23339026272296906\n","Save item: 30 / best_val_loss: 0.23112423419952394\n","[epoch : 90 / 500] Train Loss : 0.22851008259587818\n","[epoch : 100 / 500] Train Loss : 0.22671087996827233\n","Save item: 30 / best_val_loss: 0.22894709706306457\n","Save item: 30 / best_val_loss: 0.22836299538612365\n","[epoch : 110 / 500] Train Loss : 0.22463325493865544\n","Save item: 30 / best_val_loss: 0.22711290121078492\n","[epoch : 120 / 500] Train Loss : 0.22435039612982008\n","[epoch : 130 / 500] Train Loss : 0.22154311173492008\n","Save item: 30 / best_val_loss: 0.22623217105865479\n","[epoch : 140 / 500] Train Loss : 0.22171771277983984\n","Save item: 30 / best_val_loss: 0.225446218252182\n","Save item: 30 / best_val_loss: 0.22470879256725312\n","[epoch : 150 / 500] Train Loss : 0.22027387883928087\n","[epoch : 160 / 500] Train Loss : 0.21804405583275688\n","Save item: 30 / best_val_loss: 0.22409034371376038\n","[epoch : 170 / 500] Train Loss : 0.21885548449224895\n","[epoch : 180 / 500] Train Loss : 0.21902273346980414\n","[epoch : 190 / 500] Train Loss : 0.21704939918385613\n","Save item: 30 / best_val_loss: 0.2233365684747696\n","[epoch : 200 / 500] Train Loss : 0.2163920659157965\n","Save item: 30 / best_val_loss: 0.22235419750213622\n","[epoch : 210 / 500] Train Loss : 0.21563700089852014\n","Save item: 30 / best_val_loss: 0.22142547965049744\n","Save item: 30 / best_val_loss: 0.22141788601875306\n","[epoch : 220 / 500] Train Loss : 0.2161835233370463\n","Save item: 30 / best_val_loss: 0.22064403295516968\n","[epoch : 230 / 500] Train Loss : 0.21671138372686174\n","[epoch : 240 / 500] Train Loss : 0.2158568667040931\n","[epoch : 250 / 500] Train Loss : 0.2153773026333915\n","[epoch : 260 / 500] Train Loss : 0.2158200161324607\n","[epoch : 270 / 500] Train Loss : 0.21576283540990618\n","[epoch : 280 / 500] Train Loss : 0.21513347079356512\n","[epoch : 290 / 500] Train Loss : 0.21529365248150295\n","[epoch : 300 / 500] Train Loss : 0.21535186138417986\n","Save item: 30 / best_val_loss: 0.22048189043998717\n","Save item: 30 / best_val_loss: 0.21889549493789673\n","[epoch : 310 / 500] Train Loss : 0.21472682224379647\n","[epoch : 320 / 500] Train Loss : 0.2145141280359692\n","[epoch : 330 / 500] Train Loss : 0.21344122207827038\n","Save item: 30 / best_val_loss: 0.21798080205917358\n","[epoch : 340 / 500] Train Loss : 0.21459903981950548\n","[epoch : 350 / 500] Train Loss : 0.21411174452967113\n","[epoch : 360 / 500] Train Loss : 0.21271761672364342\n","[epoch : 370 / 500] Train Loss : 0.21232632961538103\n","Save item: 30 / best_val_loss: 0.21767187118530273\n","[epoch : 380 / 500] Train Loss : 0.21174578865369162\n","Save item: 30 / best_val_loss: 0.21764300763607025\n","[epoch : 390 / 500] Train Loss : 0.2115948067771064\n","[epoch : 400 / 500] Train Loss : 0.2113538028465377\n","[epoch : 410 / 500] Train Loss : 0.21169958098067176\n","[epoch : 420 / 500] Train Loss : 0.21155268450578055\n","Save item: 30 / best_val_loss: 0.21734857857227324\n","[epoch : 430 / 500] Train Loss : 0.2110640530784925\n","[epoch : 440 / 500] Train Loss : 0.21155600166983074\n","[epoch : 450 / 500] Train Loss : 0.21151936302582422\n","Save item: 30 / best_val_loss: 0.21720472872257232\n","Save item: 30 / best_val_loss: 0.21671970784664155\n","[epoch : 460 / 500] Train Loss : 0.21042773127555847\n","[epoch : 470 / 500] Train Loss : 0.2111489185028606\n","[epoch : 480 / 500] Train Loss : 0.21059001568290922\n","[epoch : 490 / 500] Train Loss : 0.2109331323040856\n","[epoch : 500 / 500] Train Loss : 0.21074412928687203\n","1419\n","[   0.     4517.8237 4995.283  4575.3853 4493.2173 4688.36   4971.713\n","    0.     4848.142  3872.5054    0.        0.        0.        0.\n","    0.        0.        0.     3125.962  3003.8757 2852.5835 2557.1252\n","    0.     2438.429  2366.6672 2415.5042 2539.6387 2700.835  2706.3452]\n","0.0\n","[-1.          0.42141294  0.57163286  0.43952313  0.41367117  0.4750676\n","  0.5642171  -1.          0.5253388   0.2183807  -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.01649931\n"," -0.05491048 -0.10251055 -0.19546862 -1.         -0.23281325 -0.25539115\n"," -0.24002594 -0.2009703  -0.15025419 -0.14852053]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 31 / best_val_loss: 0.40638257265090943\n","Save item: 31 / best_val_loss: 0.40044487714767457\n","Save item: 31 / best_val_loss: 0.39843891859054564\n","Save item: 31 / best_val_loss: 0.39760587811470033\n","Save item: 31 / best_val_loss: 0.39704582691192625\n","Save item: 31 / best_val_loss: 0.39693754315376284\n","Save item: 31 / best_val_loss: 0.39548357129096984\n","Save item: 31 / best_val_loss: 0.39469903111457827\n","[epoch : 10 / 500] Train Loss : 0.3972139341963662\n","Save item: 31 / best_val_loss: 0.3925087332725525\n","Save item: 31 / best_val_loss: 0.39131964445114137\n","Save item: 31 / best_val_loss: 0.38514944911003113\n","Save item: 31 / best_val_loss: 0.3756794214248657\n","Save item: 31 / best_val_loss: 0.36881842017173766\n","Save item: 31 / best_val_loss: 0.36668511629104616\n","Save item: 31 / best_val_loss: 0.3626193702220917\n","[epoch : 20 / 500] Train Loss : 0.3592260513040755\n","Save item: 31 / best_val_loss: 0.3603876352310181\n","Save item: 31 / best_val_loss: 0.35796340703964236\n","Save item: 31 / best_val_loss: 0.3509097695350647\n","Save item: 31 / best_val_loss: 0.34893377423286437\n","[epoch : 30 / 500] Train Loss : 0.3426062994533115\n","Save item: 31 / best_val_loss: 0.3437972664833069\n","Save item: 31 / best_val_loss: 0.33944480419158934\n","Save item: 31 / best_val_loss: 0.3357882142066956\n","Save item: 31 / best_val_loss: 0.3340561330318451\n","[epoch : 40 / 500] Train Loss : 0.3225837465789583\n","Save item: 31 / best_val_loss: 0.3318924129009247\n","Save item: 31 / best_val_loss: 0.32818966507911684\n","[epoch : 50 / 500] Train Loss : 0.3149355947971344\n","Save item: 31 / best_val_loss: 0.32768869400024414\n","Save item: 31 / best_val_loss: 0.32632540464401244\n","[epoch : 60 / 500] Train Loss : 0.3086680190430747\n","Save item: 31 / best_val_loss: 0.32525829076766966\n","[epoch : 70 / 500] Train Loss : 0.3060169418652852\n","Save item: 31 / best_val_loss: 0.32179136872291564\n","[epoch : 80 / 500] Train Loss : 0.3007405681742562\n","[epoch : 90 / 500] Train Loss : 0.29835156930817497\n","[epoch : 100 / 500] Train Loss : 0.29345297978983986\n","Save item: 31 / best_val_loss: 0.3214716911315918\n","Save item: 31 / best_val_loss: 0.32117493748664855\n","Save item: 31 / best_val_loss: 0.3211281538009644\n","[epoch : 110 / 500] Train Loss : 0.2910115371147792\n","Save item: 31 / best_val_loss: 0.3208049714565277\n","Save item: 31 / best_val_loss: 0.3200850248336792\n","Save item: 31 / best_val_loss: 0.3199364602565765\n","Save item: 31 / best_val_loss: 0.31924609541893006\n","[epoch : 120 / 500] Train Loss : 0.2901234444644716\n","[epoch : 130 / 500] Train Loss : 0.2892632136742274\n","Save item: 31 / best_val_loss: 0.3170917212963104\n","[epoch : 140 / 500] Train Loss : 0.2859642720884747\n","Save item: 31 / best_val_loss: 0.313176429271698\n","[epoch : 150 / 500] Train Loss : 0.28599341544840073\n","[epoch : 160 / 500] Train Loss : 0.28516626275247997\n","[epoch : 170 / 500] Train Loss : 0.2852588974767261\n","Save item: 31 / best_val_loss: 0.3128260672092438\n","[epoch : 180 / 500] Train Loss : 0.2841717733277215\n","[epoch : 190 / 500] Train Loss : 0.28150345881779987\n","Save item: 31 / best_val_loss: 0.31259437203407286\n","[epoch : 200 / 500] Train Loss : 0.2812466902865304\n","Save item: 31 / best_val_loss: 0.3118307054042816\n","[epoch : 210 / 500] Train Loss : 0.28256166146861184\n","Save item: 31 / best_val_loss: 0.31145281791687013\n","[epoch : 220 / 500] Train Loss : 0.28050265378422207\n","[epoch : 230 / 500] Train Loss : 0.2804885125822491\n","[epoch : 240 / 500] Train Loss : 0.2800856911473804\n","[epoch : 250 / 500] Train Loss : 0.280914048353831\n","[epoch : 260 / 500] Train Loss : 0.282336938712332\n","Save item: 31 / best_val_loss: 0.3100168764591217\n","[epoch : 270 / 500] Train Loss : 0.2825357798073027\n","Save item: 31 / best_val_loss: 0.307359391450882\n","[epoch : 280 / 500] Train Loss : 0.28371360235744053\n","[epoch : 290 / 500] Train Loss : 0.28066116240289474\n","[epoch : 300 / 500] Train Loss : 0.27985096474488574\n","Save item: 31 / best_val_loss: 0.30710819363594055\n","[epoch : 310 / 500] Train Loss : 0.2814325905508465\n","[epoch : 320 / 500] Train Loss : 0.2791543271806505\n","Save item: 31 / best_val_loss: 0.3071074545383453\n","[epoch : 330 / 500] Train Loss : 0.2798819906181759\n","Save item: 31 / best_val_loss: 0.30467469096183775\n","[epoch : 340 / 500] Train Loss : 0.2789378977484173\n","[epoch : 350 / 500] Train Loss : 0.2808842923906114\n","Save item: 31 / best_val_loss: 0.3033642590045929\n","[epoch : 360 / 500] Train Loss : 0.2755122250980801\n","[epoch : 370 / 500] Train Loss : 0.27562258972062004\n","[epoch : 380 / 500] Train Loss : 0.27533840305275387\n","[epoch : 390 / 500] Train Loss : 0.2731524987353219\n","[epoch : 400 / 500] Train Loss : 0.2736627989345127\n","[epoch : 410 / 500] Train Loss : 0.2735731270578172\n","[epoch : 420 / 500] Train Loss : 0.2753109642201\n","[epoch : 430 / 500] Train Loss : 0.27398006204101777\n","[epoch : 440 / 500] Train Loss : 0.27324582388003665\n","[epoch : 450 / 500] Train Loss : 0.27366160932514405\n","[epoch : 460 / 500] Train Loss : 0.2724580019712448\n","Save item: 31 / best_val_loss: 0.3018946945667267\n","[epoch : 470 / 500] Train Loss : 0.27355798499451744\n","[epoch : 480 / 500] Train Loss : 0.27347654269801247\n","Save item: 31 / best_val_loss: 0.3017536699771881\n","[epoch : 490 / 500] Train Loss : 0.27343155774805283\n","[epoch : 500 / 500] Train Loss : 0.27305300037066144\n","1419\n","[   0.     5052.3335 5252.9385 5097.345  4354.4863 5234.9507 4919.6235\n","    0.     5407.1284 4750.7476    0.        0.        0.        0.\n","    0.        0.        0.     5220.5347 4560.5312 5346.061  4569.23\n","    0.     5457.0674 5392.406  5145.66   4344.957  5246.871  5027.9053]\n","0.0\n","[-1.         -0.2124641  -0.18119466 -0.20544787 -0.3212415  -0.18399853\n"," -0.23315035 -1.         -0.15716021 -0.259474   -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.18624564\n"," -0.2891241  -0.16667913 -0.2877682  -1.         -0.14937595 -0.15945512\n"," -0.19791675 -0.32272688 -0.18214042 -0.21627186]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 32 / best_val_loss: 0.2842168748378754\n","Save item: 32 / best_val_loss: 0.2750703155994415\n","Save item: 32 / best_val_loss: 0.2722580790519714\n","Save item: 32 / best_val_loss: 0.27133705019950866\n","Save item: 32 / best_val_loss: 0.2701850891113281\n","Save item: 32 / best_val_loss: 0.2701667547225952\n","Save item: 32 / best_val_loss: 0.2696996986865997\n","[epoch : 10 / 500] Train Loss : 0.27225180053048664\n","Save item: 32 / best_val_loss: 0.26908902525901796\n","Save item: 32 / best_val_loss: 0.26885191798210145\n","Save item: 32 / best_val_loss: 0.2682983160018921\n","Save item: 32 / best_val_loss: 0.2680967807769775\n","Save item: 32 / best_val_loss: 0.2680657863616943\n","[epoch : 20 / 500] Train Loss : 0.269087547229396\n","Save item: 32 / best_val_loss: 0.266842246055603\n","Save item: 32 / best_val_loss: 0.2667081832885742\n","Save item: 32 / best_val_loss: 0.2654512941837311\n","Save item: 32 / best_val_loss: 0.26285263895988464\n","Save item: 32 / best_val_loss: 0.2627703845500946\n","Save item: 32 / best_val_loss: 0.26025733947753904\n","Save item: 32 / best_val_loss: 0.2594771146774292\n","Save item: 32 / best_val_loss: 0.2555857807397842\n","Save item: 32 / best_val_loss: 0.25294102132320406\n","[epoch : 30 / 500] Train Loss : 0.25566410190529293\n","Save item: 32 / best_val_loss: 0.25267917215824126\n","Save item: 32 / best_val_loss: 0.25225613117218015\n","Save item: 32 / best_val_loss: 0.2515482932329178\n","Save item: 32 / best_val_loss: 0.25017977356910703\n","[epoch : 40 / 500] Train Loss : 0.2509557298488087\n","Save item: 32 / best_val_loss: 0.24752487540245055\n","Save item: 32 / best_val_loss: 0.24728649258613586\n","Save item: 32 / best_val_loss: 0.24651741087436677\n","Save item: 32 / best_val_loss: 0.24633544087409973\n","Save item: 32 / best_val_loss: 0.24560152888298034\n","[epoch : 50 / 500] Train Loss : 0.24519288457102245\n","Save item: 32 / best_val_loss: 0.24386868476867676\n","Save item: 32 / best_val_loss: 0.24245551824569703\n","Save item: 32 / best_val_loss: 0.24167628288269044\n","Save item: 32 / best_val_loss: 0.24166449904441833\n","Save item: 32 / best_val_loss: 0.24141076803207398\n","Save item: 32 / best_val_loss: 0.2379173219203949\n","Save item: 32 / best_val_loss: 0.23740753829479216\n","[epoch : 60 / 500] Train Loss : 0.23421861893600887\n","Save item: 32 / best_val_loss: 0.2364745706319809\n","Save item: 32 / best_val_loss: 0.23569915890693666\n","Save item: 32 / best_val_loss: 0.23449819087982177\n","[epoch : 70 / 500] Train Loss : 0.23070103343990114\n","Save item: 32 / best_val_loss: 0.23351401686668397\n","Save item: 32 / best_val_loss: 0.23241402804851533\n","Save item: 32 / best_val_loss: 0.2318655550479889\n","[epoch : 80 / 500] Train Loss : 0.22873887419700623\n","Save item: 32 / best_val_loss: 0.23106510937213898\n","[epoch : 90 / 500] Train Loss : 0.22734288622935614\n","Save item: 32 / best_val_loss: 0.23031371533870698\n","[epoch : 100 / 500] Train Loss : 0.22544660419225693\n","[epoch : 110 / 500] Train Loss : 0.223818801343441\n","Save item: 32 / best_val_loss: 0.2298684000968933\n","[epoch : 120 / 500] Train Loss : 0.2235556956794527\n","Save item: 32 / best_val_loss: 0.2276834011077881\n","[epoch : 130 / 500] Train Loss : 0.22442035211457145\n","[epoch : 140 / 500] Train Loss : 0.22258709205521476\n","[epoch : 150 / 500] Train Loss : 0.22265582945611742\n","[epoch : 160 / 500] Train Loss : 0.22179993987083435\n","[epoch : 170 / 500] Train Loss : 0.22082123657067618\n","[epoch : 180 / 500] Train Loss : 0.22081108639637628\n","[epoch : 190 / 500] Train Loss : 0.2201223439640469\n","[epoch : 200 / 500] Train Loss : 0.22068244384394753\n","Save item: 32 / best_val_loss: 0.22736580967903136\n","[epoch : 210 / 500] Train Loss : 0.2198313367035654\n","Save item: 32 / best_val_loss: 0.22730086743831635\n","[epoch : 220 / 500] Train Loss : 0.21922155883577135\n","Save item: 32 / best_val_loss: 0.22597595751285554\n","[epoch : 230 / 500] Train Loss : 0.22000659339957768\n","[epoch : 240 / 500] Train Loss : 0.21840257942676544\n","[epoch : 250 / 500] Train Loss : 0.21931518531507915\n","[epoch : 260 / 500] Train Loss : 0.22018937766551971\n","[epoch : 270 / 500] Train Loss : 0.2196294309364425\n","[epoch : 280 / 500] Train Loss : 0.21907281461689207\n","[epoch : 290 / 500] Train Loss : 0.21892177230781978\n","[epoch : 300 / 500] Train Loss : 0.21840638667345047\n","[epoch : 310 / 500] Train Loss : 0.21810438566737705\n","[epoch : 320 / 500] Train Loss : 0.21855387422773573\n","[epoch : 330 / 500] Train Loss : 0.21825024320019615\n","[epoch : 340 / 500] Train Loss : 0.21810386495457756\n","[epoch : 350 / 500] Train Loss : 0.21768119268947178\n","[epoch : 360 / 500] Train Loss : 0.21737419979439843\n","[epoch : 370 / 500] Train Loss : 0.21600725418991512\n","[epoch : 380 / 500] Train Loss : 0.2167359640200933\n","[epoch : 390 / 500] Train Loss : 0.2165821757581499\n","[epoch : 400 / 500] Train Loss : 0.21642352557844585\n","[epoch : 410 / 500] Train Loss : 0.2156517364912563\n","[epoch : 420 / 500] Train Loss : 0.2154382268587748\n","[epoch : 430 / 500] Train Loss : 0.21564893507295185\n","Save item: 32 / best_val_loss: 0.225816747546196\n","[epoch : 440 / 500] Train Loss : 0.21627982209126154\n","[epoch : 450 / 500] Train Loss : 0.2157862592074606\n","[epoch : 460 / 500] Train Loss : 0.215636498398251\n","Save item: 32 / best_val_loss: 0.22520437240600585\n","[epoch : 470 / 500] Train Loss : 0.2159181104765998\n","[epoch : 480 / 500] Train Loss : 0.21572208321756786\n","[epoch : 490 / 500] Train Loss : 0.21508647667037117\n","[epoch : 500 / 500] Train Loss : 0.21579084628158146\n","1419\n","[   0.     2194.5498 1739.5696 1889.6766 1849.3704 1902.3529 2747.1465\n","    0.     2182.8413 1912.4148    0.        0.        0.        0.\n","    0.        0.        0.     2450.8765 1336.8024 2118.1829 1954.3291\n","    0.     2085.4094 2350.6992 1916.2041 2085.3628 1766.5725 2292.5315]\n","0.0\n","[-1.          0.19484319 -0.05287505  0.02885214  0.00690701  0.03575385\n","  0.49570963 -1.          0.1884684   0.04123214 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.33440262\n"," -0.27216542  0.1532645   0.06405278 -1.          0.13542068  0.2798602\n","  0.04329526  0.13539529 -0.03817306  0.24819024]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 33 / best_val_loss: 0.294549560546875\n","Save item: 33 / best_val_loss: 0.2852394819259644\n","Save item: 33 / best_val_loss: 0.28337817788124087\n","Save item: 33 / best_val_loss: 0.28269878029823303\n","Save item: 33 / best_val_loss: 0.28196335434913633\n","Save item: 33 / best_val_loss: 0.2810999870300293\n","[epoch : 10 / 500] Train Loss : 0.3032799114783605\n","Save item: 33 / best_val_loss: 0.2804369866847992\n","Save item: 33 / best_val_loss: 0.28043299317359927\n","Save item: 33 / best_val_loss: 0.28034302592277527\n","Save item: 33 / best_val_loss: 0.27994775772094727\n","Save item: 33 / best_val_loss: 0.2794689953327179\n","[epoch : 20 / 500] Train Loss : 0.3021089086929957\n","Save item: 33 / best_val_loss: 0.27926074266433715\n","Save item: 33 / best_val_loss: 0.2789611995220184\n","Save item: 33 / best_val_loss: 0.27780950665473936\n","Save item: 33 / best_val_loss: 0.2777725398540497\n","Save item: 33 / best_val_loss: 0.27770366072654723\n","Save item: 33 / best_val_loss: 0.2767492175102234\n","[epoch : 30 / 500] Train Loss : 0.29574426511923474\n","Save item: 33 / best_val_loss: 0.2741569459438324\n","Save item: 33 / best_val_loss: 0.2721652090549469\n","Save item: 33 / best_val_loss: 0.26850171387195587\n","Save item: 33 / best_val_loss: 0.2668869853019714\n","[epoch : 40 / 500] Train Loss : 0.2882312337557475\n","Save item: 33 / best_val_loss: 0.26685540080070497\n","Save item: 33 / best_val_loss: 0.2637451082468033\n","[epoch : 50 / 500] Train Loss : 0.2849850141339832\n","Save item: 33 / best_val_loss: 0.26002458333969114\n","[epoch : 60 / 500] Train Loss : 0.2791316658258438\n","Save item: 33 / best_val_loss: 0.2586591988801956\n","[epoch : 70 / 500] Train Loss : 0.27470216320620644\n","Save item: 33 / best_val_loss: 0.25781628489494324\n","Save item: 33 / best_val_loss: 0.25591444671154023\n","Save item: 33 / best_val_loss: 0.25463518500328064\n","[epoch : 80 / 500] Train Loss : 0.27043218082851833\n","[epoch : 90 / 500] Train Loss : 0.26759520504209733\n","Save item: 33 / best_val_loss: 0.2530657291412354\n","Save item: 33 / best_val_loss: 0.2526216089725494\n","[epoch : 100 / 500] Train Loss : 0.26610371222098667\n","[epoch : 110 / 500] Train Loss : 0.266800324122111\n","Save item: 33 / best_val_loss: 0.2520466685295105\n","[epoch : 120 / 500] Train Loss : 0.2630734129084481\n","Save item: 33 / best_val_loss: 0.250178462266922\n","[epoch : 130 / 500] Train Loss : 0.2623380588160621\n","Save item: 33 / best_val_loss: 0.24936355650424957\n","[epoch : 140 / 500] Train Loss : 0.2602437883615494\n","[epoch : 150 / 500] Train Loss : 0.25932445873816806\n","Save item: 33 / best_val_loss: 0.2491464287042618\n","[epoch : 160 / 500] Train Loss : 0.259473029938009\n","Save item: 33 / best_val_loss: 0.24901888370513917\n","Save item: 33 / best_val_loss: 0.24888987243175506\n","[epoch : 170 / 500] Train Loss : 0.2587328470415539\n","[epoch : 180 / 500] Train Loss : 0.2566722200976478\n","[epoch : 190 / 500] Train Loss : 0.25690749949879116\n","[epoch : 200 / 500] Train Loss : 0.25666806515720153\n","[epoch : 210 / 500] Train Loss : 0.25521933370166355\n","Save item: 33 / best_val_loss: 0.24650956690311432\n","[epoch : 220 / 500] Train Loss : 0.25649748494227725\n","[epoch : 230 / 500] Train Loss : 0.2554653435945511\n","[epoch : 240 / 500] Train Loss : 0.2591687829958068\n","[epoch : 250 / 500] Train Loss : 0.2548016756772995\n","[epoch : 260 / 500] Train Loss : 0.2551693601740731\n","[epoch : 270 / 500] Train Loss : 0.2569282013509009\n","[epoch : 280 / 500] Train Loss : 0.2568724809421433\n","[epoch : 290 / 500] Train Loss : 0.25514601171016693\n","[epoch : 300 / 500] Train Loss : 0.25473542511463165\n","[epoch : 310 / 500] Train Loss : 0.2554097862707244\n","[epoch : 320 / 500] Train Loss : 0.25433022611671025\n","[epoch : 330 / 500] Train Loss : 0.25534386105007595\n","[epoch : 340 / 500] Train Loss : 0.255115098423428\n","[epoch : 350 / 500] Train Loss : 0.2539737390147315\n","[epoch : 360 / 500] Train Loss : 0.2523963567283418\n","[epoch : 370 / 500] Train Loss : 0.25334256804651684\n","[epoch : 380 / 500] Train Loss : 0.25228379170099896\n","[epoch : 390 / 500] Train Loss : 0.2521259668800566\n","[epoch : 400 / 500] Train Loss : 0.25248631421062684\n","[epoch : 410 / 500] Train Loss : 0.25236327201128006\n","[epoch : 420 / 500] Train Loss : 0.2519379316104783\n","Save item: 33 / best_val_loss: 0.24608852565288544\n","[epoch : 430 / 500] Train Loss : 0.2518684110707707\n","[epoch : 440 / 500] Train Loss : 0.251409193707837\n","[epoch : 450 / 500] Train Loss : 0.25193507638242507\n","[epoch : 460 / 500] Train Loss : 0.25062966760661864\n","Save item: 33 / best_val_loss: 0.24604833126068115\n","[epoch : 470 / 500] Train Loss : 0.25569961137241787\n","[epoch : 480 / 500] Train Loss : 0.25495106395747924\n","[epoch : 490 / 500] Train Loss : 0.25144241005182266\n","Save item: 33 / best_val_loss: 0.2460339218378067\n","[epoch : 500 / 500] Train Loss : 0.257660787138674\n","1419\n","[   0.     4595.136  4807.429  4707.4624 4706.3203 4635.183  5142.759\n","    0.     5260.0625 5242.244     0.        0.        0.        0.\n","    0.        0.        0.     5866.605  5571.273  4776.3203 5019.929\n","    0.     5200.7334 5441.1055 5265.241  5302.3486 5068.8135 4897.5063]\n","0.0\n","[-1.          0.26354247  0.3219175   0.29442924  0.2941152   0.27455434\n","  0.41412437 -1.          0.44637984  0.44148025 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.          0.6131632\n","  0.5319546   0.31336337  0.38034943 -1.          0.43006587  0.4961619\n","  0.44780383  0.45800743  0.39379135  0.34668636]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 34 / best_val_loss: 0.5183277606964112\n","Save item: 34 / best_val_loss: 0.5086717903614044\n","Save item: 34 / best_val_loss: 0.5080997109413147\n","Save item: 34 / best_val_loss: 0.5023521780967712\n","Save item: 34 / best_val_loss: 0.49996744394302367\n","Save item: 34 / best_val_loss: 0.49797860980033876\n","Save item: 34 / best_val_loss: 0.49543156027793883\n","Save item: 34 / best_val_loss: 0.49273688793182374\n","Save item: 34 / best_val_loss: 0.48965963125228884\n","[epoch : 10 / 500] Train Loss : 0.4737200637658437\n","Save item: 34 / best_val_loss: 0.48703689575195314\n","Save item: 34 / best_val_loss: 0.4833871901035309\n","Save item: 34 / best_val_loss: 0.4723099648952484\n","Save item: 34 / best_val_loss: 0.4707381248474121\n","Save item: 34 / best_val_loss: 0.4671302080154419\n","Save item: 34 / best_val_loss: 0.4638341128826141\n","Save item: 34 / best_val_loss: 0.46121338605880735\n","[epoch : 20 / 500] Train Loss : 0.4484325183762444\n","Save item: 34 / best_val_loss: 0.46061971783638\n","Save item: 34 / best_val_loss: 0.45913574695587156\n","Save item: 34 / best_val_loss: 0.4567117035388947\n","Save item: 34 / best_val_loss: 0.4556366324424744\n","Save item: 34 / best_val_loss: 0.45373281836509705\n","Save item: 34 / best_val_loss: 0.4490005671977997\n","Save item: 34 / best_val_loss: 0.4475620687007904\n","Save item: 34 / best_val_loss: 0.4453052580356598\n","Save item: 34 / best_val_loss: 0.44049009680747986\n","[epoch : 30 / 500] Train Loss : 0.42388612197505104\n","Save item: 34 / best_val_loss: 0.4399232447147369\n","Save item: 34 / best_val_loss: 0.4336982429027557\n","Save item: 34 / best_val_loss: 0.42392025589942933\n","Save item: 34 / best_val_loss: 0.4221991777420044\n","Save item: 34 / best_val_loss: 0.4113132178783417\n","Save item: 34 / best_val_loss: 0.4032114088535309\n","Save item: 34 / best_val_loss: 0.4009169340133667\n","Save item: 34 / best_val_loss: 0.3919537544250488\n","[epoch : 40 / 500] Train Loss : 0.3830098294549518\n","Save item: 34 / best_val_loss: 0.385054874420166\n","Save item: 34 / best_val_loss: 0.38417510986328124\n","Save item: 34 / best_val_loss: 0.3797748327255249\n","Save item: 34 / best_val_loss: 0.3774255156517029\n","[epoch : 50 / 500] Train Loss : 0.3731870949268341\n","Save item: 34 / best_val_loss: 0.3768678426742554\n","Save item: 34 / best_val_loss: 0.3748459994792938\n","Save item: 34 / best_val_loss: 0.3726012289524078\n","Save item: 34 / best_val_loss: 0.37203449606895445\n","[epoch : 60 / 500] Train Loss : 0.36978964342011345\n","[epoch : 70 / 500] Train Loss : 0.36375246610906387\n","Save item: 34 / best_val_loss: 0.3713653266429901\n","Save item: 34 / best_val_loss: 0.3696086585521698\n","Save item: 34 / best_val_loss: 0.3684770464897156\n","Save item: 34 / best_val_loss: 0.36680845022201536\n","[epoch : 80 / 500] Train Loss : 0.3620661314990785\n","Save item: 34 / best_val_loss: 0.3667615532875061\n","[epoch : 90 / 500] Train Loss : 0.35486043492952984\n","Save item: 34 / best_val_loss: 0.3667257249355316\n","Save item: 34 / best_val_loss: 0.36520002484321595\n","[epoch : 100 / 500] Train Loss : 0.3554546733697255\n","Save item: 34 / best_val_loss: 0.3612845242023468\n","Save item: 34 / best_val_loss: 0.36081458926200866\n","Save item: 34 / best_val_loss: 0.35818732380867\n","[epoch : 110 / 500] Train Loss : 0.3533584425846736\n","Save item: 34 / best_val_loss: 0.35730778574943545\n","[epoch : 120 / 500] Train Loss : 0.34953799347082776\n","[epoch : 130 / 500] Train Loss : 0.3469194422165553\n","Save item: 34 / best_val_loss: 0.3554833948612213\n","[epoch : 140 / 500] Train Loss : 0.3442484570874108\n","Save item: 34 / best_val_loss: 0.3548291325569153\n","[epoch : 150 / 500] Train Loss : 0.34400304986370933\n","[epoch : 160 / 500] Train Loss : 0.3424147665500641\n","Save item: 34 / best_val_loss: 0.35317754149436953\n","[epoch : 170 / 500] Train Loss : 0.34592749509546494\n","[epoch : 180 / 500] Train Loss : 0.3431153529220157\n","[epoch : 190 / 500] Train Loss : 0.34136752121978337\n","[epoch : 200 / 500] Train Loss : 0.3420584251483281\n","[epoch : 210 / 500] Train Loss : 0.33720071117083233\n","Save item: 34 / best_val_loss: 0.3527517795562744\n","[epoch : 220 / 500] Train Loss : 0.3389727887180116\n","Save item: 34 / best_val_loss: 0.35179752111434937\n","[epoch : 230 / 500] Train Loss : 0.33863749106725055\n","Save item: 34 / best_val_loss: 0.34961138367652894\n","Save item: 34 / best_val_loss: 0.3443882465362549\n","[epoch : 240 / 500] Train Loss : 0.33705894814597237\n","[epoch : 250 / 500] Train Loss : 0.3385451270474328\n","[epoch : 260 / 500] Train Loss : 0.3426393684413698\n","[epoch : 270 / 500] Train Loss : 0.33881008956167435\n","[epoch : 280 / 500] Train Loss : 0.33889856437842053\n","[epoch : 290 / 500] Train Loss : 0.33869500789377427\n","[epoch : 300 / 500] Train Loss : 0.3355913956960042\n","[epoch : 310 / 500] Train Loss : 0.33528804779052734\n","[epoch : 320 / 500] Train Loss : 0.338311321205563\n","[epoch : 330 / 500] Train Loss : 0.3371223575539059\n","[epoch : 340 / 500] Train Loss : 0.33478204078144497\n","[epoch : 350 / 500] Train Loss : 0.3342165682050917\n","[epoch : 360 / 500] Train Loss : 0.3352079391479492\n","Save item: 34 / best_val_loss: 0.3436100006103516\n","Save item: 34 / best_val_loss: 0.3433867871761322\n","[epoch : 370 / 500] Train Loss : 0.33413512342505985\n","[epoch : 380 / 500] Train Loss : 0.33308933675289154\n","Save item: 34 / best_val_loss: 0.3427428722381592\n","[epoch : 390 / 500] Train Loss : 0.3315059029393726\n","[epoch : 400 / 500] Train Loss : 0.3308767163091236\n","[epoch : 410 / 500] Train Loss : 0.33194080822997624\n","[epoch : 420 / 500] Train Loss : 0.3276643604040146\n","Save item: 34 / best_val_loss: 0.34187416434288026\n","[epoch : 430 / 500] Train Loss : 0.32867251005437637\n","[epoch : 440 / 500] Train Loss : 0.3290615893072552\n","[epoch : 450 / 500] Train Loss : 0.327906534075737\n","[epoch : 460 / 500] Train Loss : 0.3307957384321425\n","[epoch : 470 / 500] Train Loss : 0.3301288170946969\n","[epoch : 480 / 500] Train Loss : 0.3290968636671702\n","[epoch : 490 / 500] Train Loss : 0.3286609782112969\n","[epoch : 500 / 500] Train Loss : 0.3285389029317432\n","1419\n","[   0.     2916.6177 3035.857  3134.0476 3202.7107 3670.0488 4245.2524\n"," 3419.157  4329.976  3873.4749    0.        0.        0.        0.\n","    0.        0.        0.     2422.1387 2369.6836 2217.4036 2060.5344\n","    0.     2202.2385 2290.301  2237.4924 2185.776  2102.4937 2047.485 ]\n","0.0\n","[-1.         -0.06068247 -0.02228062  0.00934239  0.03145582  0.18196541\n","  0.36721382  0.10116389  0.39449966  0.24748021 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.21993296\n"," -0.2368265  -0.28586936 -0.3363902  -1.         -0.29075336 -0.26239222\n"," -0.2793996  -0.2960553  -0.32287693 -0.34059286]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 35 / best_val_loss: 0.35423324108123777\n","Save item: 35 / best_val_loss: 0.34739983081817627\n","Save item: 35 / best_val_loss: 0.3453726232051849\n","Save item: 35 / best_val_loss: 0.3448968231678009\n","Save item: 35 / best_val_loss: 0.34481804966926577\n","Save item: 35 / best_val_loss: 0.34392355680465697\n","Save item: 35 / best_val_loss: 0.3432453453540802\n","Save item: 35 / best_val_loss: 0.3419890940189362\n","[epoch : 10 / 500] Train Loss : 0.3346011820766661\n","Save item: 35 / best_val_loss: 0.3418129086494446\n","Save item: 35 / best_val_loss: 0.3402911305427551\n","Save item: 35 / best_val_loss: 0.3396638810634613\n","Save item: 35 / best_val_loss: 0.33730012774467466\n","Save item: 35 / best_val_loss: 0.3333811342716217\n","Save item: 35 / best_val_loss: 0.3308872997760773\n","Save item: 35 / best_val_loss: 0.33045232892036436\n","[epoch : 20 / 500] Train Loss : 0.31797971328099567\n","Save item: 35 / best_val_loss: 0.3299257457256317\n","Save item: 35 / best_val_loss: 0.3280417501926422\n","Save item: 35 / best_val_loss: 0.3255860090255737\n","Save item: 35 / best_val_loss: 0.32511124610900877\n","Save item: 35 / best_val_loss: 0.32184109687805174\n","Save item: 35 / best_val_loss: 0.31994168758392333\n","Save item: 35 / best_val_loss: 0.3198890745639801\n","[epoch : 30 / 500] Train Loss : 0.3051919572883182\n","Save item: 35 / best_val_loss: 0.3198068797588348\n","Save item: 35 / best_val_loss: 0.31662113070487974\n","Save item: 35 / best_val_loss: 0.3150116324424744\n","Save item: 35 / best_val_loss: 0.3120538294315338\n","Save item: 35 / best_val_loss: 0.3120002746582031\n","Save item: 35 / best_val_loss: 0.31134181618690493\n","Save item: 35 / best_val_loss: 0.30990574359893797\n","Save item: 35 / best_val_loss: 0.3070057272911072\n","[epoch : 40 / 500] Train Loss : 0.2924799654218886\n","Save item: 35 / best_val_loss: 0.305360472202301\n","Save item: 35 / best_val_loss: 0.30468294620513914\n","Save item: 35 / best_val_loss: 0.3031557500362396\n","Save item: 35 / best_val_loss: 0.30010764598846434\n","Save item: 35 / best_val_loss: 0.2997817397117615\n","[epoch : 50 / 500] Train Loss : 0.2849038640658061\n","Save item: 35 / best_val_loss: 0.2990721881389618\n","Save item: 35 / best_val_loss: 0.2968185722827911\n","Save item: 35 / best_val_loss: 0.29667251706123354\n","Save item: 35 / best_val_loss: 0.2961341142654419\n","Save item: 35 / best_val_loss: 0.29542307257652284\n","Save item: 35 / best_val_loss: 0.29437199234962463\n","Save item: 35 / best_val_loss: 0.2929190993309021\n","[epoch : 60 / 500] Train Loss : 0.2794765912824207\n","Save item: 35 / best_val_loss: 0.2913693070411682\n","Save item: 35 / best_val_loss: 0.2908335506916046\n","[epoch : 70 / 500] Train Loss : 0.2754072646299998\n","Save item: 35 / best_val_loss: 0.29040477275848386\n","Save item: 35 / best_val_loss: 0.28914942741394045\n","Save item: 35 / best_val_loss: 0.289053338766098\n","Save item: 35 / best_val_loss: 0.28823958039283754\n","[epoch : 80 / 500] Train Loss : 0.2734663610657056\n","Save item: 35 / best_val_loss: 0.28611661195755006\n","[epoch : 90 / 500] Train Loss : 0.27012068695492214\n","Save item: 35 / best_val_loss: 0.2858801126480103\n","Save item: 35 / best_val_loss: 0.2847787499427795\n","[epoch : 100 / 500] Train Loss : 0.26973145372337765\n","[epoch : 110 / 500] Train Loss : 0.2680768428577317\n","Save item: 35 / best_val_loss: 0.2843126475811005\n","Save item: 35 / best_val_loss: 0.2841734766960144\n","Save item: 35 / best_val_loss: 0.28379571437835693\n","Save item: 35 / best_val_loss: 0.2829544901847839\n","[epoch : 120 / 500] Train Loss : 0.26760584281550515\n","Save item: 35 / best_val_loss: 0.2812145292758942\n","[epoch : 130 / 500] Train Loss : 0.26604078710079193\n","Save item: 35 / best_val_loss: 0.280454957485199\n","[epoch : 140 / 500] Train Loss : 0.2669497811132007\n","[epoch : 150 / 500] Train Loss : 0.2662711772653792\n","[epoch : 160 / 500] Train Loss : 0.2631453176339467\n","Save item: 35 / best_val_loss: 0.278814309835434\n","[epoch : 170 / 500] Train Loss : 0.265287679930528\n","[epoch : 180 / 500] Train Loss : 0.26210195074478787\n","[epoch : 190 / 500] Train Loss : 0.26319358083936906\n","[epoch : 200 / 500] Train Loss : 0.26216210838821197\n","Save item: 35 / best_val_loss: 0.2781437873840332\n","[epoch : 210 / 500] Train Loss : 0.2625702718893687\n","[epoch : 220 / 500] Train Loss : 0.26203153365188175\n","Save item: 35 / best_val_loss: 0.27760844230651854\n","[epoch : 230 / 500] Train Loss : 0.2624342267711957\n","[epoch : 240 / 500] Train Loss : 0.2613797311981519\n","Save item: 35 / best_val_loss: 0.27759422063827516\n","[epoch : 250 / 500] Train Loss : 0.26117993228965336\n","[epoch : 260 / 500] Train Loss : 0.26433822760979336\n","[epoch : 270 / 500] Train Loss : 0.2633036325375239\n","Save item: 35 / best_val_loss: 0.2773532152175903\n","[epoch : 280 / 500] Train Loss : 0.2621420853667789\n","[epoch : 290 / 500] Train Loss : 0.26282915141847396\n","[epoch : 300 / 500] Train Loss : 0.26145448618465\n","[epoch : 310 / 500] Train Loss : 0.26169534855418736\n","[epoch : 320 / 500] Train Loss : 0.26152415242460036\n","Save item: 35 / best_val_loss: 0.2764682054519653\n","[epoch : 330 / 500] Train Loss : 0.26178120490577483\n","[epoch : 340 / 500] Train Loss : 0.2606376450922754\n","Save item: 35 / best_val_loss: 0.27639161348342894\n","[epoch : 350 / 500] Train Loss : 0.2595154800348812\n","[epoch : 360 / 500] Train Loss : 0.25887314726909\n","Save item: 35 / best_val_loss: 0.2746959149837494\n","[epoch : 370 / 500] Train Loss : 0.25882405208216774\n","[epoch : 380 / 500] Train Loss : 0.2591021541092131\n","[epoch : 390 / 500] Train Loss : 0.25773318111896515\n","[epoch : 400 / 500] Train Loss : 0.25855951921807396\n","[epoch : 410 / 500] Train Loss : 0.25803492549392915\n","[epoch : 420 / 500] Train Loss : 0.257824595603678\n","Save item: 35 / best_val_loss: 0.2731498062610626\n","[epoch : 430 / 500] Train Loss : 0.25679270592000747\n","[epoch : 440 / 500] Train Loss : 0.2575184247559971\n","[epoch : 450 / 500] Train Loss : 0.2571963734096951\n","[epoch : 460 / 500] Train Loss : 0.2578511718246672\n","[epoch : 470 / 500] Train Loss : 0.25798999187019134\n","[epoch : 480 / 500] Train Loss : 0.25651345650355023\n","[epoch : 490 / 500] Train Loss : 0.2572377845644951\n","[epoch : 500 / 500] Train Loss : 0.25666927215125823\n","1419\n","[   0.     1711.2798 1690.3645 1649.0424 1621.3358 1624.5515 1714.7244\n"," 1521.52   1968.3241 1940.0653    0.        0.        0.        0.\n","    0.        0.        0.     1538.1498 1440.0488 1354.7017 1278.4019\n","    0.     1337.1991 1369.4221 1366.5316 1311.4436 1237.2888 1220.2393]\n","0.0\n","[-1.         -0.05450889 -0.06606469 -0.0888954  -0.10420341 -0.10242672\n"," -0.05260574 -0.15935217  0.08750945  0.07189631 -1.         -1.\n"," -1.         -1.         -1.         -1.         -1.         -0.15016413\n"," -0.20436543 -0.2515202  -0.29367623 -1.         -0.26119044 -0.24338706\n"," -0.24498408 -0.2754205  -0.31639138 -0.32581136]\n","torch.Size([64, 14, 49])\n","torch.Size([64, 28])\n","Save item: 36 / best_val_loss: 0.3881786286830902\n","Save item: 36 / best_val_loss: 0.3819129765033722\n","Save item: 36 / best_val_loss: 0.3788849115371704\n","Save item: 36 / best_val_loss: 0.37865898609161375\n","Save item: 36 / best_val_loss: 0.3776146709918976\n","Save item: 36 / best_val_loss: 0.375847202539444\n","Save item: 36 / best_val_loss: 0.3757036507129669\n","Save item: 36 / best_val_loss: 0.3743929326534271\n","[epoch : 10 / 500] Train Loss : 0.374328323536449\n","Save item: 36 / best_val_loss: 0.3729194700717926\n","Save item: 36 / best_val_loss: 0.3710954189300537\n","Save item: 36 / best_val_loss: 0.36694958806037903\n","Save item: 36 / best_val_loss: 0.3639427304267883\n","Save item: 36 / best_val_loss: 0.36077134013175965\n","Save item: 36 / best_val_loss: 0.3568974435329437\n","Save item: 36 / best_val_loss: 0.35455859899520875\n","Save item: 36 / best_val_loss: 0.35143098831176756\n","Save item: 36 / best_val_loss: 0.34867175817489626\n","[epoch : 20 / 500] Train Loss : 0.34283023575941723\n","Save item: 36 / best_val_loss: 0.3475963890552521\n","Save item: 36 / best_val_loss: 0.3429792821407318\n","Save item: 36 / best_val_loss: 0.34185829758644104\n","Save item: 36 / best_val_loss: 0.33698501586914065\n","Save item: 36 / best_val_loss: 0.3340225279331207\n","Save item: 36 / best_val_loss: 0.32926628589630125\n","Save item: 36 / best_val_loss: 0.3275515854358673\n","[epoch : 30 / 500] Train Loss : 0.316814081536399\n","Save item: 36 / best_val_loss: 0.3237206220626831\n","Save item: 36 / best_val_loss: 0.323186457157135\n","Save item: 36 / best_val_loss: 0.3200766444206238\n","Save item: 36 / best_val_loss: 0.3177601516246796\n","Save item: 36 / best_val_loss: 0.3145399272441864\n","Save item: 36 / best_val_loss: 0.3121377944946289\n","[epoch : 40 / 500] Train Loss : 0.3063656704293357\n","Save item: 36 / best_val_loss: 0.31149669289588927\n","Save item: 36 / best_val_loss: 0.30814495086669924\n","Save item: 36 / best_val_loss: 0.3067959785461426\n","[epoch : 50 / 500] Train Loss : 0.2973147713475757\n","Save item: 36 / best_val_loss: 0.30556777119636536\n","Save item: 36 / best_val_loss: 0.3050354659557343\n","[epoch : 60 / 500] Train Loss : 0.29306725329822964\n","Save item: 36 / best_val_loss: 0.30232191681861875\n","[epoch : 70 / 500] Train Loss : 0.2883167051606708\n","Save item: 36 / best_val_loss: 0.30181390047073364\n","Save item: 36 / best_val_loss: 0.3001867711544037\n","Save item: 36 / best_val_loss: 0.29959850311279296\n","Save item: 36 / best_val_loss: 0.29519970417022706\n","[epoch : 80 / 500] Train Loss : 0.2854890508784188\n","[epoch : 90 / 500] Train Loss : 0.28208182752132416\n","[epoch : 100 / 500] Train Loss : 0.2815714693731732\n","Save item: 36 / best_val_loss: 0.293417352437973\n","[epoch : 110 / 500] Train Loss : 0.27911637557877433\n","Save item: 36 / best_val_loss: 0.2923099935054779\n","Save item: 36 / best_val_loss: 0.2913339138031006\n","[epoch : 120 / 500] Train Loss : 0.2776464099685351\n","[epoch : 130 / 500] Train Loss : 0.2770813918775982\n","Save item: 36 / best_val_loss: 0.28951709866523745\n","[epoch : 140 / 500] Train Loss : 0.27679582436879474\n","Save item: 36 / best_val_loss: 0.28925199508666993\n","[epoch : 150 / 500] Train Loss : 0.274687980612119\n","Save item: 36 / best_val_loss: 0.28740747570991515\n","[epoch : 160 / 500] Train Loss : 0.27297087675995296\n","[epoch : 170 / 500] Train Loss : 0.27327454338471097\n","Save item: 36 / best_val_loss: 0.28588539361953735\n","[epoch : 180 / 500] Train Loss : 0.2716280652417077\n","Save item: 36 / best_val_loss: 0.28525757789611816\n","[epoch : 190 / 500] Train Loss : 0.2715490178929435\n","Save item: 36 / best_val_loss: 0.2822986841201782\n","[epoch : 200 / 500] Train Loss : 0.27075202266375226\n","[epoch : 210 / 500] Train Loss : 0.26914241827196544\n","[epoch : 220 / 500] Train Loss : 0.2691484010881848\n","[epoch : 230 / 500] Train Loss : 0.2685786692632569\n","[epoch : 240 / 500] Train Loss : 0.2688780244853761\n","[epoch : 250 / 500] Train Loss : 0.26729418916834724\n","[epoch : 260 / 500] Train Loss : 0.2693880564636654\n","[epoch : 270 / 500] Train Loss : 0.2715894993808534\n","[epoch : 280 / 500] Train Loss : 0.26992662416564095\n","[epoch : 290 / 500] Train Loss : 0.26955147749847835\n","Save item: 36 / best_val_loss: 0.2810863435268402\n","[epoch : 300 / 500] Train Loss : 0.2688480441768964\n","[epoch : 310 / 500] Train Loss : 0.2678258601162169\n","[epoch : 320 / 500] Train Loss : 0.2676488732298215\n","Save item: 36 / best_val_loss: 0.2807122111320496\n","[epoch : 330 / 500] Train Loss : 0.2669239102138413\n","[epoch : 340 / 500] Train Loss : 0.2671566257874171\n","Save item: 36 / best_val_loss: 0.2796954572200775\n","[epoch : 350 / 500] Train Loss : 0.2673017672366566\n","[epoch : 360 / 500] Train Loss : 0.2653303485777643\n","Save item: 36 / best_val_loss: 0.27857346534729005\n","[epoch : 370 / 500] Train Loss : 0.2654583892888493\n","Save item: 36 / best_val_loss: 0.277490371465683\n","[epoch : 380 / 500] Train Loss : 0.2636522162291739\n","[epoch : 390 / 500] Train Loss : 0.26481982900036705\n","[epoch : 400 / 500] Train Loss : 0.2634242706828647\n","Save item: 36 / best_val_loss: 0.27591472864151\n","[epoch : 410 / 500] Train Loss : 0.26604917148749035\n","[epoch : 420 / 500] Train Loss : 0.26349131017923355\n","[epoch : 430 / 500] Train Loss : 0.26439804087082547\n","Save item: 36 / best_val_loss: 0.27579256892204285\n","[epoch : 440 / 500] Train Loss : 0.26261138336526024\n","[epoch : 450 / 500] Train Loss : 0.2626439705491066\n","[epoch : 460 / 500] Train Loss : 0.26237641606065965\n","[epoch : 470 / 500] Train Loss : 0.26278244372871185\n","[epoch : 480 / 500] Train Loss : 0.26404202812247807\n","Save item: 36 / best_val_loss: 0.2743068873882294\n","[epoch : 490 / 500] Train Loss : 0.2614385692609681\n","[epoch : 500 / 500] Train Loss : 0.26239127665758133\n"]}]},{"cell_type":"code","source":["def make_Tensor(array):\n","    return torch.from_numpy(array)\n","\n","\n","def astype_data(data):\n","    df = data.astype(np.float32)\n","    return make_Tensor(df)\n","\n","\n","class testDataset(Dataset):\n","    def __init__(self, data):\n","        zero_csv = [0 for i in range(14)]\n","        df = pd.read_csv(data)\n","\n","        if len(df) == 0:\n","            print('no data in Dataset!!')\n","            print(df)\n","            df['zero_non'] = zero_csv\n","            print(df)\n","            df = df.fillna(0)\n","            print(df)\n","            df.drop('zero_non', axis=1, inplace=True)\n","            df.drop('Unnamed: 0', axis=1, inplace=True)\n","            print(df)\n","\n","        file_number = data.split('test_')[1].split('.')[0]\n","\n","        # 사용할 열 선택, index 설정\n","        df.drop(ts_del_list, axis=1, inplace=True)\n","        df.set_index('datadate', drop=True, inplace=True)\n","\n","        # train input 과 형상 맞추기\n","        add_col = [i for i in check_col if i not in df.columns]\n","\n","        for a in add_col:\n","            df[a] = 0\n","\n","        # ' ' -> nan 으로 변경\n","        for a in df.columns:\n","            df[a] = df[a].replace({' ': np.nan})\n","\n","        # nan 처리\n","        df = df.fillna(0)\n","\n","        # x_test  생성\n","        self.df_test = astype_data(df.values.reshape(1, df.values.shape[0], df.values.shape[1]))\n","\n","    def __len__(self):\n","        return len(self.df_test)\n","\n","    def __getitem__(self, idx):\n","        return self.df_test[idx]"],"metadata":{"id":"9SNEISWj3L1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def submit(flags):\n","    flags = Flag(flags)\n","\n","    result_np = np.zeros((1, 28), dtype=np.float32)\n","    for item_idx in range(37):\n","\n","        net = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(14 * 49, flags.model.hid_dim),\n","            # nn.BatchNorm1d(flags.model.hid_dim),\n","            nn.ReLU(),\n","            nn.Dropout(flags.dropout),\n","        )\n","\n","        for _ in range(flags.model.nlayers - 2):\n","            net.append(nn.Linear(flags.model.hid_dim, flags.model.hid_dim))\n","            # net.append(nn.BatchNorm1d(flags.model.hid_dim))\n","            net.append(nn.ReLU())\n","            net.append(nn.Dropout(flags.dropout))\n","        \n","        net.append(nn.Linear(flags.model.hid_dim, 28))\n","\n","        net.load_state_dict(torch.load(f'./model_weights_28.bias_{item_idx}.pth'))\n","\n","        net = net.to('cuda')\n","\n","        for set_num in range(10):\n","            file_path = f'./test/set_{set_num}/test_{item_idx}.csv'\n","            test_dataset = testDataset(file_path)\n","\n","            inputs = test_dataset[0].reshape(1, 14, 49).to('cuda')\n","\n","            with torch.no_grad():\n","                outputs = net(inputs)            \n","            output_np = outputs.cpu().detach().numpy()\n","            save_df = pd.DataFrame(output_np).T\n","            save_df.to_csv(f'./set_{set_num}/predict_{item_idx}.csv', index=False)\n","            print(f'Save Result set: {set_num}, item: {item_idx}')\n","\n","flags = {\n","    'name': 'Exp_val_y_variance_001',\n","    'epochs': 500,\n","    'lr': 1e-4,\n","    'batch_size': 64,\n","    'data_num': 0,\n","    'model': {\n","        'activation': 'relu',\n","        'nlayers': 10,\n","        'hid_dim': 1024,\n","        'weight_init': 'xavier_uniform'\n","    },\n","    'optim': 'Adam',\n","    'criterion': 'L1Loss',\n","    'dropout': 0.5,\n","    'lr_scheduler': {\n","        'method': 'Lambda'\n","    }\n","}\n","submit(flags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l7_VWT1W12V2","executionInfo":{"status":"ok","timestamp":1662539111599,"user_tz":-540,"elapsed":15666,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"3b1484d2-6aee-4ca8-fbb5-5f0d97fc312c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Save Result set: 0, item: 0\n","Save Result set: 1, item: 0\n","Save Result set: 2, item: 0\n","Save Result set: 3, item: 0\n","Save Result set: 4, item: 0\n","Save Result set: 5, item: 0\n","Save Result set: 6, item: 0\n","Save Result set: 7, item: 0\n","Save Result set: 8, item: 0\n","Save Result set: 9, item: 0\n","Save Result set: 0, item: 1\n","Save Result set: 1, item: 1\n","Save Result set: 2, item: 1\n","Save Result set: 3, item: 1\n","Save Result set: 4, item: 1\n","Save Result set: 5, item: 1\n","Save Result set: 6, item: 1\n","Save Result set: 7, item: 1\n","Save Result set: 8, item: 1\n","Save Result set: 9, item: 1\n","Save Result set: 0, item: 2\n","Save Result set: 1, item: 2\n","Save Result set: 2, item: 2\n","Save Result set: 3, item: 2\n","Save Result set: 4, item: 2\n","Save Result set: 5, item: 2\n","Save Result set: 6, item: 2\n","Save Result set: 7, item: 2\n","Save Result set: 8, item: 2\n","Save Result set: 9, item: 2\n","Save Result set: 0, item: 3\n","Save Result set: 1, item: 3\n","Save Result set: 2, item: 3\n","Save Result set: 3, item: 3\n","Save Result set: 4, item: 3\n","Save Result set: 5, item: 3\n","Save Result set: 6, item: 3\n","Save Result set: 7, item: 3\n","Save Result set: 8, item: 3\n","Save Result set: 9, item: 3\n","Save Result set: 0, item: 4\n","Save Result set: 1, item: 4\n","Save Result set: 2, item: 4\n","Save Result set: 3, item: 4\n","Save Result set: 4, item: 4\n","Save Result set: 5, item: 4\n","Save Result set: 6, item: 4\n","Save Result set: 7, item: 4\n","Save Result set: 8, item: 4\n","Save Result set: 9, item: 4\n","Save Result set: 0, item: 5\n","Save Result set: 1, item: 5\n","Save Result set: 2, item: 5\n","Save Result set: 3, item: 5\n","Save Result set: 4, item: 5\n","Save Result set: 5, item: 5\n","Save Result set: 6, item: 5\n","Save Result set: 7, item: 5\n","Save Result set: 8, item: 5\n","Save Result set: 9, item: 5\n","Save Result set: 0, item: 6\n","Save Result set: 1, item: 6\n","Save Result set: 2, item: 6\n","Save Result set: 3, item: 6\n","Save Result set: 4, item: 6\n","Save Result set: 5, item: 6\n","Save Result set: 6, item: 6\n","Save Result set: 7, item: 6\n","Save Result set: 8, item: 6\n","Save Result set: 9, item: 6\n","Save Result set: 0, item: 7\n","Save Result set: 1, item: 7\n","Save Result set: 2, item: 7\n","Save Result set: 3, item: 7\n","Save Result set: 4, item: 7\n","Save Result set: 5, item: 7\n","Save Result set: 6, item: 7\n","Save Result set: 7, item: 7\n","Save Result set: 8, item: 7\n","no data in Dataset!!\n","Empty DataFrame\n","Columns: [Unnamed: 0, 단가(원), 거래량, 거래대금(원), 경매건수, 도매시장코드, 도매법인코드, 산지코드 , 해당일자_전체평균가격(원), 해당일자_전체거래물량(kg), 하위가격 평균가(원), 상위가격 평균가(원), 하위가격 거래물량(kg), 상위가격 거래물량(kg), 일자별_도매가격_최대(원), 일자별_도매가격_평균(원), 일자별_도매가격_최소(원), datadate, 일자별_소매가격_최대(원), 일자별_소매가격_평균(원), 일자별_소매가격_최소(원), 수출중량(kg), 수출금액(달러), 수입중량(kg), 수입금액(달러), 무역수지(달러), 주산지_0_초기온도(℃), 주산지_0_최대온도(℃), 주산지_0_최저온도(℃), 주산지_0_평균온도(℃), 주산지_0_강수량(ml), 주산지_0_습도(%), 주산지_1_초기온도(℃), 주산지_1_최대온도(℃), 주산지_1_최저온도(℃), 주산지_1_평균온도(℃), 주산지_1_강수량(ml), 주산지_1_습도(%), 주산지_2_초기온도(℃), 주산지_2_최대온도(℃), 주산지_2_최저온도(℃), 주산지_2_평균온도(℃), 주산지_2_강수량(ml), 주산지_2_습도(%)]\n","Index: []\n","\n","[0 rows x 44 columns]\n","   Unnamed: 0 단가(원)  거래량 거래대금(원) 경매건수 도매시장코드 도매법인코드 산지코드  해당일자_전체평균가격(원)  \\\n","0         NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","1         NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","2         NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","3         NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","4         NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","5         NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","6         NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","7         NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","8         NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","9         NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","10        NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","11        NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","12        NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","13        NaN   NaN  NaN     NaN  NaN    NaN    NaN   NaN            NaN   \n","\n","   해당일자_전체거래물량(kg)  ... 주산지_1_평균온도(℃) 주산지_1_강수량(ml) 주산지_1_습도(%) 주산지_2_초기온도(℃)  \\\n","0              NaN  ...           NaN           NaN         NaN           NaN   \n","1              NaN  ...           NaN           NaN         NaN           NaN   \n","2              NaN  ...           NaN           NaN         NaN           NaN   \n","3              NaN  ...           NaN           NaN         NaN           NaN   \n","4              NaN  ...           NaN           NaN         NaN           NaN   \n","5              NaN  ...           NaN           NaN         NaN           NaN   \n","6              NaN  ...           NaN           NaN         NaN           NaN   \n","7              NaN  ...           NaN           NaN         NaN           NaN   \n","8              NaN  ...           NaN           NaN         NaN           NaN   \n","9              NaN  ...           NaN           NaN         NaN           NaN   \n","10             NaN  ...           NaN           NaN         NaN           NaN   \n","11             NaN  ...           NaN           NaN         NaN           NaN   \n","12             NaN  ...           NaN           NaN         NaN           NaN   \n","13             NaN  ...           NaN           NaN         NaN           NaN   \n","\n","   주산지_2_최대온도(℃) 주산지_2_최저온도(℃) 주산지_2_평균온도(℃) 주산지_2_강수량(ml) 주산지_2_습도(%)  \\\n","0            NaN           NaN           NaN           NaN         NaN   \n","1            NaN           NaN           NaN           NaN         NaN   \n","2            NaN           NaN           NaN           NaN         NaN   \n","3            NaN           NaN           NaN           NaN         NaN   \n","4            NaN           NaN           NaN           NaN         NaN   \n","5            NaN           NaN           NaN           NaN         NaN   \n","6            NaN           NaN           NaN           NaN         NaN   \n","7            NaN           NaN           NaN           NaN         NaN   \n","8            NaN           NaN           NaN           NaN         NaN   \n","9            NaN           NaN           NaN           NaN         NaN   \n","10           NaN           NaN           NaN           NaN         NaN   \n","11           NaN           NaN           NaN           NaN         NaN   \n","12           NaN           NaN           NaN           NaN         NaN   \n","13           NaN           NaN           NaN           NaN         NaN   \n","\n","   zero_non  \n","0         0  \n","1         0  \n","2         0  \n","3         0  \n","4         0  \n","5         0  \n","6         0  \n","7         0  \n","8         0  \n","9         0  \n","10        0  \n","11        0  \n","12        0  \n","13        0  \n","\n","[14 rows x 45 columns]\n","    Unnamed: 0  단가(원)  거래량  거래대금(원)  경매건수  도매시장코드  도매법인코드  산지코드   \\\n","0            0      0    0        0     0       0       0      0   \n","1            0      0    0        0     0       0       0      0   \n","2            0      0    0        0     0       0       0      0   \n","3            0      0    0        0     0       0       0      0   \n","4            0      0    0        0     0       0       0      0   \n","5            0      0    0        0     0       0       0      0   \n","6            0      0    0        0     0       0       0      0   \n","7            0      0    0        0     0       0       0      0   \n","8            0      0    0        0     0       0       0      0   \n","9            0      0    0        0     0       0       0      0   \n","10           0      0    0        0     0       0       0      0   \n","11           0      0    0        0     0       0       0      0   \n","12           0      0    0        0     0       0       0      0   \n","13           0      0    0        0     0       0       0      0   \n","\n","    해당일자_전체평균가격(원)  해당일자_전체거래물량(kg)  ...  주산지_1_평균온도(℃)  주산지_1_강수량(ml)  \\\n","0                0                0  ...              0              0   \n","1                0                0  ...              0              0   \n","2                0                0  ...              0              0   \n","3                0                0  ...              0              0   \n","4                0                0  ...              0              0   \n","5                0                0  ...              0              0   \n","6                0                0  ...              0              0   \n","7                0                0  ...              0              0   \n","8                0                0  ...              0              0   \n","9                0                0  ...              0              0   \n","10               0                0  ...              0              0   \n","11               0                0  ...              0              0   \n","12               0                0  ...              0              0   \n","13               0                0  ...              0              0   \n","\n","    주산지_1_습도(%)  주산지_2_초기온도(℃)  주산지_2_최대온도(℃)  주산지_2_최저온도(℃)  주산지_2_평균온도(℃)  \\\n","0             0              0              0              0              0   \n","1             0              0              0              0              0   \n","2             0              0              0              0              0   \n","3             0              0              0              0              0   \n","4             0              0              0              0              0   \n","5             0              0              0              0              0   \n","6             0              0              0              0              0   \n","7             0              0              0              0              0   \n","8             0              0              0              0              0   \n","9             0              0              0              0              0   \n","10            0              0              0              0              0   \n","11            0              0              0              0              0   \n","12            0              0              0              0              0   \n","13            0              0              0              0              0   \n","\n","    주산지_2_강수량(ml)  주산지_2_습도(%)  zero_non  \n","0               0            0         0  \n","1               0            0         0  \n","2               0            0         0  \n","3               0            0         0  \n","4               0            0         0  \n","5               0            0         0  \n","6               0            0         0  \n","7               0            0         0  \n","8               0            0         0  \n","9               0            0         0  \n","10              0            0         0  \n","11              0            0         0  \n","12              0            0         0  \n","13              0            0         0  \n","\n","[14 rows x 45 columns]\n","    단가(원)  거래량  거래대금(원)  경매건수  도매시장코드  도매법인코드  산지코드   해당일자_전체평균가격(원)  \\\n","0       0    0        0     0       0       0      0               0   \n","1       0    0        0     0       0       0      0               0   \n","2       0    0        0     0       0       0      0               0   \n","3       0    0        0     0       0       0      0               0   \n","4       0    0        0     0       0       0      0               0   \n","5       0    0        0     0       0       0      0               0   \n","6       0    0        0     0       0       0      0               0   \n","7       0    0        0     0       0       0      0               0   \n","8       0    0        0     0       0       0      0               0   \n","9       0    0        0     0       0       0      0               0   \n","10      0    0        0     0       0       0      0               0   \n","11      0    0        0     0       0       0      0               0   \n","12      0    0        0     0       0       0      0               0   \n","13      0    0        0     0       0       0      0               0   \n","\n","    해당일자_전체거래물량(kg)  하위가격 평균가(원)  ...  주산지_1_최저온도(℃)  주산지_1_평균온도(℃)  \\\n","0                 0            0  ...              0              0   \n","1                 0            0  ...              0              0   \n","2                 0            0  ...              0              0   \n","3                 0            0  ...              0              0   \n","4                 0            0  ...              0              0   \n","5                 0            0  ...              0              0   \n","6                 0            0  ...              0              0   \n","7                 0            0  ...              0              0   \n","8                 0            0  ...              0              0   \n","9                 0            0  ...              0              0   \n","10                0            0  ...              0              0   \n","11                0            0  ...              0              0   \n","12                0            0  ...              0              0   \n","13                0            0  ...              0              0   \n","\n","    주산지_1_강수량(ml)  주산지_1_습도(%)  주산지_2_초기온도(℃)  주산지_2_최대온도(℃)  주산지_2_최저온도(℃)  \\\n","0               0            0              0              0              0   \n","1               0            0              0              0              0   \n","2               0            0              0              0              0   \n","3               0            0              0              0              0   \n","4               0            0              0              0              0   \n","5               0            0              0              0              0   \n","6               0            0              0              0              0   \n","7               0            0              0              0              0   \n","8               0            0              0              0              0   \n","9               0            0              0              0              0   \n","10              0            0              0              0              0   \n","11              0            0              0              0              0   \n","12              0            0              0              0              0   \n","13              0            0              0              0              0   \n","\n","    주산지_2_평균온도(℃)  주산지_2_강수량(ml)  주산지_2_습도(%)  \n","0               0              0            0  \n","1               0              0            0  \n","2               0              0            0  \n","3               0              0            0  \n","4               0              0            0  \n","5               0              0            0  \n","6               0              0            0  \n","7               0              0            0  \n","8               0              0            0  \n","9               0              0            0  \n","10              0              0            0  \n","11              0              0            0  \n","12              0              0            0  \n","13              0              0            0  \n","\n","[14 rows x 43 columns]\n","Save Result set: 9, item: 7\n","Save Result set: 0, item: 8\n","Save Result set: 1, item: 8\n","Save Result set: 2, item: 8\n","Save Result set: 3, item: 8\n","Save Result set: 4, item: 8\n","Save Result set: 5, item: 8\n","Save Result set: 6, item: 8\n","Save Result set: 7, item: 8\n","Save Result set: 8, item: 8\n","Save Result set: 9, item: 8\n","Save Result set: 0, item: 9\n","Save Result set: 1, item: 9\n","Save Result set: 2, item: 9\n","Save Result set: 3, item: 9\n","Save Result set: 4, item: 9\n","Save Result set: 5, item: 9\n","Save Result set: 6, item: 9\n","Save Result set: 7, item: 9\n","Save Result set: 8, item: 9\n","Save Result set: 9, item: 9\n","Save Result set: 0, item: 10\n","Save Result set: 1, item: 10\n","Save Result set: 2, item: 10\n","Save Result set: 3, item: 10\n","Save Result set: 4, item: 10\n","Save Result set: 5, item: 10\n","Save Result set: 6, item: 10\n","Save Result set: 7, item: 10\n","Save Result set: 8, item: 10\n","Save Result set: 9, item: 10\n","Save Result set: 0, item: 11\n","Save Result set: 1, item: 11\n","Save Result set: 2, item: 11\n","Save Result set: 3, item: 11\n","Save Result set: 4, item: 11\n","Save Result set: 5, item: 11\n","Save Result set: 6, item: 11\n","Save Result set: 7, item: 11\n","Save Result set: 8, item: 11\n","Save Result set: 9, item: 11\n","Save Result set: 0, item: 12\n","Save Result set: 1, item: 12\n","Save Result set: 2, item: 12\n","Save Result set: 3, item: 12\n","Save Result set: 4, item: 12\n","Save Result set: 5, item: 12\n","Save Result set: 6, item: 12\n","Save Result set: 7, item: 12\n","Save Result set: 8, item: 12\n","Save Result set: 9, item: 12\n","Save Result set: 0, item: 13\n","Save Result set: 1, item: 13\n","Save Result set: 2, item: 13\n","Save Result set: 3, item: 13\n","Save Result set: 4, item: 13\n","Save Result set: 5, item: 13\n","Save Result set: 6, item: 13\n","Save Result set: 7, item: 13\n","Save Result set: 8, item: 13\n","Save Result set: 9, item: 13\n","Save Result set: 0, item: 14\n","Save Result set: 1, item: 14\n","Save Result set: 2, item: 14\n","Save Result set: 3, item: 14\n","Save Result set: 4, item: 14\n","Save Result set: 5, item: 14\n","Save Result set: 6, item: 14\n","Save Result set: 7, item: 14\n","Save Result set: 8, item: 14\n","Save Result set: 9, item: 14\n","Save Result set: 0, item: 15\n","Save Result set: 1, item: 15\n","Save Result set: 2, item: 15\n","Save Result set: 3, item: 15\n","Save Result set: 4, item: 15\n","Save Result set: 5, item: 15\n","Save Result set: 6, item: 15\n","Save Result set: 7, item: 15\n","Save Result set: 8, item: 15\n","Save Result set: 9, item: 15\n","Save Result set: 0, item: 16\n","Save Result set: 1, item: 16\n","Save Result set: 2, item: 16\n","Save Result set: 3, item: 16\n","Save Result set: 4, item: 16\n","Save Result set: 5, item: 16\n","Save Result set: 6, item: 16\n","Save Result set: 7, item: 16\n","Save Result set: 8, item: 16\n","Save Result set: 9, item: 16\n","Save Result set: 0, item: 17\n","Save Result set: 1, item: 17\n","Save Result set: 2, item: 17\n","Save Result set: 3, item: 17\n","Save Result set: 4, item: 17\n","Save Result set: 5, item: 17\n","Save Result set: 6, item: 17\n","Save Result set: 7, item: 17\n","Save Result set: 8, item: 17\n","Save Result set: 9, item: 17\n","Save Result set: 0, item: 18\n","Save Result set: 1, item: 18\n","Save Result set: 2, item: 18\n","Save Result set: 3, item: 18\n","Save Result set: 4, item: 18\n","Save Result set: 5, item: 18\n","Save Result set: 6, item: 18\n","Save Result set: 7, item: 18\n","Save Result set: 8, item: 18\n","Save Result set: 9, item: 18\n","Save Result set: 0, item: 19\n","Save Result set: 1, item: 19\n","Save Result set: 2, item: 19\n","Save Result set: 3, item: 19\n","Save Result set: 4, item: 19\n","Save Result set: 5, item: 19\n","Save Result set: 6, item: 19\n","Save Result set: 7, item: 19\n","Save Result set: 8, item: 19\n","Save Result set: 9, item: 19\n","Save Result set: 0, item: 20\n","Save Result set: 1, item: 20\n","Save Result set: 2, item: 20\n","Save Result set: 3, item: 20\n","Save Result set: 4, item: 20\n","Save Result set: 5, item: 20\n","Save Result set: 6, item: 20\n","Save Result set: 7, item: 20\n","Save Result set: 8, item: 20\n","Save Result set: 9, item: 20\n","Save Result set: 0, item: 21\n","Save Result set: 1, item: 21\n","Save Result set: 2, item: 21\n","Save Result set: 3, item: 21\n","Save Result set: 4, item: 21\n","Save Result set: 5, item: 21\n","Save Result set: 6, item: 21\n","Save Result set: 7, item: 21\n","Save Result set: 8, item: 21\n","Save Result set: 9, item: 21\n","Save Result set: 0, item: 22\n","Save Result set: 1, item: 22\n","Save Result set: 2, item: 22\n","Save Result set: 3, item: 22\n","Save Result set: 4, item: 22\n","Save Result set: 5, item: 22\n","Save Result set: 6, item: 22\n","Save Result set: 7, item: 22\n","Save Result set: 8, item: 22\n","Save Result set: 9, item: 22\n","Save Result set: 0, item: 23\n","Save Result set: 1, item: 23\n","Save Result set: 2, item: 23\n","Save Result set: 3, item: 23\n","Save Result set: 4, item: 23\n","Save Result set: 5, item: 23\n","Save Result set: 6, item: 23\n","Save Result set: 7, item: 23\n","Save Result set: 8, item: 23\n","Save Result set: 9, item: 23\n","Save Result set: 0, item: 24\n","Save Result set: 1, item: 24\n","Save Result set: 2, item: 24\n","Save Result set: 3, item: 24\n","Save Result set: 4, item: 24\n","Save Result set: 5, item: 24\n","Save Result set: 6, item: 24\n","Save Result set: 7, item: 24\n","Save Result set: 8, item: 24\n","Save Result set: 9, item: 24\n","Save Result set: 0, item: 25\n","Save Result set: 1, item: 25\n","Save Result set: 2, item: 25\n","Save Result set: 3, item: 25\n","Save Result set: 4, item: 25\n","Save Result set: 5, item: 25\n","Save Result set: 6, item: 25\n","Save Result set: 7, item: 25\n","Save Result set: 8, item: 25\n","Save Result set: 9, item: 25\n","Save Result set: 0, item: 26\n","Save Result set: 1, item: 26\n","Save Result set: 2, item: 26\n","Save Result set: 3, item: 26\n","Save Result set: 4, item: 26\n","Save Result set: 5, item: 26\n","Save Result set: 6, item: 26\n","Save Result set: 7, item: 26\n","Save Result set: 8, item: 26\n","Save Result set: 9, item: 26\n","Save Result set: 0, item: 27\n","Save Result set: 1, item: 27\n","Save Result set: 2, item: 27\n","Save Result set: 3, item: 27\n","Save Result set: 4, item: 27\n","Save Result set: 5, item: 27\n","Save Result set: 6, item: 27\n","Save Result set: 7, item: 27\n","Save Result set: 8, item: 27\n","Save Result set: 9, item: 27\n","Save Result set: 0, item: 28\n","Save Result set: 1, item: 28\n","Save Result set: 2, item: 28\n","Save Result set: 3, item: 28\n","Save Result set: 4, item: 28\n","Save Result set: 5, item: 28\n","Save Result set: 6, item: 28\n","Save Result set: 7, item: 28\n","Save Result set: 8, item: 28\n","Save Result set: 9, item: 28\n","Save Result set: 0, item: 29\n","Save Result set: 1, item: 29\n","Save Result set: 2, item: 29\n","Save Result set: 3, item: 29\n","Save Result set: 4, item: 29\n","Save Result set: 5, item: 29\n","Save Result set: 6, item: 29\n","Save Result set: 7, item: 29\n","Save Result set: 8, item: 29\n","Save Result set: 9, item: 29\n","Save Result set: 0, item: 30\n","Save Result set: 1, item: 30\n","Save Result set: 2, item: 30\n","Save Result set: 3, item: 30\n","Save Result set: 4, item: 30\n","Save Result set: 5, item: 30\n","Save Result set: 6, item: 30\n","Save Result set: 7, item: 30\n","Save Result set: 8, item: 30\n","Save Result set: 9, item: 30\n","Save Result set: 0, item: 31\n","Save Result set: 1, item: 31\n","Save Result set: 2, item: 31\n","Save Result set: 3, item: 31\n","Save Result set: 4, item: 31\n","Save Result set: 5, item: 31\n","Save Result set: 6, item: 31\n","Save Result set: 7, item: 31\n","Save Result set: 8, item: 31\n","Save Result set: 9, item: 31\n","Save Result set: 0, item: 32\n","Save Result set: 1, item: 32\n","Save Result set: 2, item: 32\n","Save Result set: 3, item: 32\n","Save Result set: 4, item: 32\n","Save Result set: 5, item: 32\n","Save Result set: 6, item: 32\n","Save Result set: 7, item: 32\n","Save Result set: 8, item: 32\n","Save Result set: 9, item: 32\n","Save Result set: 0, item: 33\n","Save Result set: 1, item: 33\n","Save Result set: 2, item: 33\n","Save Result set: 3, item: 33\n","Save Result set: 4, item: 33\n","Save Result set: 5, item: 33\n","Save Result set: 6, item: 33\n","Save Result set: 7, item: 33\n","Save Result set: 8, item: 33\n","Save Result set: 9, item: 33\n","Save Result set: 0, item: 34\n","Save Result set: 1, item: 34\n","Save Result set: 2, item: 34\n","Save Result set: 3, item: 34\n","Save Result set: 4, item: 34\n","Save Result set: 5, item: 34\n","Save Result set: 6, item: 34\n","Save Result set: 7, item: 34\n","Save Result set: 8, item: 34\n","Save Result set: 9, item: 34\n","Save Result set: 0, item: 35\n","Save Result set: 1, item: 35\n","Save Result set: 2, item: 35\n","Save Result set: 3, item: 35\n","Save Result set: 4, item: 35\n","Save Result set: 5, item: 35\n","Save Result set: 6, item: 35\n","Save Result set: 7, item: 35\n","Save Result set: 8, item: 35\n","Save Result set: 9, item: 35\n","Save Result set: 0, item: 36\n","Save Result set: 1, item: 36\n","Save Result set: 2, item: 36\n","Save Result set: 3, item: 36\n","Save Result set: 4, item: 36\n","Save Result set: 5, item: 36\n","Save Result set: 6, item: 36\n","Save Result set: 7, item: 36\n","Save Result set: 8, item: 36\n","Save Result set: 9, item: 36\n"]}]},{"cell_type":"code","source":["for k in tqdm(range(10)):\n","\n","  globals()[f'set_df_{k}'] = pd.DataFrame()\n","  answer_df_list = glob(f'./set_{k}/*.csv') # 예측한 결과 불러오기\n","  pum_list = glob(f'./aT_test_raw/sep_{k}/*.csv') # 기존 test input 불러오기\n","  pummok = [a for a in pum_list if 'pummok' in a.split('/')[-1]]\n","\n","  for i in answer_df_list:\n","    df = pd.read_csv(i)\n","    number = i.split('_')[-1].split('.')[0]\n","\n","    base_number = 0\n","    for p in pummok:\n","      if number == p.split('_')[-1].split('.')[0]:\n","        pum_df = pd.read_csv(p)\n","\n","        if len(pum_df) != 0:\n","           base_number = pum_df.iloc[len(pum_df)-1]['해당일자_전체평균가격(원)']  # 기존 각 sep 마다 test input의 마지막 target 값 가져오기 (변동률 계산을 위해)\n","        else:\n","          base_number = np.nan\n","\n","    globals()[f'set_df_{k}'][f'품목{number}']  = [base_number] + list(df[df.columns[-1]].values) # 각 품목당 순서를 t, t+1 ... t+28 로 변경\n","\n","  globals()[f'set_df_{k}'] = globals()[f'set_df_{k}'][[f'품목{col}' for col in range(37)]] # 열 순서를 품목0 ~ 품목36 으로 변경"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vX7f-OTJ9kEG","executionInfo":{"status":"ok","timestamp":1662539167461,"user_tz":-540,"elapsed":40500,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"2ce331d9-e871-44a5-a8ec-a4a3cae355f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:39<00:00,  3.98s/it]\n"]}]},{"cell_type":"code","source":["set_df_0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"IWefVmRh9nK7","executionInfo":{"status":"ok","timestamp":1662539167461,"user_tz":-540,"elapsed":21,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"576bdb29-3be8-4325-e8bb-4b6078b1778b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            품목0          품목1          품목2          품목3          품목4  \\\n","0   3871.125000  1362.117613  2909.783785  3400.075583  3947.809169   \n","1     -0.098704    -0.208349    -0.030669    -0.179442    -0.033723   \n","2     -0.105068    -0.194260    -0.045841    -0.185040    -0.024620   \n","3     -0.104312    -0.213983    -0.040041    -0.202736    -0.032060   \n","4     -0.096159    -0.221220    -0.031434    -0.197726    -0.045425   \n","5     -0.079600    -0.219619    -0.034849    -0.211215    -0.031644   \n","6     -0.102885    -0.220557    -0.037263    -0.220034    -0.045295   \n","7     -0.102408    -0.215402    -0.043569    -0.236576    -0.060382   \n","8     -0.103783    -0.199212    -0.036895    -0.228485    -0.043003   \n","9     -0.111943    -0.220475    -0.048597    -0.236415    -0.050359   \n","10    -0.096188    -0.225603    -0.046933    -0.253028    -0.058231   \n","11    -0.109824    -0.281840    -0.045115    -0.251516    -0.056766   \n","12    -0.101277    -0.262624    -0.039010    -0.241673    -0.055687   \n","13    -0.104777    -0.249309    -0.036640    -0.265590    -0.050801   \n","14    -0.115491    -0.243046    -0.057140    -0.276707    -0.057057   \n","15    -0.119685    -0.227224    -0.036586    -0.259644    -0.048719   \n","16    -0.124844    -0.275940    -0.039353    -0.267972    -0.046164   \n","17    -0.132181    -0.304682    -0.042596    -0.282400    -0.054689   \n","18    -0.110446    -0.300136    -0.034865    -0.287832    -0.056432   \n","19    -0.127718    -0.289768    -0.046292    -0.267134    -0.057461   \n","20    -0.119673    -0.281101    -0.040661    -0.267261    -0.055002   \n","21    -0.113833    -0.269075    -0.061349    -0.285727    -0.067711   \n","22    -0.126029    -0.286500    -0.040521    -0.278753    -0.068819   \n","23    -0.117248    -0.300415    -0.054093    -0.274279    -0.068348   \n","24    -0.140635    -0.300278    -0.048302    -0.296293    -0.066663   \n","25    -0.110453    -0.282016    -0.055354    -0.276827    -0.083054   \n","26    -0.125791    -0.303951    -0.050639    -0.276663    -0.075359   \n","27    -0.120492    -0.300542    -0.041042    -0.266510    -0.071554   \n","28    -0.129528    -0.317873    -0.069120    -0.284368    -0.076656   \n","\n","            품목5          품목6          품목7          품목8          품목9  ...  \\\n","0   9253.947514  2717.280000  3361.030923  4911.899864  1173.018633  ...   \n","1     -0.088001    -0.095634    -0.036049    -0.127025     0.014201  ...   \n","2     -0.097661    -0.145952    -0.021373    -0.128772     0.011254  ...   \n","3     -0.093784    -0.110657    -0.045481    -0.128919     0.005640  ...   \n","4     -0.103915    -0.054150    -0.030704    -0.149009     0.010941  ...   \n","5     -0.106284    -0.107980    -0.039167    -0.129154     0.011154  ...   \n","6     -0.104895    -0.085439    -0.030747    -0.151296     0.013863  ...   \n","7     -0.107047    -0.120601    -0.015257    -0.131517     0.008270  ...   \n","8     -0.102455    -0.088212    -0.020756    -0.132866     0.017791  ...   \n","9     -0.117733    -0.129261    -0.023630    -0.135039     0.016688  ...   \n","10    -0.122889    -0.105953    -0.028393    -0.152137     0.016264  ...   \n","11    -0.144189    -0.087181    -0.038913    -0.155279     0.025486  ...   \n","12    -0.130277    -0.110334    -0.017087    -0.155447     0.019216  ...   \n","13    -0.135807    -0.142800    -0.016594    -0.157519     0.019211  ...   \n","14    -0.142229    -0.090080    -0.008220    -0.152489     0.028480  ...   \n","15    -0.145691    -0.137892    -0.006912    -0.121718     0.029971  ...   \n","16    -0.135663    -0.160472    -0.015979    -0.129380     0.026036  ...   \n","17    -0.164246    -0.103961     0.007141    -0.169946     0.029345  ...   \n","18    -0.151404    -0.166917    -0.003581    -0.160348     0.033655  ...   \n","19    -0.152301    -0.113702     0.018233    -0.170710     0.035104  ...   \n","20    -0.152583    -0.084905     0.001971    -0.159272     0.038874  ...   \n","21    -0.148350    -0.126282     0.004325    -0.130616     0.029720  ...   \n","22    -0.156860    -0.110404     0.000022    -0.144208     0.037018  ...   \n","23    -0.164231    -0.098012    -0.000622    -0.156900     0.036243  ...   \n","24    -0.169167    -0.073781    -0.011057    -0.175674     0.035219  ...   \n","25    -0.157676    -0.107026     0.012137    -0.167833     0.025535  ...   \n","26    -0.185679    -0.130104    -0.001493    -0.184260     0.034168  ...   \n","27    -0.165572    -0.091138     0.028640    -0.145511     0.038085  ...   \n","28    -0.165116    -0.113942    -0.001718    -0.168349     0.034021  ...   \n","\n","           품목27        품목28         품목29         품목30         품목31  \\\n","0   8640.811309  602.005658  1105.412623  1566.274239  3633.464557   \n","1     -0.171518   -0.092869    -0.123811     0.013422    -0.101043   \n","2     -0.171184   -0.102812    -0.146323     0.021701    -0.119364   \n","3     -0.187573   -0.111513    -0.176994     0.017166    -0.127064   \n","4     -0.178969   -0.089716    -0.153893     0.019843    -0.137207   \n","5     -0.191400   -0.096434    -0.155161     0.022190    -0.121410   \n","6     -0.185042   -0.085266    -0.170424     0.032275    -0.111476   \n","7     -0.201968   -0.097505    -0.165630     0.032205    -0.111614   \n","8     -0.190577   -0.108066    -0.159750     0.037268    -0.116338   \n","9     -0.196949   -0.112684    -0.162672     0.032753    -0.122265   \n","10    -0.215237   -0.120599    -0.174217     0.040363    -0.114491   \n","11    -0.200109   -0.106909    -0.174225     0.034976    -0.116006   \n","12    -0.199960   -0.117543    -0.187650     0.048451    -0.108090   \n","13    -0.215250   -0.119562    -0.175599     0.048000    -0.099339   \n","14    -0.214045   -0.113852    -0.199926     0.044449    -0.117245   \n","15    -0.209251   -0.131311    -0.182652     0.047543    -0.119347   \n","16    -0.236956   -0.120225    -0.182961     0.058915    -0.128594   \n","17    -0.232739   -0.122738    -0.199608     0.054743    -0.118746   \n","18    -0.236884   -0.128695    -0.203369     0.057875    -0.111313   \n","19    -0.218565   -0.115098    -0.197594     0.067467    -0.101696   \n","20    -0.246925   -0.127355    -0.198907     0.064805    -0.106127   \n","21    -0.237504   -0.124580    -0.210563     0.067578    -0.100844   \n","22    -0.251534   -0.126040    -0.200205     0.067189    -0.109352   \n","23    -0.244984   -0.141857    -0.196728     0.065671    -0.109988   \n","24    -0.251861   -0.129892    -0.207761     0.073205    -0.114607   \n","25    -0.244671   -0.143276    -0.227616     0.069516    -0.093092   \n","26    -0.242947   -0.140064    -0.215796     0.071643    -0.086533   \n","27    -0.240241   -0.132655    -0.217751     0.081187    -0.082066   \n","28    -0.234503   -0.144603    -0.245566     0.081976    -0.088849   \n","\n","           품목32         품목33         품목34         품목35         품목36  \n","0   5454.710444  5619.188362  5230.620027  2905.100888  2087.675036  \n","1      0.027667    -0.092294    -0.057289    -0.089267    -0.080421  \n","2      0.030727    -0.093349    -0.081633    -0.100971    -0.091578  \n","3      0.037848    -0.082695    -0.086575    -0.106187    -0.105724  \n","4      0.023684    -0.092194    -0.089181    -0.108863    -0.083952  \n","5      0.034709    -0.117058    -0.076427    -0.100425    -0.104697  \n","6      0.044160    -0.121155    -0.061194    -0.102796    -0.076243  \n","7      0.028726    -0.106227    -0.089874    -0.095072    -0.088554  \n","8      0.025974    -0.097460    -0.099172    -0.094013    -0.086691  \n","9      0.044189    -0.107037    -0.100952    -0.092463    -0.080775  \n","10     0.043867    -0.109139    -0.121421    -0.094051    -0.099563  \n","11     0.040327    -0.122081    -0.103223    -0.112633    -0.091986  \n","12     0.045066    -0.121220    -0.123699    -0.114155    -0.080079  \n","13     0.044687    -0.105072    -0.100505    -0.097612    -0.067559  \n","14     0.035938    -0.131891    -0.121433    -0.096780    -0.084395  \n","15     0.030256    -0.122889    -0.119765    -0.098838    -0.081105  \n","16     0.040690    -0.107880    -0.124211    -0.094596    -0.074010  \n","17     0.040493    -0.113503    -0.145222    -0.092678    -0.086152  \n","18     0.024581    -0.118799    -0.157566    -0.099798    -0.066507  \n","19     0.043817    -0.114569    -0.154215    -0.104258    -0.067671  \n","20     0.051138    -0.116683    -0.154383    -0.110406    -0.063234  \n","21     0.034406    -0.140105    -0.156613    -0.105721    -0.079133  \n","22     0.024703    -0.120640    -0.180079    -0.110357    -0.101861  \n","23     0.043705    -0.108921    -0.188006    -0.107999    -0.094394  \n","24     0.046034    -0.124683    -0.207086    -0.113992    -0.100805  \n","25     0.031643    -0.138475    -0.214667    -0.112974    -0.083538  \n","26     0.037618    -0.128923    -0.210197    -0.126415    -0.104372  \n","27     0.040074    -0.131733    -0.209488    -0.118706    -0.109532  \n","28     0.032879    -0.136936    -0.221848    -0.125647    -0.127332  \n","\n","[29 rows x 37 columns]"],"text/html":["\n","  <div id=\"df-56d0a9b3-8ec9-4a71-aa5e-2db808db75b3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>품목0</th>\n","      <th>품목1</th>\n","      <th>품목2</th>\n","      <th>품목3</th>\n","      <th>품목4</th>\n","      <th>품목5</th>\n","      <th>품목6</th>\n","      <th>품목7</th>\n","      <th>품목8</th>\n","      <th>품목9</th>\n","      <th>...</th>\n","      <th>품목27</th>\n","      <th>품목28</th>\n","      <th>품목29</th>\n","      <th>품목30</th>\n","      <th>품목31</th>\n","      <th>품목32</th>\n","      <th>품목33</th>\n","      <th>품목34</th>\n","      <th>품목35</th>\n","      <th>품목36</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3871.125000</td>\n","      <td>1362.117613</td>\n","      <td>2909.783785</td>\n","      <td>3400.075583</td>\n","      <td>3947.809169</td>\n","      <td>9253.947514</td>\n","      <td>2717.280000</td>\n","      <td>3361.030923</td>\n","      <td>4911.899864</td>\n","      <td>1173.018633</td>\n","      <td>...</td>\n","      <td>8640.811309</td>\n","      <td>602.005658</td>\n","      <td>1105.412623</td>\n","      <td>1566.274239</td>\n","      <td>3633.464557</td>\n","      <td>5454.710444</td>\n","      <td>5619.188362</td>\n","      <td>5230.620027</td>\n","      <td>2905.100888</td>\n","      <td>2087.675036</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.098704</td>\n","      <td>-0.208349</td>\n","      <td>-0.030669</td>\n","      <td>-0.179442</td>\n","      <td>-0.033723</td>\n","      <td>-0.088001</td>\n","      <td>-0.095634</td>\n","      <td>-0.036049</td>\n","      <td>-0.127025</td>\n","      <td>0.014201</td>\n","      <td>...</td>\n","      <td>-0.171518</td>\n","      <td>-0.092869</td>\n","      <td>-0.123811</td>\n","      <td>0.013422</td>\n","      <td>-0.101043</td>\n","      <td>0.027667</td>\n","      <td>-0.092294</td>\n","      <td>-0.057289</td>\n","      <td>-0.089267</td>\n","      <td>-0.080421</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.105068</td>\n","      <td>-0.194260</td>\n","      <td>-0.045841</td>\n","      <td>-0.185040</td>\n","      <td>-0.024620</td>\n","      <td>-0.097661</td>\n","      <td>-0.145952</td>\n","      <td>-0.021373</td>\n","      <td>-0.128772</td>\n","      <td>0.011254</td>\n","      <td>...</td>\n","      <td>-0.171184</td>\n","      <td>-0.102812</td>\n","      <td>-0.146323</td>\n","      <td>0.021701</td>\n","      <td>-0.119364</td>\n","      <td>0.030727</td>\n","      <td>-0.093349</td>\n","      <td>-0.081633</td>\n","      <td>-0.100971</td>\n","      <td>-0.091578</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.104312</td>\n","      <td>-0.213983</td>\n","      <td>-0.040041</td>\n","      <td>-0.202736</td>\n","      <td>-0.032060</td>\n","      <td>-0.093784</td>\n","      <td>-0.110657</td>\n","      <td>-0.045481</td>\n","      <td>-0.128919</td>\n","      <td>0.005640</td>\n","      <td>...</td>\n","      <td>-0.187573</td>\n","      <td>-0.111513</td>\n","      <td>-0.176994</td>\n","      <td>0.017166</td>\n","      <td>-0.127064</td>\n","      <td>0.037848</td>\n","      <td>-0.082695</td>\n","      <td>-0.086575</td>\n","      <td>-0.106187</td>\n","      <td>-0.105724</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.096159</td>\n","      <td>-0.221220</td>\n","      <td>-0.031434</td>\n","      <td>-0.197726</td>\n","      <td>-0.045425</td>\n","      <td>-0.103915</td>\n","      <td>-0.054150</td>\n","      <td>-0.030704</td>\n","      <td>-0.149009</td>\n","      <td>0.010941</td>\n","      <td>...</td>\n","      <td>-0.178969</td>\n","      <td>-0.089716</td>\n","      <td>-0.153893</td>\n","      <td>0.019843</td>\n","      <td>-0.137207</td>\n","      <td>0.023684</td>\n","      <td>-0.092194</td>\n","      <td>-0.089181</td>\n","      <td>-0.108863</td>\n","      <td>-0.083952</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>-0.079600</td>\n","      <td>-0.219619</td>\n","      <td>-0.034849</td>\n","      <td>-0.211215</td>\n","      <td>-0.031644</td>\n","      <td>-0.106284</td>\n","      <td>-0.107980</td>\n","      <td>-0.039167</td>\n","      <td>-0.129154</td>\n","      <td>0.011154</td>\n","      <td>...</td>\n","      <td>-0.191400</td>\n","      <td>-0.096434</td>\n","      <td>-0.155161</td>\n","      <td>0.022190</td>\n","      <td>-0.121410</td>\n","      <td>0.034709</td>\n","      <td>-0.117058</td>\n","      <td>-0.076427</td>\n","      <td>-0.100425</td>\n","      <td>-0.104697</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>-0.102885</td>\n","      <td>-0.220557</td>\n","      <td>-0.037263</td>\n","      <td>-0.220034</td>\n","      <td>-0.045295</td>\n","      <td>-0.104895</td>\n","      <td>-0.085439</td>\n","      <td>-0.030747</td>\n","      <td>-0.151296</td>\n","      <td>0.013863</td>\n","      <td>...</td>\n","      <td>-0.185042</td>\n","      <td>-0.085266</td>\n","      <td>-0.170424</td>\n","      <td>0.032275</td>\n","      <td>-0.111476</td>\n","      <td>0.044160</td>\n","      <td>-0.121155</td>\n","      <td>-0.061194</td>\n","      <td>-0.102796</td>\n","      <td>-0.076243</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>-0.102408</td>\n","      <td>-0.215402</td>\n","      <td>-0.043569</td>\n","      <td>-0.236576</td>\n","      <td>-0.060382</td>\n","      <td>-0.107047</td>\n","      <td>-0.120601</td>\n","      <td>-0.015257</td>\n","      <td>-0.131517</td>\n","      <td>0.008270</td>\n","      <td>...</td>\n","      <td>-0.201968</td>\n","      <td>-0.097505</td>\n","      <td>-0.165630</td>\n","      <td>0.032205</td>\n","      <td>-0.111614</td>\n","      <td>0.028726</td>\n","      <td>-0.106227</td>\n","      <td>-0.089874</td>\n","      <td>-0.095072</td>\n","      <td>-0.088554</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>-0.103783</td>\n","      <td>-0.199212</td>\n","      <td>-0.036895</td>\n","      <td>-0.228485</td>\n","      <td>-0.043003</td>\n","      <td>-0.102455</td>\n","      <td>-0.088212</td>\n","      <td>-0.020756</td>\n","      <td>-0.132866</td>\n","      <td>0.017791</td>\n","      <td>...</td>\n","      <td>-0.190577</td>\n","      <td>-0.108066</td>\n","      <td>-0.159750</td>\n","      <td>0.037268</td>\n","      <td>-0.116338</td>\n","      <td>0.025974</td>\n","      <td>-0.097460</td>\n","      <td>-0.099172</td>\n","      <td>-0.094013</td>\n","      <td>-0.086691</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>-0.111943</td>\n","      <td>-0.220475</td>\n","      <td>-0.048597</td>\n","      <td>-0.236415</td>\n","      <td>-0.050359</td>\n","      <td>-0.117733</td>\n","      <td>-0.129261</td>\n","      <td>-0.023630</td>\n","      <td>-0.135039</td>\n","      <td>0.016688</td>\n","      <td>...</td>\n","      <td>-0.196949</td>\n","      <td>-0.112684</td>\n","      <td>-0.162672</td>\n","      <td>0.032753</td>\n","      <td>-0.122265</td>\n","      <td>0.044189</td>\n","      <td>-0.107037</td>\n","      <td>-0.100952</td>\n","      <td>-0.092463</td>\n","      <td>-0.080775</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>-0.096188</td>\n","      <td>-0.225603</td>\n","      <td>-0.046933</td>\n","      <td>-0.253028</td>\n","      <td>-0.058231</td>\n","      <td>-0.122889</td>\n","      <td>-0.105953</td>\n","      <td>-0.028393</td>\n","      <td>-0.152137</td>\n","      <td>0.016264</td>\n","      <td>...</td>\n","      <td>-0.215237</td>\n","      <td>-0.120599</td>\n","      <td>-0.174217</td>\n","      <td>0.040363</td>\n","      <td>-0.114491</td>\n","      <td>0.043867</td>\n","      <td>-0.109139</td>\n","      <td>-0.121421</td>\n","      <td>-0.094051</td>\n","      <td>-0.099563</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>-0.109824</td>\n","      <td>-0.281840</td>\n","      <td>-0.045115</td>\n","      <td>-0.251516</td>\n","      <td>-0.056766</td>\n","      <td>-0.144189</td>\n","      <td>-0.087181</td>\n","      <td>-0.038913</td>\n","      <td>-0.155279</td>\n","      <td>0.025486</td>\n","      <td>...</td>\n","      <td>-0.200109</td>\n","      <td>-0.106909</td>\n","      <td>-0.174225</td>\n","      <td>0.034976</td>\n","      <td>-0.116006</td>\n","      <td>0.040327</td>\n","      <td>-0.122081</td>\n","      <td>-0.103223</td>\n","      <td>-0.112633</td>\n","      <td>-0.091986</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>-0.101277</td>\n","      <td>-0.262624</td>\n","      <td>-0.039010</td>\n","      <td>-0.241673</td>\n","      <td>-0.055687</td>\n","      <td>-0.130277</td>\n","      <td>-0.110334</td>\n","      <td>-0.017087</td>\n","      <td>-0.155447</td>\n","      <td>0.019216</td>\n","      <td>...</td>\n","      <td>-0.199960</td>\n","      <td>-0.117543</td>\n","      <td>-0.187650</td>\n","      <td>0.048451</td>\n","      <td>-0.108090</td>\n","      <td>0.045066</td>\n","      <td>-0.121220</td>\n","      <td>-0.123699</td>\n","      <td>-0.114155</td>\n","      <td>-0.080079</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>-0.104777</td>\n","      <td>-0.249309</td>\n","      <td>-0.036640</td>\n","      <td>-0.265590</td>\n","      <td>-0.050801</td>\n","      <td>-0.135807</td>\n","      <td>-0.142800</td>\n","      <td>-0.016594</td>\n","      <td>-0.157519</td>\n","      <td>0.019211</td>\n","      <td>...</td>\n","      <td>-0.215250</td>\n","      <td>-0.119562</td>\n","      <td>-0.175599</td>\n","      <td>0.048000</td>\n","      <td>-0.099339</td>\n","      <td>0.044687</td>\n","      <td>-0.105072</td>\n","      <td>-0.100505</td>\n","      <td>-0.097612</td>\n","      <td>-0.067559</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>-0.115491</td>\n","      <td>-0.243046</td>\n","      <td>-0.057140</td>\n","      <td>-0.276707</td>\n","      <td>-0.057057</td>\n","      <td>-0.142229</td>\n","      <td>-0.090080</td>\n","      <td>-0.008220</td>\n","      <td>-0.152489</td>\n","      <td>0.028480</td>\n","      <td>...</td>\n","      <td>-0.214045</td>\n","      <td>-0.113852</td>\n","      <td>-0.199926</td>\n","      <td>0.044449</td>\n","      <td>-0.117245</td>\n","      <td>0.035938</td>\n","      <td>-0.131891</td>\n","      <td>-0.121433</td>\n","      <td>-0.096780</td>\n","      <td>-0.084395</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>-0.119685</td>\n","      <td>-0.227224</td>\n","      <td>-0.036586</td>\n","      <td>-0.259644</td>\n","      <td>-0.048719</td>\n","      <td>-0.145691</td>\n","      <td>-0.137892</td>\n","      <td>-0.006912</td>\n","      <td>-0.121718</td>\n","      <td>0.029971</td>\n","      <td>...</td>\n","      <td>-0.209251</td>\n","      <td>-0.131311</td>\n","      <td>-0.182652</td>\n","      <td>0.047543</td>\n","      <td>-0.119347</td>\n","      <td>0.030256</td>\n","      <td>-0.122889</td>\n","      <td>-0.119765</td>\n","      <td>-0.098838</td>\n","      <td>-0.081105</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>-0.124844</td>\n","      <td>-0.275940</td>\n","      <td>-0.039353</td>\n","      <td>-0.267972</td>\n","      <td>-0.046164</td>\n","      <td>-0.135663</td>\n","      <td>-0.160472</td>\n","      <td>-0.015979</td>\n","      <td>-0.129380</td>\n","      <td>0.026036</td>\n","      <td>...</td>\n","      <td>-0.236956</td>\n","      <td>-0.120225</td>\n","      <td>-0.182961</td>\n","      <td>0.058915</td>\n","      <td>-0.128594</td>\n","      <td>0.040690</td>\n","      <td>-0.107880</td>\n","      <td>-0.124211</td>\n","      <td>-0.094596</td>\n","      <td>-0.074010</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>-0.132181</td>\n","      <td>-0.304682</td>\n","      <td>-0.042596</td>\n","      <td>-0.282400</td>\n","      <td>-0.054689</td>\n","      <td>-0.164246</td>\n","      <td>-0.103961</td>\n","      <td>0.007141</td>\n","      <td>-0.169946</td>\n","      <td>0.029345</td>\n","      <td>...</td>\n","      <td>-0.232739</td>\n","      <td>-0.122738</td>\n","      <td>-0.199608</td>\n","      <td>0.054743</td>\n","      <td>-0.118746</td>\n","      <td>0.040493</td>\n","      <td>-0.113503</td>\n","      <td>-0.145222</td>\n","      <td>-0.092678</td>\n","      <td>-0.086152</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>-0.110446</td>\n","      <td>-0.300136</td>\n","      <td>-0.034865</td>\n","      <td>-0.287832</td>\n","      <td>-0.056432</td>\n","      <td>-0.151404</td>\n","      <td>-0.166917</td>\n","      <td>-0.003581</td>\n","      <td>-0.160348</td>\n","      <td>0.033655</td>\n","      <td>...</td>\n","      <td>-0.236884</td>\n","      <td>-0.128695</td>\n","      <td>-0.203369</td>\n","      <td>0.057875</td>\n","      <td>-0.111313</td>\n","      <td>0.024581</td>\n","      <td>-0.118799</td>\n","      <td>-0.157566</td>\n","      <td>-0.099798</td>\n","      <td>-0.066507</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>-0.127718</td>\n","      <td>-0.289768</td>\n","      <td>-0.046292</td>\n","      <td>-0.267134</td>\n","      <td>-0.057461</td>\n","      <td>-0.152301</td>\n","      <td>-0.113702</td>\n","      <td>0.018233</td>\n","      <td>-0.170710</td>\n","      <td>0.035104</td>\n","      <td>...</td>\n","      <td>-0.218565</td>\n","      <td>-0.115098</td>\n","      <td>-0.197594</td>\n","      <td>0.067467</td>\n","      <td>-0.101696</td>\n","      <td>0.043817</td>\n","      <td>-0.114569</td>\n","      <td>-0.154215</td>\n","      <td>-0.104258</td>\n","      <td>-0.067671</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>-0.119673</td>\n","      <td>-0.281101</td>\n","      <td>-0.040661</td>\n","      <td>-0.267261</td>\n","      <td>-0.055002</td>\n","      <td>-0.152583</td>\n","      <td>-0.084905</td>\n","      <td>0.001971</td>\n","      <td>-0.159272</td>\n","      <td>0.038874</td>\n","      <td>...</td>\n","      <td>-0.246925</td>\n","      <td>-0.127355</td>\n","      <td>-0.198907</td>\n","      <td>0.064805</td>\n","      <td>-0.106127</td>\n","      <td>0.051138</td>\n","      <td>-0.116683</td>\n","      <td>-0.154383</td>\n","      <td>-0.110406</td>\n","      <td>-0.063234</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>-0.113833</td>\n","      <td>-0.269075</td>\n","      <td>-0.061349</td>\n","      <td>-0.285727</td>\n","      <td>-0.067711</td>\n","      <td>-0.148350</td>\n","      <td>-0.126282</td>\n","      <td>0.004325</td>\n","      <td>-0.130616</td>\n","      <td>0.029720</td>\n","      <td>...</td>\n","      <td>-0.237504</td>\n","      <td>-0.124580</td>\n","      <td>-0.210563</td>\n","      <td>0.067578</td>\n","      <td>-0.100844</td>\n","      <td>0.034406</td>\n","      <td>-0.140105</td>\n","      <td>-0.156613</td>\n","      <td>-0.105721</td>\n","      <td>-0.079133</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>-0.126029</td>\n","      <td>-0.286500</td>\n","      <td>-0.040521</td>\n","      <td>-0.278753</td>\n","      <td>-0.068819</td>\n","      <td>-0.156860</td>\n","      <td>-0.110404</td>\n","      <td>0.000022</td>\n","      <td>-0.144208</td>\n","      <td>0.037018</td>\n","      <td>...</td>\n","      <td>-0.251534</td>\n","      <td>-0.126040</td>\n","      <td>-0.200205</td>\n","      <td>0.067189</td>\n","      <td>-0.109352</td>\n","      <td>0.024703</td>\n","      <td>-0.120640</td>\n","      <td>-0.180079</td>\n","      <td>-0.110357</td>\n","      <td>-0.101861</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>-0.117248</td>\n","      <td>-0.300415</td>\n","      <td>-0.054093</td>\n","      <td>-0.274279</td>\n","      <td>-0.068348</td>\n","      <td>-0.164231</td>\n","      <td>-0.098012</td>\n","      <td>-0.000622</td>\n","      <td>-0.156900</td>\n","      <td>0.036243</td>\n","      <td>...</td>\n","      <td>-0.244984</td>\n","      <td>-0.141857</td>\n","      <td>-0.196728</td>\n","      <td>0.065671</td>\n","      <td>-0.109988</td>\n","      <td>0.043705</td>\n","      <td>-0.108921</td>\n","      <td>-0.188006</td>\n","      <td>-0.107999</td>\n","      <td>-0.094394</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>-0.140635</td>\n","      <td>-0.300278</td>\n","      <td>-0.048302</td>\n","      <td>-0.296293</td>\n","      <td>-0.066663</td>\n","      <td>-0.169167</td>\n","      <td>-0.073781</td>\n","      <td>-0.011057</td>\n","      <td>-0.175674</td>\n","      <td>0.035219</td>\n","      <td>...</td>\n","      <td>-0.251861</td>\n","      <td>-0.129892</td>\n","      <td>-0.207761</td>\n","      <td>0.073205</td>\n","      <td>-0.114607</td>\n","      <td>0.046034</td>\n","      <td>-0.124683</td>\n","      <td>-0.207086</td>\n","      <td>-0.113992</td>\n","      <td>-0.100805</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>-0.110453</td>\n","      <td>-0.282016</td>\n","      <td>-0.055354</td>\n","      <td>-0.276827</td>\n","      <td>-0.083054</td>\n","      <td>-0.157676</td>\n","      <td>-0.107026</td>\n","      <td>0.012137</td>\n","      <td>-0.167833</td>\n","      <td>0.025535</td>\n","      <td>...</td>\n","      <td>-0.244671</td>\n","      <td>-0.143276</td>\n","      <td>-0.227616</td>\n","      <td>0.069516</td>\n","      <td>-0.093092</td>\n","      <td>0.031643</td>\n","      <td>-0.138475</td>\n","      <td>-0.214667</td>\n","      <td>-0.112974</td>\n","      <td>-0.083538</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>-0.125791</td>\n","      <td>-0.303951</td>\n","      <td>-0.050639</td>\n","      <td>-0.276663</td>\n","      <td>-0.075359</td>\n","      <td>-0.185679</td>\n","      <td>-0.130104</td>\n","      <td>-0.001493</td>\n","      <td>-0.184260</td>\n","      <td>0.034168</td>\n","      <td>...</td>\n","      <td>-0.242947</td>\n","      <td>-0.140064</td>\n","      <td>-0.215796</td>\n","      <td>0.071643</td>\n","      <td>-0.086533</td>\n","      <td>0.037618</td>\n","      <td>-0.128923</td>\n","      <td>-0.210197</td>\n","      <td>-0.126415</td>\n","      <td>-0.104372</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>-0.120492</td>\n","      <td>-0.300542</td>\n","      <td>-0.041042</td>\n","      <td>-0.266510</td>\n","      <td>-0.071554</td>\n","      <td>-0.165572</td>\n","      <td>-0.091138</td>\n","      <td>0.028640</td>\n","      <td>-0.145511</td>\n","      <td>0.038085</td>\n","      <td>...</td>\n","      <td>-0.240241</td>\n","      <td>-0.132655</td>\n","      <td>-0.217751</td>\n","      <td>0.081187</td>\n","      <td>-0.082066</td>\n","      <td>0.040074</td>\n","      <td>-0.131733</td>\n","      <td>-0.209488</td>\n","      <td>-0.118706</td>\n","      <td>-0.109532</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>-0.129528</td>\n","      <td>-0.317873</td>\n","      <td>-0.069120</td>\n","      <td>-0.284368</td>\n","      <td>-0.076656</td>\n","      <td>-0.165116</td>\n","      <td>-0.113942</td>\n","      <td>-0.001718</td>\n","      <td>-0.168349</td>\n","      <td>0.034021</td>\n","      <td>...</td>\n","      <td>-0.234503</td>\n","      <td>-0.144603</td>\n","      <td>-0.245566</td>\n","      <td>0.081976</td>\n","      <td>-0.088849</td>\n","      <td>0.032879</td>\n","      <td>-0.136936</td>\n","      <td>-0.221848</td>\n","      <td>-0.125647</td>\n","      <td>-0.127332</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>29 rows × 37 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56d0a9b3-8ec9-4a71-aa5e-2db808db75b3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-56d0a9b3-8ec9-4a71-aa5e-2db808db75b3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-56d0a9b3-8ec9-4a71-aa5e-2db808db75b3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["date = [f'd+{i}' for i in range(1,15)] + ['d+22 ~ 28 평균']\n","\n","\n","for k in range(10):\n","  globals()[f'answer_df_{k}'] = pd.DataFrame()\n","  for c in globals()[f'set_df_{k}'].columns:\n","    base_d = globals()[f'set_df_{k}'][c][0] # 변동률 기준 t 값\n","\n","    ans_1_14 = []\n","    for i in range(14):\n","      ans_1_14.append((globals()[f'set_df_{k}'][c].iloc[i+1]- base_d)/base_d)  # t+1 ~ t+14 까지는 (t+n - t)/t 로 계산\n","\n","    ans_22_28 = (globals()[f'set_df_{k}'][c][22:29].mean() - base_d)/base_d # t+22 ~ t+28은 np.mean(t+22 ~ t+28) - t / t\n","\n","    globals()[f'answer_df_{k}'][f'{c} 변동률'] = ans_1_14 + [ans_22_28]\n","  \n","  globals()[f'answer_df_{k}']['Set'] = k # set 번호 설정\n","  globals()[f'answer_df_{k}']['일자'] = date # 일자 설정\n","\n","# 위에서 계산된 변동률 들을 합쳐주는 과정\n","\n","all_df =pd.DataFrame()\n","for i in range(10):\n","  if i== 0 :\n","    all_df = pd.concat([all_df, globals()[f'answer_df_{i}']],axis=1)\n","  else:\n","    all_df = pd.concat([all_df, globals()[f'answer_df_{i}']])\n","\n","\n","all_df = all_df[['Set','일자'] + list(all_df.columns[:-2])]\n","all_df.reset_index(drop=True, inplace=True)\n","\n","# set, 일자 기억하기위해 따로 저장\n","\n","re_set = list(all_df['Set'])\n","re_date = list(all_df['일자'])\n","\n","\n","# 정답 양식 불러오기\n","out_ans = pd.read_csv('./answer_example.csv')\n","\n","# 두 dataframe 합치기 (nan + 숫자 = nan 이용)\n","submit_df = all_df + out_ans\n","\n","submit_df['Set'] = re_set\n","submit_df['일자'] = re_date\n","\n","\n","# 최종 저장\n","submit_df.to_csv('./submit.csv',index=False)"],"metadata":{"id":"k41EdGDO9pEL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lB49MrUYDoj6"},"execution_count":null,"outputs":[]}]}