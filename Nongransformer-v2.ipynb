{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1aeZSfvnex26Myxi-pItZiUYScP6z7AOF","authorship_tag":"ABX9TyNz/yp1+AS0SAmPbbRCiwki"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PcNSr-6D2lf","executionInfo":{"status":"ok","timestamp":1662202934114,"user_tz":-540,"elapsed":25,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"88e84ca1-795f-4a1e-a211-1df30f5b94f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data/aT\n"]}],"source":["%cd drive/MyDrive/data/aT"]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VatHB75VW9d","executionInfo":{"status":"ok","timestamp":1662202934114,"user_tz":-540,"elapsed":21,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"6c86e393-9840-4eea-891a-b5774ed44056"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/       \u001b[01;34mscaled_data\u001b[0m/   weights_1.pth  weights_3.pth  weights_5.pth\n","result.csv  weights_0.pth  weights_2.pth  weights_4.pth  weights_6.pth\n"]}]},{"cell_type":"markdown","source":["# Import"],"metadata":{"id":"lVEyF7bNEL2Q"}},{"cell_type":"code","source":["import torch\n","from torch import nn, Tensor\n","import torch.optim as optim\n","import torch.optim.lr_scheduler as lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","\n","import os\n","import math\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","\n","np.random.seed(seed=2020320120)\n","torch.random.manual_seed(seed=2020320120)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YiRLFQ5wEJod","executionInfo":{"status":"ok","timestamp":1662202937171,"user_tz":-540,"elapsed":3073,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"a68daf44-4532-4fcb-a096-c4130ed0eff9"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f0fb2856db0>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# Dataset\n","데이터셋을 만들 때 고려해야 할 조건\n","* train, val, test를 어떻게 구분할 것인가? -> 먼저, split 인자를 통해 (train, val), test를 구분한다.\n","* 특히 train, val을 어떻게 구분할 것인가? -> phase 인자를 통해 train, val을 구분한다.\n","* 품목에 따라 데이터셋을 만들 것인가? -> use_all_items 인자와 item_idx 인자를 통해 모든 품목을 사용할 것인지, 하나의 품목만 사용할 것인지, 하나의 품목만 사용할 것이라면 사용할 품목의 인덱스는 무엇인지 설정한다.\n","* scaled_data를 사용한다."],"metadata":{"id":"6ffo1f4bEYJN"}},{"cell_type":"code","source":["def create_time_window(df, t, t_sep):\n","    seq_len = t\n","    seqence_length = seq_len + t_sep\n","\n","    result = []\n","    for index in range(len(df) - seqence_length):\n","        result.append(df[index: index + seqence_length].values)\n","\n","    return np.array(result)"],"metadata":{"id":"fm2B_GsnEVrP","executionInfo":{"status":"ok","timestamp":1662202937172,"user_tz":-540,"elapsed":8,"user":{"displayName":"김성찬","userId":"03517507033102912155"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class NongDataset(Dataset):\n","    def __init__(self, split, use_all_items=True, item_idx=None):\n","        super().__init__()\n","\n","        self.split = split # 'train' 또는 'test'; 'train'인 경우 self.phase 인자 필요\n","        self.use_all_items = use_all_items # 모든 품목 사용 여부\n","        self.item_idx = item_idx # 모든 품목을 사용하지 않을 경우, 사용할 품목 인덱스\n","        \n","        if self.split == 'train':\n","            self.init_train(use_all_items, item_idx)\n","        elif self.split == 'test':\n","            self.init_test(use_all_items, item_idx)\n","        else:\n","            raise ValueError()\n","    \n","    def init_train(self, use_all_items, item_idx):\n","        # 'train'인 경우, self.phase 인자 필요; 'train' or 'val'\n","        self.phase = 'train'\n","\n","        # file name list; \"train_0.csv\"\n","        self.file_name_list = os.listdir('./scaled_data/train')\n","\n","        # file path list; \"./scaled_data/train/train_0.csv\"\n","        if use_all_items: # 모든 품목을 사용하는 경우\n","            self.file_path_list = [f'./scaled_data/train/{file}' for file in self.file_name_list]\n","        else: # 한 가지 품목만 사용하는 경우\n","            for file_name in self.file_name_list:\n","                # 파일 품목 인덱스\n","                file_item_idx = int(file_name.split('_')[-1].split('.')[0])\n","\n","                if file_item_idx == item_idx: # 사용할 품목 인덱스와 파일 품목 인덱스 동일\n","                    self.file_path_list = [f'./scaled_data/train/{file_name}']\n","\n","        # 학습 데이터에서 사용하지 않을 열\n","        train_del_column_list = ['단가(원)', '거래량', '거래대금(원)', '경매건수', '도매시장코드', '도매법인코드', '산지코드 ']\n","\n","        # Dataset\n","        self.dataset = {\n","            'train': {\n","                'inputs': [],\n","                'labels': [],\n","            },\n","            'val': {\n","                'inputs': [],\n","                'labels': [],\n","            },\n","        }\n","\n","        for file_path in self.file_path_list:\n","            # 판다스로 csv 파일 읽기\n","            data = pd.read_csv(file_path)\n","\n","            # ' '을 np.nan으로 바꾸기\n","            for column in data.columns:\n","                data[column] = data[column].replace({' ': np.nan})\n","            \n","            # 학습 데이터에서 사용하지 않을 열 제거\n","            data.drop(train_del_column_list, axis=1, inplace=True)\n","            data.set_index('datadate', drop=True, inplace=True)\n","\n","            # nan 값은 0으로 채우기\n","            data = data.fillna(0)\n","\n","            # inputs와 labels 구분하기\n","            x, y = data[[i for i in data.columns if i != '해당일자_전체평균가격(원)']], data['해당일자_전체평균가격(원)']\n","\n","            y = y[14:]\n","\n","            # time window 만들기\n","            data_x = create_time_window(x, 13, 1) # 입력은 14일\n","            data_y = create_time_window(y, 27, 1) # 출력은 28일\n","\n","            xdata = data_x[:len(data_y)]\n","            ydata = data_y\n","\n","            x_train, x_val, y_train, y_val = train_test_split(xdata, ydata, test_size=0.2, shuffle=False, random_state=119)\n","\n","            self.dataset['train']['inputs'].append(x_train)\n","            self.dataset['train']['labels'].append(y_train)\n","            self.dataset['val']['inputs'].append(x_val)\n","            self.dataset['val']['labels'].append(y_val)\n","        \n","        self.dataset['train']['inputs'] = torch.tensor(np.concatenate(self.dataset['train']['inputs'], axis=0, dtype=np.float32))\n","        self.dataset['train']['labels'] = torch.tensor(np.concatenate(self.dataset['train']['labels'], axis=0, dtype=np.float32))\n","        self.dataset['val']['inputs'] = torch.tensor(np.concatenate(self.dataset['val']['inputs'], axis=0, dtype=np.float32))\n","        self.dataset['val']['labels'] = torch.tensor(np.concatenate(self.dataset['val']['labels'], axis=0, dtype=np.float32))\n","\n","        print(self.dataset['train']['inputs'].shape)\n","        print(self.dataset['train']['labels'].shape)\n","        print(self.dataset['val']['inputs'].shape)\n","        print(self.dataset['val']['labels'].shape)\n","\n","    def set_phase(self, phase):\n","        self.phase = phase\n","\n","    def init_test(self, use_all_items, item_idx):\n","        # file path list; \"./scaled_data/test/set_0/test_0.csv\"\n","        self.file_path_list = []\n","\n","        # for dir_name in os.listdir(f'./scaled_data/test'):\n","        #     for file_name in os.listdir(f'./scaled_data/test/{dir_name}'):\n","        #         file_path = f'./scaled_data/test/{dir_name}/{file_name}'\n","\n","        #         if use_all_items: # 모든 품목을 사용하는 경우\n","        #             self.file_path_list.append(file_path)\n","        #         else: # 한 가지 품목만 사용하는 경우\n","        #             # 파일 품목 인덱스\n","        #             file_item_idx = int(file_name.split('_')[-1].split('.')[0])\n","\n","        #             if file_item_idx == item_idx: # 인덱스 일치\n","        #                 self.file_path_list.append(file_path)\n","\n","        for i in range(10):\n","            for j in range(37):\n","                file_path = f'./scaled_data/test/set_{i}/test_{j}.csv'\n","\n","                if use_all_items:\n","                    self.file_path_list.append(file_path)\n","                else:\n","                    if j == item_idx:\n","                        self.file_path_list.append(file_path)\n","\n","        # 테스트에서 사용하지 않을 열\n","        test_del_column_list = ['단가(원)', '거래량', '거래대금(원)', '경매건수', '도매시장코드', '도매법인코드', '산지코드 ', '해당일자_전체평균가격(원)']\n","\n","        check_col = ['일자구분_중순', '일자구분_초순', '일자구분_하순','월구분_10월', '월구분_11월', '월구분_12월', '월구분_1월', '월구분_2월', '월구분_3월', \n","             '월구분_4월','월구분_5월', '월구분_6월', '월구분_7월', '월구분_8월', '월구분_9월']\n","\n","        zero_csv = [0 for i in range(14)]\n","\n","        # Dataset\n","        self.dataset = []\n","\n","        for idx, file_path in enumerate(self.file_path_list):\n","            # 판다스로 csv 파일 읽기\n","            data = pd.read_csv(file_path)\n","\n","            # \n","            if len(data) == 0:\n","                data['zero_non'] = zero_csv\n","                data = data.fillna(0)\n","                data.drop('zero_non', axis=1, inplace=True)\n","            \n","            file_number = file_path.split('/')[-1].split('_')[-1].split('.')[0]\n","\n","            data.drop(test_del_column_list, axis=1, inplace=True)\n","            data.set_index('datadate', drop=True, inplace=True)\n","            \n","            add_col = [i for i in check_col if i not in data.columns]\n","\n","            for a in add_col:\n","                data[a] = 0\n","\n","            for a in data.columns:\n","                data[a] = data[a].replace({' ': np.nan})\n","            \n","            data = data.fillna(0)\n","\n","            x_test = np.array(data, dtype=np.float32)\n","\n","            x_test = x_test.reshape(1, x_test.shape[0], x_test.shape[1])\n","\n","            if x_test.shape == (1, 14, 50):\n","                x_test = x_test[:, :, :49]\n","\n","            self.dataset.append(x_test)\n","\n","        self.dataset = torch.tensor(np.concatenate(self.dataset, axis=0, dtype=np.float32))\n","\n","        print(self.dataset.shape)\n","\n","    def __getitem__(self, idx):\n","        if self.split == 'train':\n","            return self.dataset[self.phase]['inputs'][idx], self.dataset[self.phase]['labels'][idx]\n","        elif self.split == 'test':\n","            return self.dataset[idx]\n","    \n","    def __len__(self):\n","        if isinstance(self.dataset, dict):\n","            return len(self.dataset[self.phase]['inputs'])\n","        else:\n","            return len(self.dataset)"],"metadata":{"id":"Z-cfBXYvF56P","executionInfo":{"status":"ok","timestamp":1662202937172,"user_tz":-540,"elapsed":8,"user":{"displayName":"김성찬","userId":"03517507033102912155"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Network"],"metadata":{"id":"pRKtPuC43fHa"}},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Args:\n","            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n","        \"\"\"\n","        x = x + self.pe[:x.size(0)]\n","        return self.dropout(x)"],"metadata":{"id":"_e3uEAe91EV7","executionInfo":{"status":"ok","timestamp":1662202937172,"user_tz":-540,"elapsed":7,"user":{"displayName":"김성찬","userId":"03517507033102912155"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class Nongransformer(nn.Module):\n","    def __init__(self, d_model: int, nhead: int, nlayers: int, d_hid: int = 2048, dropout: float = 0.5):\n","        super().__init__()\n","\n","        self.dim_mag = nn.Sequential(\n","            nn.Linear(49, d_model),\n","            nn.LeakyReLU(),\n","        )\n","        # self.pos_encoder = PositionalEncoding(d_model, dropout)\n","        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n","        self.decoder = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(d_model * 14, d_model * 7),\n","            nn.LeakyReLU(),\n","            nn.Linear(d_model * 7, d_model * 7),\n","            nn.LeakyReLU(),\n","            nn.Linear(d_model * 7, 28),\n","        )\n","\n","    def forward(self, src: Tensor) -> Tensor:\n","        src_mag = self.dim_mag(src)\n","        # src_pe = self.pos_encoder(src_mag)\n","        src_encode = self.transformer_encoder(src_mag)\n","        return self.decoder(src_encode)\n","        "],"metadata":{"id":"mEXXHTv7isks","executionInfo":{"status":"ok","timestamp":1662207955723,"user_tz":-540,"elapsed":305,"user":{"displayName":"김성찬","userId":"03517507033102912155"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"kZMEGXmk4f6c"}},{"cell_type":"code","source":["train_dataset = NongDataset(split='train', use_all_items=True)\n","test_dataset = NongDataset(split='test', use_all_items=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wx23Kqib3x2p","executionInfo":{"status":"ok","timestamp":1662207868860,"user_tz":-540,"elapsed":10194,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"336fe197-b572-4d67-b245-1eab43f3e0e5"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([41995, 14, 49])\n","torch.Size([41995, 28])\n","torch.Size([10508, 14, 49])\n","torch.Size([10508, 28])\n","torch.Size([370, 14, 49])\n"]}]},{"cell_type":"code","source":["train_dataset_0 = NongDataset(split='train', use_all_items=False, item_idx=0)"],"metadata":{"id":"naKjofNEJ6TH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(epochs, train_dataset):\n","    # DataLoader\n","    train_dataloader = DataLoader(\n","        dataset=train_dataset,\n","        batch_size=128,\n","        shuffle=True\n","    )\n","\n","    for inputs, labels in train_dataloader:\n","        print(f'type(inputs): {type(inputs)}')\n","        print(f'type(labels): {type(labels)}')\n","        print(f'inputs.shape: {inputs.shape}')\n","        print(f'labels.shape: {labels.shape}')\n","        break\n","\n","    # Net\n","    net = Nongransformer(\n","        d_model=512,\n","        nhead=8,\n","        nlayers=4,\n","    )\n","\n","    for name, param in net.named_parameters():\n","        nn.init.normal_(param)\n","    \n","    # Criterion\n","    criterion = nn.L1Loss(reduction='mean')\n","\n","    # Optimizer\n","    optimizer = optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999))\n","\n","    # Learning Rate Scheduler\n","    scheduler = lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n","\n","    # Device\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    net = net.to(device)\n","\n","    best_loss = 987654321.0\n","    save_count = 0\n","\n","    for epoch in range(epochs):\n","        print(f'{epoch} Epoch ' + '=' * 50)\n","\n","        # Train\n","        train_dataloader.dataset.set_phase('train')\n","        net.train()\n","\n","        train_loss = 0.0\n","        train_size = float(len(train_dataloader.dataset))\n","        print(f'train_size: {train_size}')\n","\n","        for inputs, labels in tqdm(train_dataloader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            n_samples = inputs.shape[0]\n","\n","            optimizer.zero_grad()\n","\n","            with torch.set_grad_enabled(True):\n","                outputs = net(inputs)\n","                loss = criterion(outputs, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            train_loss += loss.item() * n_samples\n","        \n","        print(f'Train Loss: {train_loss / train_size}')\n","\n","        # Eval\n","        train_dataloader.dataset.set_phase('val')\n","        net.eval()\n","\n","        eval_loss = 0.0\n","        eval_size = float(len(train_dataloader.dataset))\n","        print(f'eval_size: {eval_size}')\n","\n","        for inputs, labels in tqdm(train_dataloader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            n_samples = inputs.shape[0]\n","\n","            with torch.set_grad_enabled(False):\n","                outputs = net(inputs)\n","                loss = criterion(outputs, labels)\n","            \n","            eval_loss += loss.item() * n_samples\n","        \n","        print(f'Eval Loss: {eval_loss / eval_size}')\n","\n","        if eval_loss < best_loss:\n","            best_loss = eval_loss\n","            torch.save(net.state_dict(), f'./weights_0903_{save_count}.pth')\n","            save_count = save_count + 1\n","            print(f'Weight Save Count: {save_count}')\n","\n","train(epochs=100, train_dataset=train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NaKn55K636NE","outputId":"dd23b844-2421-4796-ad6e-cb7a1bc72409","executionInfo":{"status":"error","timestamp":1662208398168,"user_tz":-540,"elapsed":213963,"user":{"displayName":"김성찬","userId":"03517507033102912155"}}},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["type(inputs): <class 'torch.Tensor'>\n","type(labels): <class 'torch.Tensor'>\n","inputs.shape: torch.Size([128, 14, 49])\n","labels.shape: torch.Size([128, 28])\n","0 Epoch ==================================================\n","train_size: 41995.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:23<00:00, 13.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 57957.034410160435\n","eval_size: 10508.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:01<00:00, 49.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Loss: 43719.255547856395\n","Weight Save Count: 1\n","1 Epoch ==================================================\n","train_size: 41995.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:24<00:00, 13.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 56019.04498982394\n","eval_size: 10508.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:01<00:00, 50.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Loss: 43790.14168074324\n","2 Epoch ==================================================\n","train_size: 41995.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:23<00:00, 13.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 56069.83076342794\n","eval_size: 10508.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:01<00:00, 51.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Loss: 43775.12296137467\n","3 Epoch ==================================================\n","train_size: 41995.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:23<00:00, 13.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 56012.78493161388\n","eval_size: 10508.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:01<00:00, 49.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Loss: 43751.44349097116\n","4 Epoch ==================================================\n","train_size: 41995.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:23<00:00, 13.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 56015.045635176066\n","eval_size: 10508.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:01<00:00, 50.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Loss: 43766.17651283546\n","5 Epoch ==================================================\n","train_size: 41995.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:23<00:00, 13.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 56049.11816008602\n","eval_size: 10508.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:01<00:00, 50.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Loss: 43723.47500267653\n","6 Epoch ==================================================\n","train_size: 41995.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:23<00:00, 13.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 56038.476130994015\n","eval_size: 10508.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:01<00:00, 50.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Loss: 43759.946279025506\n","7 Epoch ==================================================\n","train_size: 41995.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 329/329 [00:23<00:00, 13.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 56125.31208439993\n","eval_size: 10508.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [00:01<00:00, 50.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval Loss: 43728.16370414208\n","8 Epoch ==================================================\n","train_size: 41995.0\n"]},{"output_type":"stream","name":"stderr","text":[" 33%|███▎      | 107/329 [00:07<00:16, 13.66it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-119edaa2bd75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Weight Save Count: {save_count}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-32-119edaa2bd75>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, train_dataset)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train Loss: {train_loss / train_size}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["def test(test_dataset, weight_path):\n","    test_dataloader = DataLoader(\n","        dataset=test_dataset,\n","        batch_size=37,\n","        shuffle=False,\n","    )\n","\n","    net = Nongransformer(\n","        d_model=512,\n","        nhead=8,\n","        nlayers=4,\n","    )\n","\n","    net.load_state_dict(torch.load(weight_path))\n","\n","    for inputs in test_dataloader:\n","        print(type(inputs))\n","        print(inputs.shape)\n","        break\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    net = net.to(device)\n","    net.eval()\n","\n","    result = []\n","\n","    for inputs in test_dataloader:\n","        inputs = inputs.to(device)\n","        with torch.no_grad():\n","            outputs = net(inputs)\n","            outputs = outputs.T\n","            \n","            outputs_1 = outputs[:14, :]\n","            outputs_2 = outputs[14:, :].mean(dim=0).reshape(1, -1)\n","            final_outputs = torch.cat([outputs_1, outputs_2], dim=0)\n","        result.append(final_outputs)\n","\n","    result = torch.cat(result, dim=0)\n","    print(f'result.shape: {result.shape}')\n","\n","    result_np = result.cpu().detach().numpy()\n","\n","    index = []\n","    for i in range(10):\n","        for _ in range(15):\n","            index.append(str(i))\n","    \n","    columns = []\n","    for i in range(37):\n","        columns.append(f'품목{i} 변동률')\n","\n","    date = []\n","    for i in range(10):\n","        for j in range(14):\n","            date.append(f'd+{j+1}')\n","        date.append('d+22 ~ 28 평균')\n","    \n","    date_pd = pd.DataFrame(data=date, index=index, columns=['일자'])\n","\n","    result_pd = pd.DataFrame(data=result_np, index=index, columns=columns)\n","\n","    final_pd = pd.concat([date_pd, result_pd], axis=1)\n","\n","    print(final_pd.head())\n","\n","    final_pd.to_csv('./result_0903_0.csv', encoding='utf-8-sig')\n","\n","# Train Execute\n","test(test_dataset, weight_path='./weights_0903_0.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RlHkcmuT9VV8","executionInfo":{"status":"ok","timestamp":1662208450446,"user_tz":-540,"elapsed":1196,"user":{"displayName":"김성찬","userId":"03517507033102912155"}},"outputId":"7548dd3e-3940-47da-baa0-f43c5fe7fe00"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","torch.Size([37, 14, 49])\n","result.shape: torch.Size([150, 37])\n","    일자       품목0 변동률       품목1 변동률       품목2 변동률       품목3 변동률       품목4 변동률  \\\n","0  d+1  68551.109375  68551.210938  68551.148438  68550.890625  68551.375000   \n","0  d+2  80551.804688  80551.914062  80551.906250  80551.976562  80551.835938   \n","0  d+3   2291.870117   2291.799316   2291.870850   2292.195557   2291.647461   \n","0  d+4  23230.343750  23230.130859  23230.210938  23230.126953  23230.437500   \n","0  d+5   3696.071289   3696.183594   3696.156250   3696.082031   3696.394531   \n","\n","        품목5 변동률       품목6 변동률       품목7 변동률       품목8 변동률  ...      품목27 변동률  \\\n","0  68550.875000  68551.304688  68551.226562  68551.250000  ...  68551.343750   \n","0  80552.445312  80551.312500  80552.101562  80551.531250  ...  80551.890625   \n","0   2292.086426   2291.582031   2292.026367   2292.052979  ...   2291.705566   \n","0  23230.404297  23230.476562  23230.044922  23230.472656  ...  23230.330078   \n","0   3695.867188   3696.305664   3696.135742   3696.780273  ...   3696.690430   \n","\n","       품목28 변동률      품목29 변동률      품목30 변동률      품목31 변동률      품목32 변동률  \\\n","0  68551.281250  68551.156250  68551.195312  68551.132812  68550.953125   \n","0  80551.992188  80551.867188  80551.695312  80552.023438  80552.023438   \n","0   2292.057617   2292.111816   2291.761719   2291.811035   2291.886475   \n","0  23230.095703  23230.332031  23230.457031  23230.251953  23230.462891   \n","0   3696.123047   3696.047852   3696.359375   3696.091797   3695.713867   \n","\n","       품목33 변동률      품목34 변동률      품목35 변동률      품목36 변동률  \n","0  68551.156250  68551.156250  68550.937500  68551.359375  \n","0  80551.718750  80552.046875  80551.789062  80551.875000  \n","0   2291.658203   2291.999756   2291.647949   2291.901611  \n","0  23230.339844  23230.197266  23230.427734  23230.267578  \n","0   3696.437500   3695.910156   3696.169922   3696.074219  \n","\n","[5 rows x 38 columns]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6R_Ly2xRGwYl"},"execution_count":null,"outputs":[]}]}